# ==============================================================================
# å®Œæ•´ main.py - ã€V18.0 ç»ˆæå•å›¾ç»Ÿä¸€ç‰ˆã€‘
# ==============================================================================

import os
import io
import re
import uuid
from fastapi import FastAPI, File, UploadFile, HTTPException, Form
from fastapi.responses import PlainTextResponse
from fastapi.middleware.cors import CORSMiddleware
from dotenv import load_dotenv
import dashscope

from dashscope import MultiModalConversation

# --- 1. åˆå§‹åŒ– ---
load_dotenv()
app = FastAPI()

# åˆå§‹åŒ– é˜¿é‡Œäº‘é€šä¹‰åƒé—® (é…ç½®API Key)
print("æ­£åœ¨é…ç½®é€šä¹‰åƒé—®API Key...")
try:
    dashscope.api_key = os.getenv("DASHSCOPE_API_KEY")
    if not dashscope.api_key: raise ValueError("API Key not found in .env file")
    print("é€šä¹‰åƒé—®API Keyé…ç½®æˆåŠŸã€‚")
except Exception as e:
    print(f"!!! é…ç½®é€šä¹‰åƒé—®API Keyå¤±è´¥: {e}")

# --- 2. FastAPIåº”ç”¨é…ç½® ---
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

@app.get("/")
def read_root():
    return {"message": "AIè§£é¢˜åç«¯æœåŠ¡æ­£åœ¨è¿è¡Œ (V18.0 ç»ˆæå•å›¾ç»Ÿä¸€ç‰ˆ)"}
# ==============================================================================
# å®Œæ•´ main.py - ç¬¬äºŒéƒ¨åˆ†: æ ¸å¿ƒAPIæ¥å£
# ==============================================================================

# --- ç»Ÿä¸€çš„AIè°ƒç”¨å‡½æ•° ---
def call_qwen_vl_max(messages: list) -> str:
    """
    è°ƒç”¨é€šä¹‰åƒé—®VL-Maxæ¨¡å‹å¹¶è¿”å›æ–‡æœ¬ç»“æœã€‚
    """
    print("\n--- æ­£åœ¨è°ƒç”¨é€šä¹‰åƒé—®VL-Max API... ---")
    
    response = dashscope.MultiModalConversation.call(model='qwen-vl-max', messages=messages)
    # respon = MultiModalConversation.call(
    #     model='qwen-vl-max',
    #     messages=messages,
    #     stream=True
    # )

    # # æ‹¼æ¥æ‰€æœ‰æµå¼è¿”å›çš„å†…å®¹
    # full_content = ""
    # for chunk in respon:
    #     if chunk.output and chunk.output.choices:
    #         content = chunk.output.choices[0].message.content
    #         full_content += content
    #     else:
    #         continue  # å¿½ç•¥æ— å†…å®¹çš„ chunk

    # # æ„é€ ä¸€ä¸ªä¸åŸ response ç»“æ„ä¸€è‡´çš„ Response å¯¹è±¡
    # # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬æ‰‹åŠ¨æ„å»ºä¸€ä¸ªç­‰ä»·çš„ Response å¯¹è±¡
    # # å®é™…ä¸Šä½ å¯ä»¥é€‰æ‹©ç›´æ¥è¿”å› full_contentï¼Œä½†ä½ æƒ³ä¿æŒç±»å‹ä¸€è‡´

    # # åˆ›å»ºä¸€ä¸ªâ€œåˆæˆâ€çš„ Response å¯¹è±¡
    # response = MultiModalConversation.call(
    #     request_id=respon.request_id,
    #     output={
    #         "choices": [
    #             {
    #                 "finish_reason": "stop",  # å‡è®¾ç»“æŸåŸå› 
    #                 "index": 0,
    #                 "message": {
    #                     "content": full_content,
    #                     "role": "assistant"
    #                 }
    #             }
    #         ],
    #         "usage": None  # å¯é€‰ï¼šå¯ä»æµä¸­æå– usage æ•°æ®ï¼Œä½†é€šå¸¸ä¸å®Œæ•´
    #     },
    #     code=200,
    #     message="OK",
    #     headers=respon.headers,
    #     raw=respon.raw
    # )

    
    content = response.output.choices[0].message.content
    
    # ä»è¿”å›çš„åˆ—è¡¨ä¸­æå–æ–‡æœ¬
    if isinstance(content, list):
        for part in content:
            if part.get("text"):
                print("--- é€šä¹‰åƒé—®APIè°ƒç”¨æˆåŠŸï¼Œå·²æå–æ–‡æœ¬ã€‚ ---")
                return part["text"]
    elif isinstance(content, str):
        print("--- é€šä¹‰åƒé—®APIè°ƒç”¨æˆåŠŸï¼Œå·²æå–æ–‡æœ¬ã€‚ ---")
        return content
        
    raise ValueError("é€šä¹‰åƒé—®æœªè¿”å›æœ‰æ•ˆçš„æ–‡æœ¬å†…å®¹ã€‚")

# --- ã€æ ¸å¿ƒã€‘: åˆ›å»ºä¸€ä¸ªç»Ÿä¸€çš„ã€å¤„ç†å•å›¾è¯·æ±‚çš„å‡½æ•° ---
async def process_single_image_request(prompt_text: str, image: UploadFile):
    """
    è¿™æ˜¯ä¸€ä¸ªå¯å¤ç”¨çš„å‡½æ•°ï¼Œè´Ÿè´£å¤„ç†æ‰€æœ‰æ¥æ”¶å•å¼ å›¾ç‰‡çš„è¯·æ±‚ã€‚
    """
    print(f"\næ”¶åˆ°è¯·æ±‚, prompt: '{prompt_text[:80]}...'")
    
    # ä½¿ç”¨ /tmp ç›®å½•åœ¨Linux/macOSå’ŒWindowsçš„WSLç¯å¢ƒä¸­æ›´é€šç”¨
    temp_dir = "/tmp" if os.path.exists("/tmp") else "."
    temp_image_path = os.path.join(temp_dir, f"temp_image_{uuid.uuid4()}.png")

    try:
        image_bytes = await image.read()
        with open(temp_image_path, "wb") as f:
            f.write(image_bytes)
        
        # æ„å»ºå‘é€ç»™æ¨¡å‹çš„æ¶ˆæ¯
        messages = [{
            'role': 'user',
            'content': [
                {'text': prompt_text},
                {'image': f'file://{os.path.abspath(temp_image_path)}'}
            ]
        }]
        
        result = call_qwen_vl_max(messages)
        return PlainTextResponse(content=result, media_type="text/markdown; charset=utf-8")
        
    except Exception as e:
        print(f"!!! æ¥å£å‘ç”Ÿé”™è¯¯: {e}")
        raise HTTPException(status_code=500, detail=str(e))
    finally:
        if os.path.exists(temp_image_path):
            os.remove(temp_image_path)


# --- API æ¥å£ ---

@app.post("/solve")
async def solve_from_image(
    prompt_text: str = Form(...),
    file: UploadFile = File(...) # æ³¨æ„: keyæ˜¯ 'file'
):
    """è§£é¢˜æ¥å£ï¼šè°ƒç”¨ç»Ÿä¸€çš„å¤„ç†å‡½æ•°"""
    return await process_single_image_request(prompt_text, file)


@app.post("/review")
async def review_from_image(
    prompt_text: str = Form(...),
    file: UploadFile = File(...) # æ³¨æ„: keyä¹Ÿæ˜¯ 'file'
):
    """æ”¹é¢˜æ¥å£ï¼šä¹Ÿè°ƒç”¨ç»Ÿä¸€çš„å¤„ç†å‡½æ•°"""
    return await process_single_image_request(prompt_text, file)




































# # ==============================================================================
# # å®Œæ•´ main.py - ã€V12.0 ç»ˆææ•™å¸ˆç‰ˆã€‘
# # ==============================================================================

# # --- ã€æ ¸å¿ƒã€‘: åœ¨æ‰€æœ‰importä¹‹å‰ï¼Œè®¾ç½®ç¯å¢ƒå˜é‡ç¦ç”¨å¤šè¿›ç¨‹ ---
# import os
# # os.environ["TOKENIZERS_PARALLELISM"] = "false"
# # os.environ["OMP_NUM_THREADS"] = "1"
# # os.environ["MKL_NUM_THREADS"] = "1"

# # --- Pythonæ ‡å‡†åº“ ---
# import io
# import base64
# import cv2
# import re
# import uuid
# import numpy as np



# # --- ç¬¬ä¸‰æ–¹åº“ ---
# from fastapi import FastAPI, File, UploadFile, HTTPException
# from fastapi.staticfiles import StaticFiles
# from fastapi.middleware.cors import CORSMiddleware
# from fastapi.responses import PlainTextResponse
# from PIL import Image, ImageOps
# from pix2text import Pix2Text
# from dotenv import load_dotenv

# # --- AIåº“ ---
# from openai import OpenAI
# import dashscope

# # --- 1. åˆå§‹åŒ– ---
# load_dotenv()
# app = FastAPI()

# # æ‡’åŠ è½½ Pix2Text
# p2t = None
# def initialize_pix2text():
#     global p2t
#     if p2t is None:
#         print("é¦–æ¬¡è¯·æ±‚ï¼šæ­£åœ¨ä»¥å®‰å…¨æ¨¡å¼åˆå§‹åŒ– Pix2Text...")
#         # åœ¨äº‘ç¯å¢ƒä¸­ï¼Œ/tmpæ˜¯ä¿è¯å¯å†™çš„ä¸´æ—¶ç›®å½•
#         cache_dir = "/tmp/pix2text_cache"
#         os.makedirs(cache_dir, exist_ok=True)
#         p2t = Pix2Text(device='cpu', root=cache_dir)
#         print("Pix2Text åˆå§‹åŒ–å®Œæˆã€‚")

# print("æ­£åœ¨åˆå§‹åŒ–Kimiå®¢æˆ·ç«¯ (OpenAIå…¼å®¹æ¨¡å¼)...")
# try:
#     kimi_client = OpenAI(
#         api_key=os.getenv("MOONSHOT_API_KEY"),
#         base_url="https://api.moonshot.cn/v1",
#     )
#     if not os.getenv("MOONSHOT_API_KEY"): raise ValueError("API Key not found in .env")
#     print("Kimiå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸã€‚")
# except Exception as e:
#     print(f"!!! åˆå§‹åŒ–Kimiå®¢æˆ·ç«¯å¤±è´¥: {e}")
#     kimi_client = None

# print("æ­£åœ¨é…ç½®é€šä¹‰åƒé—®API Key...")
# try:
#     dashscope.api_key = os.getenv("DASHSCOPE_API_KEY")
#     if not dashscope.api_key: raise ValueError("API Key not found in .env")
#     print("é€šä¹‰åƒé—®API Keyé…ç½®æˆåŠŸã€‚")
# except Exception as e:
#     print(f"!!! é…ç½®é€šä¹‰åƒé—®API Keyå¤±è´¥: {e}")
    
    
# # --- 2. æ ¸å¿ƒè¾…åŠ©å‡½æ•° (æ¥è‡ªKimiçš„å»ºè®®) ---

# def image_preprocess_v2(image_bytes: bytes, max_size: int = 2048) -> Image.Image:
#     """
#     ä¸€ä¸ªå·¥ç¨‹çº§çš„å›¾ç‰‡é¢„å¤„ç†æµæ°´çº¿ã€‚
#     :param image_bytes: åŸå§‹å›¾ç‰‡å­—èŠ‚æµ
#     :param max_size: å›¾ç‰‡é•¿è¾¹çš„æœ€å¤§å°ºå¯¸
#     :return: ç»è¿‡ä¼˜åŒ–å¤„ç†çš„PIL Imageå¯¹è±¡ (ç°åº¦å›¾)
#     """
#     try:
#         # 1. ä»å­—èŠ‚æµåŠ è½½å›¾ç‰‡ (ä½¿ç”¨OpenCV)
#         nparr = np.frombuffer(image_bytes, np.uint8)
#         img_cv = cv2.imdecode(nparr, cv2.IMREAD_COLOR)

#         # 2. å°ºå¯¸å½’ä¸€åŒ–
#         h, w = img_cv.shape[:2]
#         if max(h, w) > max_size:
#             scale = max_size / max(h, w)
#             img_cv = cv2.resize(img_cv, (int(w * scale), int(h * scale)), interpolation=cv2.INTER_AREA)

#         # 3. è½¬æ¢ä¸ºç°åº¦å›¾
#         gray = cv2.cvtColor(img_cv, cv2.COLOR_BGR2GRAY)

#         # 4. è§’åº¦æ ¡æ­£ (Deskew)
#         # è¿™æ˜¯ä¸€ä¸ªç®€åŒ–çš„å®ç°ï¼ŒåŸºäºå¯»æ‰¾æœ€å°é¢ç§¯çš„åŒ…å›´çŸ©å½¢
#         coords = np.column_stack(np.where(gray < 128))
#         angle = cv2.minAreaRect(coords)[-1]
#         if angle < -45:
#             angle = -(90 + angle)
#         else:
#             angle = -angle
        
#         if abs(angle) > 1: # åªå¯¹å€¾æ–œè¶…è¿‡1åº¦çš„å›¾ç‰‡è¿›è¡Œæ ¡æ­£
#             (h, w) = gray.shape[:2]
#             center = (w // 2, h // 2)
#             M = cv2.getRotationMatrix2D(center, angle, 1.0)
#             gray = cv2.warpAffine(gray, M, (w, h), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)
#             print(f"--- å›¾ç‰‡å·²è‡ªåŠ¨æ ¡æ­£è§’åº¦: {angle:.2f} åº¦ ---")

#         # 5. é™å™ª (ä½¿ç”¨é«˜æ–¯æ¨¡ç³Š)
#         blurred = cv2.GaussianBlur(gray, (5, 5), 0)

#         # 6. æ™ºèƒ½è‡ªé€‚åº”äºŒå€¼åŒ– (å¤„ç†å…‰ç…§ä¸å‡)
#         # ADAPTIVE_THRESH_GAUSSIAN_C æ•ˆæœé€šå¸¸æ¯” MEAN_C æ›´å¥½
#         binary = cv2.adaptiveThreshold(
#             blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
#             cv2.THRESH_BINARY, 11, 2
#         )

#         # 7. (å¯é€‰) é”åŒ– - æ‹‰æ™®æ‹‰æ–¯ç®—å­
#         sharpened = cv2.Laplacian(binary, cv2.CV_64F)
#         sharpened = np.uint8(np.clip(binary - 0.5 * sharpened, 0, 255))

#         # 8. å°†å¤„ç†åçš„OpenCVå›¾åƒè½¬å›PIL Imageå¯¹è±¡
#         img_pil = Image.fromarray(binary)
        
#         return img_pil

#     except Exception as e:
#         print(f"!!! å›¾ç‰‡é¢„å¤„ç†å¤±è´¥: {e}. å°†ä½¿ç”¨åŸå§‹å›¾ç‰‡è¿›è¡Œè¯†åˆ«ã€‚")
#         # å¦‚æœé¢„å¤„ç†å¤±è´¥ï¼Œä¼˜é›…é™çº§ï¼Œè¿”å›åŸå§‹çš„ç°åº¦å›¾
#         return Image.open(io.BytesIO(image_bytes)).convert('L')

# def ocr_text_clean_v2(raw_text: str) -> str:
#     """
#     ä¸€ä¸ªå·¥ç¨‹çº§çš„ã€å¤šé˜¶æ®µçš„OCRæ–‡æœ¬æ¸…æ´—å‡½æ•°ã€‚
#     """
#     # æ£€æŸ¥è¾“å…¥æ˜¯å¦ä¸ºå­—ç¬¦ä¸²
#     if not isinstance(raw_text, str):
#         print(f"!!! æ–‡æœ¬æ¸…æ´—å‡½æ•°æ”¶åˆ°éå­—ç¬¦ä¸²ç±»å‹: {type(raw_text)}ï¼Œå°†è¿”å›ç©ºå­—ç¬¦ä¸²ã€‚")
#         return ""
    
#     # --- é˜¶æ®µ1: åŸºç¡€å­—ç¬¦å½’ä¸€åŒ– ---
#     # æ›¿æ¢æ‰€æœ‰ä¸­æ–‡æ ‡ç‚¹å’Œå¸¸è§é”™è®¤å­—ç¬¦
#     replacements_char = {
#         'ï¼ˆ': '(', 'ï¼‰': ')', 'ã€': '[', 'ã€‘': ']', 'ï¼Œ': ',', 'ã€‚': '.',
#         'ï¼‹': '+', 'ï¼': '-', 'Ã—': '*', 'Ã·': '/', 'ï¼': '=',
#         'Î±': '\\alpha', 'Î²': '\\beta', 'Î³': '\\gamma', 'Î¸': '\\theta', 'Ï€': '\\pi',
#         'Î”': '\\Delta', 'Î©': '\\Omega',
#         'â‰¤': '\\leq', 'â‰¥': '\\geq', 'â‰ ': '\\neq',
#         'âˆˆ': '\\in', 'âˆ€': '\\forall', 'âˆƒ': '\\exists',
#         'â†’': '\\rightarrow',
#         'âŠ¥': '\\perp',
#     }
#     for old, new in replacements_char.items():
#         raw_text = raw_text.replace(old, new)
        
#     cleaned_text = raw_text
    
#     # --- é˜¶æ®µ2: åŸºäºæ¨¡å¼çš„é€šç”¨ä¿®å¤ (é«˜é¢‘é”™è¯¯) ---
#     # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼ï¼ŒæŒ‰ä¼˜å…ˆçº§é¡ºåºæ‰§è¡Œ
#     # (keyæ˜¯æ­£åˆ™è¡¨è¾¾å¼, valueæ˜¯æ›¿æ¢æ ¼å¼)
#     replacements_pattern = {
#         # ä¿®å¤ sqrt, e.g., "sqrt3" -> "\sqrt{3}"
#         r'sqrt\s*(\d+|[a-zA-Z])': r'\\sqrt{\1}',
#         # ä¿®å¤ frac, e.g., "frac12" -> "\frac{1}{2}", "fracab" -> "\frac{a}{b}"
#         r'frac\s*(\d+|[a-zA-Z])\s*(\d+|[a-zA-Z])': r'\\frac{\1}{\2}',
#         # ä¿®å¤ä¸Šä¸‹æ ‡, e.g., "x^2", "x_1" -> "$x^2$", "$x_1$" (å…ˆä¸åŠ $, åç»­å¤„ç†)
#         # è¿™é‡Œåªåšè§„èŒƒåŒ–
#         r'([a-zA-Z\)])\s*\^\s*(\d+|[a-zA-Z])': r'\1^{\2}',
#         r'([a-zA-Z\)])\s*_\s*(\d+|[a-zA-Z])': r'\1_{\2}',
#         # ä¿®å¤å¸¸è§çš„å‡½æ•°å, e.g., "sin x" -> "\sin x"
#         r'\b(sin|cos|tan|log|ln)\b': r'\\\1',
#         # ä¿®å¤å‘é‡è¡¨ç¤º, e.g., "vec a" -> "\vec{a}"
#         r'\bvec\s*([a-zA-Z])': r'\\vec{\1}',
#     }

#     for pattern, replacement in replacements_pattern.items():
#         cleaned_text = re.sub(pattern, replacement, cleaned_text)
        
#     # --- é˜¶æ®µ3: ä¸Šä¸‹æ–‡æ„ŸçŸ¥ä¿®å¤ ---
#     # e.g., ä¿®å¤è¢«ç©ºæ ¼éš”å¼€çš„ "x ^ 2"
#     # è¿™ä¸ªæ¯”è¾ƒå¤æ‚ï¼Œå¯ä»¥é€šè¿‡åˆ†è¯åæ£€æŸ¥ï¼Œæˆ–è€…æ›´å¤æ‚çš„æ­£åˆ™
    
#     # --- é˜¶æ®µ4: æœ€ç»ˆæ¸…ç† ---
#     # ç§»é™¤å…¬å¼å’Œæ–‡æœ¬ä¹‹é—´çš„å¤šä½™ç©ºæ ¼
#     cleaned_text = re.sub(r'\s{2,}', ' ', cleaned_text).strip()
    
#     return cleaned_text

# # --- ã€æ–°å¢ã€‘å¯å¤ç”¨çš„OCRå¤„ç†æ€»ç®¡ ---
# def get_ocr_text_from_image(image_bytes: bytes) -> str:
#     """
#     å°è£…äº† é¢„å¤„ç† -> OCRè¯†åˆ« -> ç±»å‹é€‚é… -> æ–‡æœ¬æ¸…æ´— çš„å®Œæ•´æµç¨‹ã€‚
#     è¿™æ˜¯è§£å†³'Page'å¯¹è±¡é—®é¢˜çš„æœ€ç»ˆæ–¹æ¡ˆã€‚
#     """
#     print("\n--- [å­æµç¨‹] å¼€å§‹OCRå¤„ç†... ---")
#     preprocessed_image = image_preprocess_v2(image_bytes)
    
#     # å¼ºåˆ¶Pix2Textè¿”å›å­—ç¬¦ä¸²ï¼Œè¿™æ˜¯æœ€å…³é”®çš„ä¿®å¤
#     ocr_result = p2t(preprocessed_image, return_text=True)
    
#     # åŒé‡ä¿é™©ï¼šæ£€æŸ¥è¿”å›ç±»å‹
#     if not isinstance(ocr_result, str):
#         print(f"--- [è­¦å‘Š] Pix2Textæœªè¿”å›å­—ç¬¦ä¸²ï¼Œç±»å‹ä¸º: {type(ocr_result)}ã€‚å°è¯•è°ƒç”¨.to_text()ã€‚")
#         if hasattr(ocr_result, 'to_text'):
#             ocr_result = ocr_result.to_text()
#         else:
#             ocr_result = str(ocr_result)
            
#     cleaned_text = ocr_text_clean_v2(ocr_result)
#     print(f"--- [å­æµç¨‹] OCRå¤„ç†å®Œæˆï¼Œæ¸…æ´—åæ–‡æœ¬: {cleaned_text[:80].strip()}...")
#     return cleaned_text

# def get_vision_description(image_bytes: bytes, temp_dir: str = "/tmp") -> str:
#     """å°è£…äº†Visionè¯†åˆ«çš„å®Œæ•´æµç¨‹ã€‚"""
#     print("\n--- [å­æµç¨‹] å¼€å§‹Visionå¤„ç†... ---")
#     temp_image_path = os.path.join(temp_dir, f"temp_vision_{uuid.uuid4()}.png")
    
#     try:
#         with open(temp_image_path, "wb") as f:
#             f.write(image_bytes)
        
#         vision_prompt = """
# **æ ¸å¿ƒä»»åŠ¡**:
# ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å›¾åƒåˆ†æå¼•æ“ã€‚è¯·å½»åº•è§£æä¸‹æ–¹å›¾ç‰‡ä¸­çš„æ‰€æœ‰ã€è§†è§‰ä¿¡æ¯ã€‘ï¼Œå¹¶å°†å…¶è½¬åŒ–ä¸ºå¯¹è§£é¢˜è‡³å…³é‡è¦çš„ã€ç»“æ„åŒ–çš„æ–‡å­—æè¿°ã€‚

# **åˆ†æåŸåˆ™**:
# 1.  **ç»å¯¹ä¸“æ³¨è§†è§‰**: **å½»åº•å¿½ç•¥**å›¾ç‰‡ä¸­çš„æ‰€æœ‰é•¿æ®µæ–‡å­—ï¼ˆå¦‚é¢˜ç›®ã€é—®é¢˜æè¿°ã€é€‰é¡¹ï¼‰ã€‚ä½ çš„åˆ†æå¯¹è±¡ä»…é™äº**å›¾å½¢ã€å›¾è¡¨ã€å›¾åƒã€ç¤ºæ„å›¾åŠå…¶å†…éƒ¨çš„æ ‡æ³¨**ã€‚
# 2.  **æå–å…³é”®ä¿¡æ¯**: ä½ çš„ç›®æ ‡æ˜¯æå–æ‰€æœ‰**æ— æ³•**é€šè¿‡çº¯æ–‡æœ¬OCRè·å¾—çš„å…³é”®ä¿¡æ¯ã€‚ä¾‹å¦‚ï¼š
#     *   **å‡ ä½•**: å›¾å½¢ç±»å‹ã€é¡¶ç‚¹/çº¿æ®µ/è§’çš„å…³ç³»ï¼ˆå¹³è¡Œã€å‚ç›´ã€ç›¸ç­‰ï¼‰ã€æ ‡æ³¨çš„æ•°å€¼ã€‚
#     *   **å›¾è¡¨**: åæ ‡è½´å«ä¹‰ã€å•ä½ã€å…³é”®ç‚¹åæ ‡ï¼ˆé¡¶ç‚¹ã€äº¤ç‚¹ï¼‰ã€æ•°æ®è¶‹åŠ¿ã€‚
#     *   **ç‰©ç†/åŒ–å­¦/ç”Ÿç‰©**: è£…ç½®è¿æ¥å…³ç³»ã€ç‰©è´¨æµå‘ã€å—åŠ›æ–¹å‘ã€ç»†èƒç»“æ„ã€é£Ÿç‰©ç½‘å…³ç³»ç­‰ã€‚
#     *   **åœ°ç†**: åœ°å›¾è¦ç´ ï¼ˆç­‰é«˜çº¿ã€æ²³æµã€å›¾ä¾‹ï¼‰ã€ç©ºé—´åˆ†å¸ƒè§„å¾‹ã€‚
# 3.  **ç®€æ´ä¸”ç»“æ„åŒ–**: ä½¿ç”¨æ¸…æ™°çš„Markdownæ ‡é¢˜å’Œåˆ—è¡¨æ¥ç»„ç»‡ä½ çš„åˆ†æç»“æœï¼Œè¯­è¨€è¦ç²¾ç‚¼ã€å®¢è§‚ã€‚

# **æœ€ç»ˆæŒ‡ä»¤**:
# å¦‚æœå›¾ç‰‡ä¸­ä¸åŒ…å«ä»»ä½•æœ‰æ„ä¹‰çš„ã€ç”¨äºè§£é¢˜çš„è§†è§‰å›¾å½¢ï¼ˆä¾‹å¦‚ï¼Œåªæ˜¯ä¸€æ®µçº¯æ–‡å­—çš„æˆªå›¾ï¼‰ï¼Œè¯·ç›´æ¥å›ç­”ï¼šâ€œå›¾ä¸­æœªåŒ…å«é¢å¤–çš„è§†è§‰ä¿¡æ¯ã€‚â€ å¦åˆ™ï¼Œè¯·å¼€å§‹ä½ çš„åˆ†æã€‚
# """
#         messages = [{'role': 'user', 'content': [{'text': vision_prompt}, {'image': f'file://{os.path.abspath(temp_image_path)}'}]}]
#         response = dashscope.MultiModalConversation.call(model='qwen-vl-max', messages=messages)
        
#         if response.status_code == 200:
#             content = response.output.choices[0].message.content
#             if isinstance(content, list):
#                 for part in content:
#                     if part.get("text"):
#                         desc = part["text"]
#                         print(f"--- [å­æµç¨‹] Visionå¤„ç†å®Œæˆï¼Œæè¿°: {desc[:80].strip()}...")
#                         return desc
#             elif isinstance(content, str):
#                 print(f"--- [å­æµç¨‹] Visionå¤„ç†å®Œæˆï¼Œæè¿°: {content[:80].strip()}...")
#                 return content
#         else:
#              print(f"!!! Vision APIè°ƒç”¨å¤±è´¥: {response.message}")
#              return "è§†è§‰æ¨¡å‹åˆ†æå¤±è´¥ã€‚"
#     finally:
#         if os.path.exists(temp_image_path):
#             os.remove(temp_image_path)
#     return "è§†è§‰æ¨¡å‹æœªè¿”å›æœ‰æ•ˆæè¿°ã€‚"
# # ==============================================================================
# # å®Œæ•´ main.py - ç¬¬äºŒéƒ¨åˆ†: FastAPIåº”ç”¨é…ç½®
# # ==============================================================================

# # --- 2. FastAPIåº”ç”¨é…ç½® ---
# app.add_middleware(
#     CORSMiddleware,
#     allow_origins=["*"],
#     allow_credentials=True,
#     allow_methods=["*"],
#     allow_headers=["*"],
# )


# @app.get("/")
# def read_root():
#     return {"message": "AIè§£é¢˜åç«¯æœåŠ¡æ­£åœ¨è¿è¡Œ (V14.2 ç»ˆæé‡æ„ç‰ˆ)"}
# # ==============================================================================
# # å®Œæ•´ main.py - ç¬¬ä¸‰éƒ¨åˆ†: æ ¸å¿ƒAPIæ¥å£
# # ==============================================================================
# @app.post("/solve")
# async def solve_from_image(file: UploadFile = File(...)):
#     try:
#         initialize_pix2text()
#     except Exception as e:
#         raise HTTPException(status_code=500, detail=f"æ ¸å¿ƒOCRæœåŠ¡åˆå§‹åŒ–å¤±è´¥: {e}")

#     if not p2t or not kimi_client or not dashscope.api_key:
#         raise HTTPException(status_code=500, detail="æ ¸å¿ƒAIæœåŠ¡æœªå°±ç»ª")

    
#     temp_image_path = f"/tmp/temp_{uuid.uuid4()}.png"
#     try:
#         image_bytes = await file.read()
        
#         # --- å›¾åƒå±‚ & è¯†åˆ«å±‚ (Aè·¯) ---
#         preprocessed_image = image_preprocess_v2(image_bytes)
#         full_page_ocr_text = p2t(preprocessed_image, return_text=True)
        
#         # --- ã€æ–°å¢ã€‘ä¸“æ³¨åŠ›æ¨¡å— (A.2è·¯) ---
#         print("\n--- [A.2è·¯] æ­£åœ¨æå–é¢˜ç›®ä¸»ä½“... ---")
#         extractor_prompt = f"""
#         **æ ¸å¿ƒä»»åŠ¡**:
#         ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–‡æ¡£åˆ†æå¸ˆã€‚ä¸‹é¢æ˜¯ä¸€å¼ å›¾ç‰‡OCRè¯†åˆ«å‡ºçš„æ‰€æœ‰æ–‡æœ¬ã€‚è¯·ä»ä¸­**åªæå–å‡ºå±äºâ€œé¢˜ç›®â€æœ¬èº«çš„æ ¸å¿ƒå†…å®¹**ã€‚

#         **æå–è§„åˆ™**:
#         1.  **åŒ…å«**: é¢˜ç›®çš„é¢˜å¹²ã€é—®é¢˜(ä¾‹å¦‚(1)(2))ã€æ‰€æœ‰é€‰é¡¹ï¼ˆA, B, C, Dç­‰ï¼‰ã€ä»¥åŠé¢˜ç›®é™„å¸¦çš„å…¬å¼å’Œæ¡ä»¶ã€‚
#         2.  **å¿½ç•¥**: å¿…é¡»å¿½ç•¥æ‰€æœ‰ä¸é¢˜ç›®æ— å…³çš„å†…å®¹ï¼Œä¾‹å¦‚ï¼šâ€œè§£é¢˜è¯¦æƒ…â€ã€â€œç­”æ¡ˆè§£æâ€ã€â€œæ ¸å¿ƒæ€è·¯â€ã€â€œç¬¬ä¸€ä¸ªå…ƒç´ â€ã€â€œé¡µçœ‰é¡µè„šâ€ã€â€œå›¾1â€ã€â€œé€‰æ‹©é¢˜â€ç­‰æ ‡é¢˜æ€§æˆ–è§£é‡Šæ€§æ–‡å­—ã€‚
#         3.  **è¾“å‡º**: åªè¾“å‡ºæå–å‡ºçš„ã€çº¯å‡€çš„é¢˜ç›®æ–‡æœ¬ã€‚å¦‚æœOCRå…¨æ–‡çœ‹èµ·æ¥å°±æ˜¯ä¸€ä¸ªå¹²å‡€çš„é¢˜ç›®ï¼Œå°±è¿”å›åŸæ–‡ã€‚

#         **ã€å¾…å¤„ç†çš„OCRå…¨æ–‡ã€‘**:
#         ```
#         {full_page_ocr_text}
#         ```
#         """

#         extractor_response = kimi_client.chat.completions.create(
#             model="moonshot-v1-8k",
#             messages=[
#                 {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªç²¾ç¡®çš„æ–‡æœ¬æå–åŠ©æ‰‹ï¼Œä¸¥æ ¼éµå¾ªæŒ‡ä»¤ï¼Œåªè¾“å‡ºæå–çš„é¢˜ç›®å†…å®¹ï¼Œä¸åŠ ä»»ä½•é¢å¤–è§£é‡Šã€‚"},
#                 {"role": "user", "content": extractor_prompt}
#             ],
#             temperature=0.0,
#         )
#         question_text = extractor_response.choices[0].message.content.strip()
#         print(f"--- [A.2è·¯] æå–å‡ºçš„é¢˜ç›®ä¸»ä½“: {question_text[:200].strip()}...")
    
#         geometry_description = get_vision_description(image_bytes)

#         # --- Cè·¯: ã€ç»ˆææ•™å¸ˆç‰ˆPromptã€‘ ---
#         print("\n--- [Cè·¯] å¼€å§‹ä¿¡æ¯èåˆå¹¶è°ƒç”¨Kimi ---")
# #         
#         final_prompt = f"""
#         **æ ¸å¿ƒä»»åŠ¡**:
#         è¯·æ ¹æ®ä¸‹é¢æä¾›çš„é¢˜ç›®ä¿¡æ¯ï¼Œä¸ºå­¦ç”Ÿç”Ÿæˆä¸€ä»½è¯¦å°½ã€å®Œæ•´ã€æ­¥éª¤æ¸…æ™°çš„è§£é¢˜ç­”æ¡ˆã€‚

#         **ã€ä¸å¯è¿èƒŒçš„é»„é‡‘æ³•åˆ™ã€‘**:

#         1.  **å¿…é¡»ç»™å‡ºæœ€ç»ˆç­”æ¡ˆ**:
#             *   å¯¹äºè®¡ç®—é¢˜ï¼Œå¿…é¡»ç»™å‡ºæœ€ç»ˆçš„æ•°å€¼ç»“æœã€‚
#             *   å¯¹äºé€‰æ‹©é¢˜ï¼Œå¿…é¡»æ˜ç¡®æŒ‡å‡ºå“ªä¸ªé€‰é¡¹æ˜¯æ­£ç¡®çš„ (ä¾‹å¦‚, "å› æ­¤ï¼Œæ­£ç¡®ç­”æ¡ˆæ˜¯ Bã€‚")ã€‚
#             *   å¯¹äºè¯æ˜é¢˜ï¼Œå¿…é¡»ç»™å‡ºæœ€ç»ˆçš„è¯æ˜ç»“è®ºã€‚
#             *   **ç»å¯¹ç¦æ­¢**åªæä¾›è§£é¢˜æ€è·¯æˆ–åˆ†æï¼Œè€Œä¸ç»™å‡ºæœ€ç»ˆç­”æ¡ˆã€‚

#         2.  **å¿…é¡»å±•ç¤ºå®Œæ•´è¿‡ç¨‹**:
#             *   å¿…é¡»å±•ç¤ºæ‰€æœ‰å…³é”®çš„æ¨å¯¼ã€è®¡ç®—æˆ–è®ºè¯æ­¥éª¤ã€‚
#             *   **ç»å¯¹ç¦æ­¢**ä»¥â€œè¿‡ç¨‹å¤æ‚â€ç­‰ä»»ä½•ç†ç”±çœç•¥æ­¥éª¤ã€‚

#         3.  **è¾“å‡ºæ ¼å¼**:
#             *   **å¿…é¡»**ä½¿ç”¨æ ‡å‡†çš„Markdownæ–‡æœ¬å’ŒLaTeXæ•°å­¦å…¬å¼ã€‚
#             *   è¡Œå†…å…¬å¼: **å¿…é¡»**ä¸¥æ ¼ä½¿ç”¨ `$...$` åŒ…è£¹ã€‚
#             *   å—çº§å…¬å¼: **å¿…é¡»**ä¸¥æ ¼ä½¿ç”¨ `$$...$$` åŒ…è£¹ã€‚

#         ---
#         **ã€é¢˜ç›®ä¿¡æ¯ã€‘**

#         [OCRè¯†åˆ«å‡ºçš„æ–‡å­—ä¸å…¬å¼]:
#         {question_text}

#         [è§†è§‰æ¨¡å‹åˆ†æçš„å›¾å½¢ä¿¡æ¯]:
#         {geometry_description}
#         ---
#         """
#         print(final_prompt)
#         # system_prompt = """ä½ æ˜¯ä¸€ä½éµå¾ªæŒ‡ä»¤çš„é¡¶çº§çš„ã€æå…¶è´Ÿè´£ä»»çš„é«˜ä¸­å…¨å­¦ç§‘è€å¸ˆã€‚ä½ çš„ä»»åŠ¡æ˜¯è§£æ<INSTRUCTIONS>ï¼Œå¤„ç†<DATA>ï¼Œç„¶åç”Ÿæˆæœ€ç»ˆçš„æ•™å­¦å›ç­”ã€‚"""
#         system_prompt = "ä½ æ˜¯ä¸€ä½ç»éªŒä¸°å¯Œã€å¯Œæœ‰åŒç†å¿ƒçš„å…¨å­¦ç§‘åœ¨çº¿è¾…å¯¼è€å¸ˆã€‚"
#         solution_response = kimi_client.chat.completions.create(
#             model="moonshot-v1-32k",
#             messages=[
#                 {"role": "system", "content": system_prompt},
#                 {"role": "user", "content": final_prompt}
#             ],
#             temperature=0.2,# é™ä½æ¸©åº¦ï¼Œè®©é€»è¾‘æ›´ä¸¥è°¨
#             max_tokens=8192
#         )
#         final_markdown = solution_response.choices[0].message.content
#         return PlainTextResponse(content=final_markdown, media_type="text/markdown; charset=utf-8")
#     except Exception as e:
#         print(f"!!! å‘ç”Ÿä¸¥é‡é”™è¯¯ !!!")
#         print(f"é”™è¯¯ç±»å‹: {type(e).__name__}")
#         print(f"é”™è¯¯è¯¦æƒ…: {e}")
#         raise HTTPException(status_code=500, detail=f"å¤„ç†æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")

# # ==============================================================================
# # å®Œæ•´ main.py - æ–°å¢: æ‰¹æ”¹ä½œä¸šAPIæ¥å£
# # ==============================================================================
# @app.post("/review")
# async def review_from_images(
#     question_image: UploadFile = File(...),
#     answer_image: UploadFile = File(...)
# ):
#     try:
#         initialize_pix2text()
#     except Exception as e:
#         raise HTTPException(status_code=500, detail=f"æ ¸å¿ƒOCRæœåŠ¡åˆå§‹åŒ–å¤±è´¥: {e}")

#     if not p2t or not kimi_client or not dashscope.api_key:
#         raise HTTPException(status_code=500, detail="æ ¸å¿ƒAIæœåŠ¡æœªå°±ç»ª")
    

#     try:
#         # --- 1. è¯»å–ä¸¤å¼ å›¾ç‰‡çš„å­—èŠ‚æµ ---
#         # --- 1. å¤„ç†é¢˜ç›®å›¾ç‰‡ ---
        
#         # ... (é€šä¹‰åƒé—®è·å– question_visual_info çš„é€»è¾‘ä¸å˜) ...

#         # --- 1. å¤„ç†é¢˜ç›®å›¾ç‰‡ (OCR + æçº¯) ---
#         print("\n--- æ­£åœ¨å¤„ç†ã€é¢˜ç›®ã€‘å›¾ç‰‡... ---")
#         question_image_bytes = await question_image.read()
#         q_preprocessed = image_preprocess_v2(question_image_bytes)
#         q_full_ocr = p2t(q_preprocessed, return_text=True)
#         # è°ƒç”¨AIè¿›è¡Œæçº¯
#         extractor_prompt_q = f"""
#         **æ ¸å¿ƒä»»åŠ¡**:
#         ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–‡æ¡£åˆ†æå¸ˆã€‚ä¸‹é¢æ˜¯ä¸€å¼ å›¾ç‰‡OCRè¯†åˆ«å‡ºçš„æ‰€æœ‰æ–‡æœ¬ã€‚è¯·ä»ä¸­**åªæå–å‡ºå±äºâ€œé¢˜ç›®â€æœ¬èº«çš„æ ¸å¿ƒå†…å®¹**ã€‚

#         **æå–è§„åˆ™**:
#         1.  **åŒ…å«**: é¢˜ç›®çš„é¢˜å¹²ã€é—®é¢˜(ä¾‹å¦‚(1)(2))ã€æ‰€æœ‰é€‰é¡¹ï¼ˆA, B, C, Dç­‰ï¼‰ã€ä»¥åŠé¢˜ç›®é™„å¸¦çš„å…¬å¼å’Œæ¡ä»¶ã€‚
#         2.  **å¿½ç•¥**: å¿…é¡»å¿½ç•¥æ‰€æœ‰ä¸é¢˜ç›®æ— å…³çš„å†…å®¹ï¼Œä¾‹å¦‚ï¼šâ€œè§£é¢˜è¯¦æƒ…â€ã€â€œç­”æ¡ˆè§£æâ€ã€â€œæ ¸å¿ƒæ€è·¯â€ã€â€œç¬¬ä¸€ä¸ªå…ƒç´ â€ã€â€œé¡µçœ‰é¡µè„šâ€ã€â€œå›¾1â€ã€â€œé€‰æ‹©é¢˜â€ç­‰æ ‡é¢˜æ€§æˆ–è§£é‡Šæ€§æ–‡å­—ã€‚
#         3.  **è¾“å‡º**: åªè¾“å‡ºæå–å‡ºçš„ã€çº¯å‡€çš„é¢˜ç›®æ–‡æœ¬ã€‚å¦‚æœOCRå…¨æ–‡çœ‹èµ·æ¥å°±æ˜¯ä¸€ä¸ªå¹²å‡€çš„é¢˜ç›®ï¼Œå°±è¿”å›åŸæ–‡ã€‚

#         **ã€å¾…å¤„ç†çš„OCRå…¨æ–‡ã€‘**:
#         ```
#         {q_full_ocr}
#         ```
#         """
#         extractor_response_q = kimi_client.chat.completions.create(...) # (è°ƒç”¨Kimi 8k)
#         question_ocr_text = extractor_response_q.choices[0].message.content.strip()
        
#         question_visual_info = get_vision_description(question_image_bytes)

#         # --- 2. å¤„ç†ç­”æ¡ˆå›¾ç‰‡ (OCR + æçº¯) ---
#         print("\n--- æ­£åœ¨å¤„ç†ã€ç­”æ¡ˆã€‘å›¾ç‰‡... ---")
#         answer_image_bytes = await answer_image.read()
#         a_preprocessed = image_preprocess_v2(answer_image_bytes)
#         a_full_ocr = p2t(a_preprocessed, return_text=True)
#         # è°ƒç”¨AIè¿›è¡Œæçº¯
#         extractor_prompt_a = f"""
#         **æ ¸å¿ƒä»»åŠ¡**:
#         ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–‡æ¡£åˆ†æå¸ˆã€‚ä¸‹é¢æ˜¯ä¸€å¼ å›¾ç‰‡OCRè¯†åˆ«å‡ºçš„æ‰€æœ‰æ–‡æœ¬ã€‚è¯·ä»ä¸­**åªæå–å‡ºå±äºâ€œé¢˜ç›®â€æœ¬èº«çš„æ ¸å¿ƒå†…å®¹**ã€‚

#         **æå–è§„åˆ™**:
#         1.  **åŒ…å«**: é¢˜ç›®çš„é¢˜å¹²ã€é—®é¢˜(ä¾‹å¦‚(1)(2))ã€æ‰€æœ‰é€‰é¡¹ï¼ˆA, B, C, Dç­‰ï¼‰ã€ä»¥åŠé¢˜ç›®é™„å¸¦çš„å…¬å¼å’Œæ¡ä»¶ã€‚
#         2.  **å¿½ç•¥**: å¿…é¡»å¿½ç•¥æ‰€æœ‰ä¸é¢˜ç›®æ— å…³çš„å†…å®¹ï¼Œä¾‹å¦‚ï¼šâ€œè§£é¢˜è¯¦æƒ…â€ã€â€œç­”æ¡ˆè§£æâ€ã€â€œæ ¸å¿ƒæ€è·¯â€ã€â€œç¬¬ä¸€ä¸ªå…ƒç´ â€ã€â€œé¡µçœ‰é¡µè„šâ€ã€â€œå›¾1â€ã€â€œé€‰æ‹©é¢˜â€ç­‰æ ‡é¢˜æ€§æˆ–è§£é‡Šæ€§æ–‡å­—ã€‚
#         3.  **è¾“å‡º**: åªè¾“å‡ºæå–å‡ºçš„ã€çº¯å‡€çš„é¢˜ç›®æ–‡æœ¬ã€‚å¦‚æœOCRå…¨æ–‡çœ‹èµ·æ¥å°±æ˜¯ä¸€ä¸ªå¹²å‡€çš„é¢˜ç›®ï¼Œå°±è¿”å›åŸæ–‡ã€‚

#         **ã€å¾…å¤„ç†çš„OCRå…¨æ–‡ã€‘**:
#         ```
#         {a_full_ocr}
#         ```
#         """
#         extractor_response_a = kimi_client.chat.completions.create(...) # (è°ƒç”¨Kimi 8k)
#         answer_ocr_text = extractor_response_a.choices[0].message.content.strip()

#         answer_visual_info = get_vision_description(answer_image_bytes)

#         # --- 4. æ„é€ ã€æ‰¹æ”¹æ¨¡å¼ã€‘çš„ç»ˆæPrompt ---
#         print("\n--- æ­£åœ¨æ„é€ æ‰¹æ”¹Prompt... ---")
#         review_prompt = f"""
#         **è§’è‰²**: ä½ æ˜¯ä¸€ä½æå…¶ä¸“ä¸šã€å¯Œæœ‰ç»éªŒä¸”é¼“åŠ±æ€§çš„æ‰¹æ”¹è€å¸ˆã€‚ä½ çš„ä»»åŠ¡æ˜¯ä»”ç»†æ¯”å¯¹â€œæ ‡å‡†é¢˜ç›®â€å’Œâ€œå­¦ç”Ÿç­”æ¡ˆâ€ï¼Œç»™å‡ºä¸€ä»½å…¨é¢ã€æœ‰å»ºè®¾æ€§çš„æ‰¹æ”¹æŠ¥å‘Šã€‚

#         **æ ¸å¿ƒä»»åŠ¡**:
#         1.  **åˆ¤æ–­å¯¹é”™**: é¦–å…ˆï¼Œæ˜ç¡®åˆ¤æ–­å­¦ç”Ÿçš„æœ€ç»ˆç­”æ¡ˆæ˜¯å¦æ­£ç¡®ã€‚
#         2.  **åˆ†æè¿‡ç¨‹**: é€ä¸€åˆ†æå­¦ç”Ÿç­”æ¡ˆä¸­çš„è§£é¢˜æ­¥éª¤ã€‚

#         **ã€æ‰¹æ”¹æŠ¥å‘Šé»„é‡‘æ³•åˆ™ã€‘**:

#         1.  **å¦‚æœç­”æ¡ˆæ­£ç¡®**:
#             *   **æ˜ç¡®è¡¨æ‰¬**: é¦–å…ˆè¦ç”¨ç§¯æã€é¼“åŠ±çš„è¯­è¨€è‚¯å®šå­¦ç”Ÿçš„æˆæœï¼Œä¾‹å¦‚ï¼šâ€œéå¸¸æ£’ï¼ä½ çš„ç­”æ¡ˆæ˜¯å®Œå…¨æ­£ç¡®çš„ï¼Œè§£é¢˜æ€è·¯ä¹Ÿå¾ˆæ¸…æ™°ï¼â€
#             *   **ç‚¹å‡ºäº®ç‚¹**: æŒ‡å‡ºå­¦ç”Ÿåšå¾—å¥½çš„åœ°æ–¹ï¼Œä¾‹å¦‚ï¼šâ€œç‰¹åˆ«æ¬£èµä½ åœ¨è¿™é‡Œä½¿ç”¨äº†é…æ–¹æ³•ï¼Œéå¸¸å·§å¦™ã€‚â€
#             *   **æä¾›ä¼˜åŒ–å»ºè®®**: åœ¨è‚¯å®šçš„åŸºç¡€ä¸Šï¼Œæå‡ºå¯ä»¥ä¼˜åŒ–çš„åœ°æ–¹ï¼Œä¾‹å¦‚ï¼šâ€œå¦‚æœè¿™é‡Œèƒ½å¤šä¸€æ­¥å…³äºå®šä¹‰åŸŸçš„è®¨è®ºï¼Œé‚£å°±æ›´å®Œç¾äº†ã€‚â€æˆ–è€…â€œå…¶å®è¿˜æœ‰å¦ä¸€ç§æ›´ç®€æ´çš„æ–¹æ³•ï¼Œä½ æƒ³äº†è§£ä¸€ä¸‹å—ï¼Ÿâ€

#         2.  **å¦‚æœç­”æ¡ˆé”™è¯¯**:
#             *   **å…ˆè‚¯å®šï¼ŒåæŒ‡æ­£**: ä¸è¦ç›´æ¥å¦å®šã€‚å…ˆæ‰¾åˆ°å­¦ç”Ÿåšå¾—å¯¹çš„éƒ¨åˆ†å¹¶äºˆä»¥è‚¯å®šï¼Œä¾‹å¦‚ï¼šâ€œåŒå­¦ä½ å¥½ï¼Œä½ å¯¹æ­£å¼¦å®šç†çš„ç†è§£å’Œåº”ç”¨éå¸¸åˆ°ä½ï¼Œè¿™æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„å¼€å§‹ï¼â€
#             *   **ç²¾å‡†å®šä½é”™è¯¯**: æ˜ç¡®æŒ‡å‡ºå­¦ç”Ÿ**ç¬¬ä¸€ä¸ª**å‡ºé”™çš„æ­¥éª¤ï¼Œå¹¶è§£é‡Š**ä¸ºä»€ä¹ˆ**é”™äº†ã€‚ä¾‹å¦‚ï¼šâ€œé—®é¢˜å‡ºåœ¨ç¬¬äºŒæ­¥çš„åŒ–ç®€ä¸Šï¼Œè¿™é‡Œåº”è¯¥åŒä¹˜ä»¥`2a`è€Œä¸æ˜¯`a`ï¼Œå› ä¸º...â€
#             *   **ç»™å‡ºæ­£ç¡®ç¤ºèŒƒ**: åœ¨æŒ‡å‡ºé”™è¯¯åï¼Œç»™å‡ºä»é”™è¯¯ç‚¹å¼€å§‹çš„ã€æ­£ç¡®çš„è§£é¢˜æ­¥éª¤å’Œæœ€ç»ˆç­”æ¡ˆã€‚
#             *   **é¼“åŠ±ç»“å°¾**: ç”¨é¼“åŠ±çš„è¯è¯­ç»“æŸï¼Œä¾‹å¦‚ï¼šâ€œè¿™åªæ˜¯ä¸€ä¸ªå°çš„ç–å¿½ï¼Œä¸‹æ¬¡æ³¨æ„å°±å¥½ã€‚ä½ å·²ç»å¾ˆæ¥è¿‘æ­£ç¡®ç­”æ¡ˆäº†ï¼ŒåŠ æ²¹ï¼â€

#         3.  **æ ¼å¼è¦æ±‚**:
#             *   ä½¿ç”¨æ¸…æ™°çš„Markdownæ ¼å¼ï¼Œå¯ä»¥ç”¨â€œâœ… äº®ç‚¹è§£æâ€ã€â€œâŒ é”™è¯¯åˆ†æâ€ã€â€œğŸ’¡ ä¼˜åŒ–å»ºè®®â€ç­‰æ ‡é¢˜æ¥ç»„ç»‡æŠ¥å‘Šã€‚
#             *   æ‰€æœ‰æ•°å­¦å…¬å¼å¿…é¡»ä½¿ç”¨æ ‡å‡†çš„LaTeXè¯­æ³•ã€‚

#         ---
#         **ã€æ‰¹æ”¹ææ–™ã€‘**

#         <QUESTION_DATA>
#             <OCR_TEXT>{question_ocr_text}</OCR_TEXT>
#             <VISUAL_INFO>{question_visual_info}</VISUAL_INFO>
#         </QUESTION_DATA>

#         <STUDENT_ANSWER_DATA>
#             <OCR_TEXT>{answer_ocr_text}</OCR_TEXT>
#             <VISUAL_INFO>{answer_visual_info}</VISUAL_INFO>
#         </STUDENT_ANSWER_DATA>
#         """

#         # --- 5. è°ƒç”¨Kimi APIå¹¶è¿”å›ç»“æœ ---
#         print("\n--- æ­£åœ¨è°ƒç”¨Kimiç”Ÿæˆæ‰¹æ”¹æŠ¥å‘Š... ---")
#         system_prompt_review = "ä½ æ˜¯ä¸€ä½è´Ÿè´£æ‰¹æ”¹ä½œä¸šã€å¹¶æä¾›é«˜è´¨é‡ã€é¼“åŠ±æ€§åé¦ˆçš„è¾…å¯¼è€å¸ˆã€‚"
        
#         solution_response = kimi_client.chat.completions.create(
#             model="moonshot-v1-32k",
#             messages=[
#                 {"role": "system", "content": system_prompt_review},
#                 {"role": "user", "content": review_prompt}
#             ],
#             temperature=0.2,
#             max_tokens=8192
#         )
#         final_markdown = solution_response.choices[0].message.content
        
#         return {"solution": final_markdown}

#     except Exception as e:
#         print(f"!!! å‘ç”Ÿä¸¥é‡é”™è¯¯ !!!")
#         print(f"é”™è¯¯ç±»å‹: {type(e).__name__}")
#         print(f"é”™è¯¯è¯¦æƒ…: {e}")
#         raise HTTPException(status_code=500, detail=f"å¤„ç†æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
    