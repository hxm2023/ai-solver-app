# ==============================================================================
# question_splitter.py - ã€V24.2 ç»“æ„åŒ–å¸ƒå±€åˆ†æç‰ˆã€‘
# æ ¸å¿ƒç­–ç•¥ï¼šä»"åƒç´ èšåˆ"åˆ°"ç»“æ„åŒ–å¸ƒå±€åˆ†æ"
# ä¸‰æ­¥èµ°ï¼šå¼ºåŠ›èšåˆ â†’ é¢˜å·æ£€æµ‹ â†’ ç²¾ç»†å½’å±
# ==============================================================================

import cv2
import numpy as np
from PIL import Image
from typing import List, Tuple
import re


def pil_to_cv2(pil_img: Image.Image) -> np.ndarray:
    """å°†PIL Imageå¯¹è±¡è½¬æ¢ä¸ºOpenCVæ ¼å¼ (BGR)"""
    if pil_img.mode != 'RGB':
        pil_img = pil_img.convert('RGB')
    return cv2.cvtColor(np.array(pil_img), cv2.COLOR_RGB2BGR)


def cv2_to_pil(cv_img: np.ndarray) -> Image.Image:
    """å°†OpenCVæ ¼å¼ (BGR) è½¬æ¢ä¸ºPIL Imageå¯¹è±¡"""
    return Image.fromarray(cv2.cvtColor(cv_img, cv2.COLOR_BGR2RGB))


# ==============================================================================
# ç¬¬ä¸€æ­¥ï¼šå¼ºåŠ›åŒºå—èšåˆ
# ==============================================================================

def coarse_graining(binary: np.ndarray, img_width: int, img_height: int, 
                    min_question_height: int = 50) -> List[Tuple[int, int, int, int]]:
    """
    ã€V24.2 - æ­¥éª¤1ã€‘å¼ºåŠ›åŒºå—èšåˆ (Coarse Graining)
    
    ç­–ç•¥ï¼šå®å¯é”™åˆ†åˆ°ä¸€èµ·ï¼Œä¹Ÿä¸è¦æ‹†å¼€
    - ä½¿ç”¨å¤§èŒƒå›´çš„æ°´å¹³è†¨èƒ€ï¼Œå¼ºåˆ¶è¿æ¥åŒä¸€è¡Œçš„æ‰€æœ‰å…ƒç´ 
    - ä½¿ç”¨é€‚åº¦çš„å‚ç›´è†¨èƒ€ï¼Œè¿æ¥å‚ç›´ç›¸é‚»çš„å†…å®¹
    - å¾—åˆ°å‡ ä¸ªå¤§çš„"å€™é€‰åŒºå—"ï¼Œæ¯ä¸ªå¯èƒ½åŒ…å«1-Né“é¢˜
    
    å‚æ•°:
        binary: äºŒå€¼åŒ–å›¾åƒ
        img_width, img_height: å›¾ç‰‡å°ºå¯¸
        min_question_height: æœ€å°é¢˜ç›®é«˜åº¦
    
    è¿”å›:
        ç²—ç²’åº¦åŒºå—åˆ—è¡¨ [(x, y, w, h), ...]
    """
    print(f"\n[æ­¥éª¤1/3] ğŸ”¥ å¼ºåŠ›åŒºå—èšåˆ...")
    
    # 1.1 å¼ºåŠ›æ°´å¹³è†¨èƒ€ - è¿æ¥åŒä¸€è¡Œçš„æ‰€æœ‰å…ƒç´ 
    # ä½¿ç”¨ä¸€ä¸ªéå¸¸å®½çš„æ°´å¹³æ ¸ï¼ˆ100åƒç´ å®½ï¼‰
    horizontal_kernel = np.ones((1, 100), np.uint8)
    dilated_h = cv2.dilate(binary, horizontal_kernel, iterations=2)
    print(f"  âœ“ æ°´å¹³è†¨èƒ€å®Œæˆï¼ˆæ ¸å¤§å°: 1x100, è¿­ä»£2æ¬¡ï¼‰")
    
    # 1.2 é€‚åº¦å‚ç›´è†¨èƒ€ - è¿æ¥å‚ç›´ç›¸é‚»çš„æ®µè½
    # ä½¿ç”¨ä¸€ä¸ªè¾ƒçª„çš„å‚ç›´æ ¸ï¼ˆ10åƒç´ é«˜ï¼‰
    vertical_kernel = np.ones((10, 1), np.uint8)
    dilated_full = cv2.dilate(dilated_h, vertical_kernel, iterations=3)
    print(f"  âœ“ å‚ç›´è†¨èƒ€å®Œæˆï¼ˆæ ¸å¤§å°: 10x1, è¿­ä»£3æ¬¡ï¼‰")
    
    # 1.3 æ£€æµ‹è½®å»“ï¼Œå¾—åˆ°å¤§çš„å€™é€‰åŒºå—
    contours, _ = cv2.findContours(dilated_full, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    print(f"  âœ“ æ£€æµ‹åˆ° {len(contours)} ä¸ªè½®å»“")
    
    # 1.4 è¿‡æ»¤ï¼Œä¿ç•™æœ‰æ•ˆçš„å€™é€‰åŒºå—
    coarse_boxes = []
    for contour in contours:
        x, y, w, h = cv2.boundingRect(contour)
        # å®½æ¾çš„è¿‡æ»¤æ¡ä»¶ï¼šå®½åº¦>20%ï¼Œé«˜åº¦>æœ€å°å€¼
        if w > img_width * 0.2 and h > min_question_height:
            coarse_boxes.append((x, y, w, h))
    
    coarse_boxes.sort(key=lambda b: b[1])  # ä»ä¸Šåˆ°ä¸‹æ’åº
    
    print(f"  âœ“ è¿‡æ»¤åä¿ç•™ {len(coarse_boxes)} ä¸ªç²—ç²’åº¦åŒºå—")
    print(f"[æ­¥éª¤1/3] âœ… å¼ºåŠ›èšåˆå®Œæˆ\n")
    
    return coarse_boxes


# ==============================================================================
# ç¬¬äºŒæ­¥ï¼šç»“æ„åŒ–åˆ†æä¸é¢˜å·æ£€æµ‹
# ==============================================================================

def find_all_text_blocks(binary: np.ndarray, min_area: int = 50) -> List[Tuple[int, int, int, int]]:
    """
    ã€V24.2 - æ­¥éª¤2è¾…åŠ©ã€‘åœ¨åŸå§‹äºŒå€¼å›¾ä¸Šæ‰¾åˆ°æ‰€æœ‰ç»†ç²’åº¦çš„æ–‡æœ¬å—
    
    è¿™äº›æ–‡æœ¬å—æ˜¯æœ€å°çš„å•å…ƒï¼Œåç»­ä¼šå°†å®ƒä»¬èšç±»åˆ°é¢˜ç›®ä¸­
    """
    # ä½¿ç”¨å°çš„è†¨èƒ€è¿æ¥å•ä¸ªå•è¯å†…çš„å­—ç¬¦
    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (10, 3))
    dilated = cv2.dilate(binary, kernel, iterations=1)
    
    contours, _ = cv2.findContours(dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    blocks = []
    for contour in contours:
        if cv2.contourArea(contour) > min_area:
            blocks.append(cv2.boundingRect(contour))
    
    return blocks


def detect_question_number_candidates(binary: np.ndarray, img_width: int, 
                                      coarse_boxes: List[Tuple[int, int, int, int]]) -> List[Tuple[int, int]]:
    """
    ã€V24.2 - æ­¥éª¤2ã€‘æ£€æµ‹é¢˜å·å€™é€‰ä½ç½®
    
    ç­–ç•¥ï¼š
    1. åœ¨æ¯ä¸ªç²—ç²’åº¦åŒºå—çš„å·¦ä¾§åŒºåŸŸå¯»æ‰¾å°çš„ã€ç±»ä¼¼é¢˜å·çš„è½®å»“
    2. ä½¿ç”¨å¯å‘å¼è§„åˆ™åˆ¤æ–­ï¼ˆä½ç½®ã€å°ºå¯¸ã€å½¢çŠ¶ï¼‰
    3. ä¸ä¾èµ–OCRï¼Œä»…ç”¨å‡ ä½•ç‰¹å¾
    
    è¿”å›:
        é¢˜å·å€™é€‰ä½ç½®åˆ—è¡¨ [(x, y), ...]ï¼ŒæŒ‰yåæ ‡æ’åº
    """
    print(f"[æ­¥éª¤2/3] ğŸ” æ£€æµ‹é¢˜å·é”šç‚¹...")
    
    # ä½¿ç”¨æ¸©å’Œè†¨èƒ€æ‰¾åˆ°å°çš„æ–‡æœ¬å—
    kernel = np.ones((3, 3), np.uint8)
    dilated = cv2.dilate(binary, kernel, iterations=1)
    
    contours, _ = cv2.findContours(dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    candidates = []
    
    for contour in contours:
        x, y, w, h = cv2.boundingRect(contour)
        
        # å¯å‘å¼è§„åˆ™1ï¼šä½äºé¡µé¢å·¦ä¾§ï¼ˆå·¦20%åŒºåŸŸï¼‰
        if x > img_width * 0.2:
            continue
        
        # å¯å‘å¼è§„åˆ™2ï¼šå°ºå¯¸åˆç†ï¼ˆé¢˜å·é€šå¸¸ä¸ä¼šå¤ªå¤§ï¼‰
        if w > 150 or h > 100 or w < 10 or h < 10:
            continue
        
        # å¯å‘å¼è§„åˆ™3ï¼šå®½é«˜æ¯”åˆç†ï¼ˆé¢˜å·é€šå¸¸æ˜¯å°æ–¹å—æˆ–ç•¥å®½ï¼‰
        aspect_ratio = w / h if h > 0 else 0
        if aspect_ratio > 5 or aspect_ratio < 0.2:
            continue
        
        # å¯å‘å¼è§„åˆ™4ï¼šå¿…é¡»åœ¨æŸä¸ªç²—ç²’åº¦åŒºå—å†…
        is_in_coarse = any(
            cb[0] <= x < cb[0] + cb[2] and cb[1] <= y < cb[1] + cb[3]
            for cb in coarse_boxes
        )
        if not is_in_coarse:
            continue
        
        candidates.append((x, y))
    
    # æŒ‰yåæ ‡æ’åºï¼Œå»é‡ï¼ˆç›¸è¿‘çš„yåæ ‡åªä¿ç•™ä¸€ä¸ªï¼‰
    candidates.sort(key=lambda c: c[1])
    
    # å»é‡ï¼šå¦‚æœä¸¤ä¸ªå€™é€‰ä½ç½®çš„yåæ ‡ç›¸å·®å°äº30åƒç´ ï¼Œåªä¿ç•™ç¬¬ä¸€ä¸ª
    deduplicated = []
    for i, (x, y) in enumerate(candidates):
        if i == 0 or y - deduplicated[-1][1] > 30:
            deduplicated.append((x, y))
    
    print(f"  âœ“ æ£€æµ‹åˆ° {len(deduplicated)} ä¸ªé¢˜å·é”šç‚¹å€™é€‰ä½ç½®")
    print(f"[æ­¥éª¤2/3] âœ… é¢˜å·æ£€æµ‹å®Œæˆ\n")
    
    return deduplicated


# ==============================================================================
# ç¬¬ä¸‰æ­¥ï¼šåŸºäºé”šç‚¹çš„ç²¾ç»†åŒ–åˆ†å‰²
# ==============================================================================

def segment_by_anchors(binary: np.ndarray, 
                      all_blocks: List[Tuple[int, int, int, int]],
                      anchor_points: List[Tuple[int, int]],
                      img_width: int, img_height: int) -> List[Tuple[int, int, int, int]]:
    """
    ã€V24.2 - æ­¥éª¤3ã€‘åŸºäºé¢˜å·é”šç‚¹è¿›è¡Œç²¾ç»†åŒ–åˆ†å‰²
    
    ç­–ç•¥ï¼š
    1. ä»¥æ¯ä¸ªé¢˜å·çš„yåæ ‡ä¸ºèµ·ç‚¹
    2. åˆ°ä¸‹ä¸€ä¸ªé¢˜å·çš„yåæ ‡ä¸ºç»ˆç‚¹ï¼ˆæˆ–å›¾ç‰‡åº•éƒ¨ï¼‰
    3. åœ¨è¿™ä¸ªå‚ç›´èŒƒå›´å†…ï¼Œæ‰¾åˆ°æ‰€æœ‰å†…å®¹çš„æœ€å°å¤–æ¥çŸ©å½¢
    
    å‚æ•°:
        binary: äºŒå€¼å›¾
        all_blocks: æ‰€æœ‰ç»†ç²’åº¦æ–‡æœ¬å—
        anchor_points: é¢˜å·é”šç‚¹ä½ç½®
        img_width, img_height: å›¾ç‰‡å°ºå¯¸
    
    è¿”å›:
        ç²¾ç»†åŒ–çš„é¢˜ç›®æ¡†åˆ—è¡¨
    """
    print(f"[æ­¥éª¤3/3] âœ‚ï¸ åŸºäºé”šç‚¹ç²¾ç»†åŒ–åˆ†å‰²...")
    
    if not anchor_points:
        print(f"  âš ï¸ æ— é¢˜å·é”šç‚¹ï¼Œé€€åŒ–ä¸ºå…¨å›¾å•é¢˜")
        if not all_blocks:
            return [(0, 0, img_width, img_height)]
        
        # è®¡ç®—æ‰€æœ‰æ–‡æœ¬å—çš„è”åˆè¾¹ç•Œæ¡†
        x_coords = [b[0] for b in all_blocks]
        y_coords = [b[1] for b in all_blocks]
        x2_coords = [b[0] + b[2] for b in all_blocks]
        y2_coords = [b[1] + b[3] for b in all_blocks]
        
        min_x = max(0, min(x_coords) - 20)
        min_y = max(0, min(y_coords) - 20)
        max_x = min(img_width, max(x2_coords) + 20)
        max_y = min(img_height, max(y2_coords) + 20)
        
        return [(min_x, min_y, max_x - min_x, max_y - min_y)]
    
    final_boxes = []
    
    for i, (anchor_x, anchor_y) in enumerate(anchor_points):
        # ç¡®å®šå½“å‰é¢˜ç›®çš„å‚ç›´èŒƒå›´
        y_start = anchor_y
        y_end = anchor_points[i + 1][1] if i + 1 < len(anchor_points) else img_height
        
        # åœ¨å‚ç›´èŒƒå›´å†…è£å‰ªå›¾åƒ
        strip = binary[y_start:y_end, :]
        
        # æ‰¾åˆ°è¿™ä¸ªæ¡å¸¦å†…çš„æ‰€æœ‰å†…å®¹
        strip_contours, _ = cv2.findContours(strip, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        if not strip_contours:
            continue
        
        # è®¡ç®—æ‰€æœ‰è½®å»“çš„è”åˆè¾¹ç•Œæ¡†
        min_x = img_width
        max_x = 0
        min_y_relative = strip.shape[0]
        max_y_relative = 0
        
        for contour in strip_contours:
            x, y, w, h = cv2.boundingRect(contour)
            min_x = min(min_x, x)
            max_x = max(max_x, x + w)
            min_y_relative = min(min_y_relative, y)
            max_y_relative = max(max_y_relative, y + h)
        
        # è½¬æ¢ä¸ºç»å¯¹åæ ‡ï¼Œæ·»åŠ padding
        padding = 20
        box_x = max(0, min_x - padding)
        box_y = max(0, y_start + min_y_relative - padding)
        box_w = min(img_width - box_x, max_x - min_x + 2 * padding)
        box_h = min(img_height - box_y, max_y_relative - min_y_relative + 2 * padding)
        
        final_boxes.append((box_x, box_y, box_w, box_h))
    
    print(f"  âœ“ åŸºäº {len(anchor_points)} ä¸ªé”šç‚¹ç”Ÿæˆäº† {len(final_boxes)} ä¸ªé¢˜ç›®æ¡†")
    print(f"[æ­¥éª¤3/3] âœ… ç²¾ç»†åŒ–åˆ†å‰²å®Œæˆ\n")
    
    return final_boxes


# ==============================================================================
# åå¤„ç†ï¼šä¿å®ˆåˆå¹¶
# ==============================================================================

def conservative_merge(boxes: List[Tuple[int, int, int, int]], 
                       img_height: int, 
                       max_gap: int = None) -> List[Tuple[int, int, int, int]]:
    """
    ã€V24.2 - åå¤„ç†ã€‘ä¿å®ˆçš„æœ€ç»ˆåˆå¹¶
    
    åªåˆå¹¶é‚£äº›å‚ç›´é—´è·éå¸¸å°ï¼ˆ<2%å›¾ç‰‡é«˜åº¦ï¼‰ä¸”æœ‰æ°´å¹³é‡å çš„æ¡†
    """
    if not boxes or len(boxes) <= 1:
        return boxes
    
    if max_gap is None:
        max_gap = int(img_height * 0.02)  # é»˜è®¤2%
    
    boxes.sort(key=lambda b: b[1])
    merged = []
    current = list(boxes[0])
    
    for next_box in boxes[1:]:
        gap = next_box[1] - (current[1] + current[3])
        
        # è®¡ç®—æ°´å¹³é‡å 
        h_overlap = max(0, min(current[0] + current[2], next_box[0] + next_box[2]) - 
                       max(current[0], next_box[0]))
        
        if gap < max_gap and h_overlap > 0:
            # åˆå¹¶
            new_x = min(current[0], next_box[0])
            new_y = min(current[1], next_box[1])
            new_x2 = max(current[0] + current[2], next_box[0] + next_box[2])
            new_y2 = max(current[1] + current[3], next_box[1] + next_box[3])
            
            current = [new_x, new_y, new_x2 - new_x, new_y2 - new_y]
        else:
            merged.append(tuple(current))
            current = list(next_box)
    
    merged.append(tuple(current))
    return merged


# ==============================================================================
# ä¸»å‡½æ•°ï¼šæ•´åˆä¸‰æ­¥èµ°ç­–ç•¥
# ==============================================================================

def find_question_boxes(image: Image.Image, 
                       min_question_height: int = 50,
                       use_anchor_based: bool = True) -> List[Tuple[int, int, int, int]]:
    """
    ã€V24.2 ç»“æ„åŒ–å¸ƒå±€åˆ†æç‰ˆã€‘
    
    æ ¸å¿ƒç­–ç•¥ï¼š
    1. å¼ºåŠ›åŒºå—èšåˆ - å®å¯åˆé”™ï¼Œä¸å¯æ‹†æ•£
    2. é¢˜å·é”šç‚¹æ£€æµ‹ - æ‰¾åˆ°é¢˜ç›®çš„"é‡å¿ƒ"
    3. ç²¾ç»†åŒ–åˆ†å‰² - åŸºäºé”šç‚¹å½’å±å†…å®¹
    
    å‚æ•°:
        image: PILæ ¼å¼è¾“å…¥å›¾åƒ
        min_question_height: æœ€å°é¢˜ç›®é«˜åº¦
        use_anchor_based: æ˜¯å¦ä½¿ç”¨åŸºäºé”šç‚¹çš„ç²¾ç»†åˆ†å‰²
    
    è¿”å›:
        é¢˜ç›®è¾¹ç•Œæ¡†åˆ—è¡¨ [(x, y, w, h), ...]
    """
    print(f"\n{'='*80}")
    print(f"[é¢˜ç›®åˆ†å‰²å™¨ V24.2] ğŸš€ ç»“æ„åŒ–å¸ƒå±€åˆ†æå¼€å§‹...")
    print(f"{'='*80}\n")
    
    # ===== å‡†å¤‡å·¥ä½œ =====
    cv_image = pil_to_cv2(image)
    img_height, img_width = cv_image.shape[:2]
    print(f"ğŸ“ å›¾ç‰‡å°ºå¯¸: {img_width}x{img_height}")
    
    # ç°åº¦åŒ–
    gray = cv2.cvtColor(cv_image, cv2.COLOR_BGR2GRAY)
    
    # è‡ªé€‚åº”äºŒå€¼åŒ–
    binary = cv2.adaptiveThreshold(
        ~gray, 255, 
        cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
        cv2.THRESH_BINARY, 
        15, -10
    )
    print(f"âœ“ é¢„å¤„ç†å®Œæˆï¼ˆç°åº¦åŒ– + äºŒå€¼åŒ–ï¼‰\n")
    
    # ===== æ­¥éª¤1: å¼ºåŠ›åŒºå—èšåˆ =====
    coarse_boxes = coarse_graining(binary, img_width, img_height, min_question_height)
    
    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ç²—ç²’åº¦åŒºå—ï¼Œæ•´å¼ å›¾ä½œä¸ºä¸€é¢˜
    if not coarse_boxes:
        print(f"âš ï¸ æœªæ£€æµ‹åˆ°æœ‰æ•ˆåŒºå—ï¼Œè¿”å›å…¨å›¾")
        return [(0, 0, img_width, img_height)]
    
    # å¦‚æœåªæœ‰ä¸€ä¸ªç²—ç²’åº¦åŒºå—ï¼Œå¯èƒ½å°±æ˜¯ä¸€é“é¢˜
    if len(coarse_boxes) == 1 and not use_anchor_based:
        print(f"â„¹ï¸ ä»…ä¸€ä¸ªåŒºå—ä¸”æœªå¯ç”¨é”šç‚¹åˆ†å‰²ï¼Œç›´æ¥è¿”å›")
        return coarse_boxes
    
    # ===== æ­¥éª¤2: é¢˜å·é”šç‚¹æ£€æµ‹ =====
    anchor_points = detect_question_number_candidates(binary, img_width, coarse_boxes)
    
    # ===== æ­¥éª¤3: åŸºäºé”šç‚¹çš„ç²¾ç»†åŒ–åˆ†å‰² =====
    if use_anchor_based and anchor_points:
        all_text_blocks = find_all_text_blocks(binary)
        print(f"ğŸ“ æ£€æµ‹åˆ° {len(all_text_blocks)} ä¸ªç»†ç²’åº¦æ–‡æœ¬å—\n")
        
        final_boxes = segment_by_anchors(binary, all_text_blocks, anchor_points, 
                                         img_width, img_height)
    else:
        print(f"â„¹ï¸ è·³è¿‡é”šç‚¹åˆ†å‰²ï¼Œä½¿ç”¨ç²—ç²’åº¦åŒºå—\n")
        final_boxes = coarse_boxes
    
    # ===== åå¤„ç†: ä¿å®ˆåˆå¹¶ =====
    if len(final_boxes) > 1:
        before_merge = len(final_boxes)
        final_boxes = conservative_merge(final_boxes, img_height)
        print(f"ğŸ”— ä¿å®ˆåˆå¹¶: {before_merge} â†’ {len(final_boxes)} ä¸ªé¢˜ç›®æ¡†\n")
    
    # ===== æ’åºå¹¶è¿”å› =====
    final_boxes.sort(key=lambda b: b[1])
    
    print(f"{'='*80}")
    print(f"âœ… [é¢˜ç›®åˆ†å‰²å™¨ V24.2] æœ€ç»ˆæ£€æµ‹åˆ° {len(final_boxes)} ä¸ªé¢˜ç›®åŒºåŸŸ")
    print(f"{'='*80}\n")
    
    return final_boxes


# ==============================================================================
# å¯è§†åŒ–è°ƒè¯•
# ==============================================================================

def visualize_detected_boxes(image: Image.Image, 
                            boxes: List[Tuple[int, int, int, int]], 
                            output_path: str = "debug_boxes.png",
                            show_labels: bool = True):
    """
    ã€V24.2ã€‘å¯è§†åŒ–è°ƒè¯•ï¼šç»˜åˆ¶æ£€æµ‹åˆ°çš„è¾¹ç•Œæ¡†
    """
    cv_image = pil_to_cv2(image)
    
    for i, (x, y, w, h) in enumerate(boxes):
        # ç»˜åˆ¶çŸ©å½¢
        color = (0, 255, 0) if i % 2 == 0 else (0, 200, 255)  # äº¤æ›¿é¢œè‰²
        cv2.rectangle(cv_image, (x, y), (x + w, y + h), color, 4)
        
        if show_labels:
            # ç»˜åˆ¶é¢˜å·æ ‡ç­¾
            label = f"Q{i+1}"
            font_scale = 1.2
            thickness = 3
            (tw, th), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, font_scale, thickness)
            
            # ç™½è‰²èƒŒæ™¯
            cv2.rectangle(cv_image, (x + 10, y + 10), (x + tw + 30, y + th + 30), (255, 255, 255), -1)
            # çº¢è‰²æ–‡å­—
            cv2.putText(cv_image, label, (x + 20, y + th + 20), 
                       cv2.FONT_HERSHEY_SIMPLEX, font_scale, (0, 0, 255), thickness)
    
    # æ·»åŠ æ ‡é¢˜
    title = f"V24.2: {len(boxes)} Questions Detected"
    cv2.putText(cv_image, title, (20, 40), 
               cv2.FONT_HERSHEY_SIMPLEX, 1.0, (255, 255, 255), 3)
    cv2.putText(cv_image, title, (20, 40), 
               cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 0, 255), 2)
    
    cv2.imwrite(output_path, cv_image)
    print(f"ğŸ“¸ [è°ƒè¯•] å¯è§†åŒ–å›¾ç‰‡å·²ä¿å­˜: {output_path}")

