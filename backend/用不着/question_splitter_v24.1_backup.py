# ==============================================================================
# question_splitter.py - ã€V24.0 é¢˜ç›®è‡ªåŠ¨åˆ†å‰²æ¨¡å—ã€‘
# åŠŸèƒ½ï¼šä½¿ç”¨OpenCVè®¡ç®—æœºè§†è§‰æŠ€æœ¯æ£€æµ‹å›¾ç‰‡ä¸­çš„å¤šä¸ªé¢˜ç›®åŒºåŸŸå¹¶åˆ†å‰²
# ==============================================================================

import cv2
import numpy as np
from PIL import Image
from typing import List, Tuple


def pil_to_cv2(pil_img: Image.Image) -> np.ndarray:
    """å°†PIL Imageå¯¹è±¡è½¬æ¢ä¸ºOpenCVæ ¼å¼ (BGR)"""
    if pil_img.mode != 'RGB':
        pil_img = pil_img.convert('RGB')
    return cv2.cvtColor(np.array(pil_img), cv2.COLOR_RGB2BGR)


def find_question_boxes(image: Image.Image, min_question_height: int = 50, use_projection: bool = True) -> List[Tuple[int, int, int, int]]:
    """
    åœ¨å›¾ç‰‡ä¸­æ£€æµ‹å¹¶è¿”å›æ¯é“é¢˜ç›®çš„è¾¹ç•Œæ¡† (bounding boxes)ã€‚
    
    ã€V24.1ä¼˜åŒ–ã€‘æ”¹è¿›ç´§å¯†æ’åˆ—é¢˜ç›®çš„è¯†åˆ«èƒ½åŠ›
    
    ç®—æ³•æµç¨‹ï¼š
    1. å›¾åƒé¢„å¤„ç†ï¼ˆç°åº¦åŒ–ã€äºŒå€¼åŒ–ï¼‰
    2. ã€æ–°å¢ã€‘æ°´å¹³æŠ•å½±åˆ†å‰²æ³•ï¼ˆé’ˆå¯¹ç´§å¯†æ’åˆ—ï¼‰
    3. å½¢æ€å­¦æ“ä½œï¼ˆè†¨èƒ€ï¼‰è¿æ¥æ–‡æœ¬åŒºåŸŸ
    4. è½®å»“æ£€æµ‹æ‰¾åˆ°ç‹¬ç«‹åŒºå—
    5. æ™ºèƒ½è¿‡æ»¤å’Œåˆå¹¶
    6. ä»ä¸Šåˆ°ä¸‹æ’åº
    
    å‚æ•°:
        image: PILæ ¼å¼çš„è¾“å…¥å›¾åƒ
        min_question_height: æœ€å°é¢˜ç›®é«˜åº¦ï¼ˆåƒç´ ï¼‰ï¼Œç”¨äºè¿‡æ»¤å™ªç‚¹
        use_projection: æ˜¯å¦ä½¿ç”¨æ°´å¹³æŠ•å½±è¾…åŠ©åˆ†å‰²ï¼ˆé’ˆå¯¹ç´§å¯†é¢˜ç›®ï¼‰
    
    è¿”å›:
        ä¸€ä¸ªå…ƒç»„åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç»„ä»£è¡¨ä¸€ä¸ªé¢˜ç›®çš„ (x, y, w, h) åæ ‡ã€‚
        åˆ—è¡¨æŒ‰ä»ä¸Šåˆ°ä¸‹çš„é¡ºåºæ’åºã€‚
    """
    print(f"\n{'='*70}")
    print(f"[é¢˜ç›®åˆ†å‰²å™¨] ğŸ” å¼€å§‹æ™ºèƒ½æ£€æµ‹é¢˜ç›®åŒºåŸŸ...")
    print(f"{'='*70}")
    
    cv_image = pil_to_cv2(image)
    img_height, img_width = cv_image.shape[:2]
    print(f"[é¢˜ç›®åˆ†å‰²å™¨] å›¾ç‰‡å°ºå¯¸: {img_width}x{img_height}")
    
    # 1. å›¾åƒé¢„å¤„ç† - è½¬ç°åº¦
    gray = cv2.cvtColor(cv_image, cv2.COLOR_BGR2GRAY)
    print("[é¢˜ç›®åˆ†å‰²å™¨] âœ“ ç°åº¦åŒ–å®Œæˆ")
    
    # 2. è‡ªé€‚åº”äºŒå€¼åŒ– - å¯¹æŠ—å…‰ç…§ä¸å‡
    binary = cv2.adaptiveThreshold(
        ~gray, 255, 
        cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
        cv2.THRESH_BINARY, 
        15,
        -10
    )
    print("[é¢˜ç›®åˆ†å‰²å™¨] âœ“ è‡ªé€‚åº”äºŒå€¼åŒ–å®Œæˆ")
    
    # ã€V24.1æ–°å¢ã€‘3. æ°´å¹³æŠ•å½±åˆ†å‰²æ³• - é’ˆå¯¹ç´§å¯†æ’åˆ—é¢˜ç›®
    projection_split_lines = []
    if use_projection:
        projection_split_lines = find_split_lines_by_projection(binary, img_height, min_gap=20)
        print(f"[é¢˜ç›®åˆ†å‰²å™¨] âœ“ æ°´å¹³æŠ•å½±æ£€æµ‹åˆ° {len(projection_split_lines)} ä¸ªæ½œåœ¨åˆ†å‰²çº¿")
    
    # 4. å½¢æ€å­¦è†¨èƒ€æ“ä½œ - å‡å°‘è†¨èƒ€å¼ºåº¦ï¼Œé¿å…è¿‡åº¦è¿æ¥
    # ã€V24.1ä¼˜åŒ–ã€‘é™ä½è†¨èƒ€è¿­ä»£æ¬¡æ•°
    kernel_horizontal = np.ones((2, 10), np.uint8)  # ä»(3,15)é™ä½åˆ°(2,10)
    kernel_vertical = np.ones((3, 2), np.uint8)     # ä»(5,3)é™ä½åˆ°(3,2)
    
    dilated = cv2.dilate(binary, kernel_horizontal, iterations=1)  # ä»2é™ä½åˆ°1
    dilated = cv2.dilate(dilated, kernel_vertical, iterations=2)    # ä»3é™ä½åˆ°2
    print("[é¢˜ç›®åˆ†å‰²å™¨] âœ“ å½¢æ€å­¦è†¨èƒ€å®Œæˆï¼ˆæ¸©å’Œæ¨¡å¼ï¼‰")
    
    # 5. å¯»æ‰¾è½®å»“
    contours, _ = cv2.findContours(dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    print(f"[é¢˜ç›®åˆ†å‰²å™¨] âœ“ æ£€æµ‹åˆ° {len(contours)} ä¸ªåŸå§‹è½®å»“")
    
    # 6. è¿‡æ»¤è½®å»“ï¼Œæå–æœ‰æ•ˆçš„é¢˜ç›®æ¡†
    raw_boxes = []
    for contour in contours:
        x, y, w, h = cv2.boundingRect(contour)
        
        # ã€V24.1ä¼˜åŒ–ã€‘æ”¾å®½è¿‡æ»¤æ¡ä»¶ï¼Œé¿å…é—æ¼
        # å®½åº¦ï¼šä»20%é™ä½åˆ°15%ï¼Œæ•è·æ›´å¤šé¢˜ç›®
        # é«˜åº¦ï¼šä»å›ºå®šå€¼æ”¹ä¸ºåŠ¨æ€ï¼ˆå›¾ç‰‡é«˜åº¦çš„3%ï¼‰
        min_h = max(min_question_height, int(img_height * 0.03))
        if (img_width * 0.15 < w < img_width * 0.98) and (min_h < h < img_height * 0.85):
            raw_boxes.append((x, y, w, h))
    
    print(f"[é¢˜ç›®åˆ†å‰²å™¨] âœ“ åˆæ­¥è¿‡æ»¤åä¿ç•™ {len(raw_boxes)} ä¸ªå€™é€‰åŒºåŸŸ")
    
    # 7. ã€V24.1æ–°å¢ã€‘ä½¿ç”¨æŠ•å½±åˆ†å‰²çº¿è¾…åŠ©åˆ†å‰²å¤§æ¡†
    if projection_split_lines and len(raw_boxes) > 0:
        raw_boxes = split_boxes_by_projection(raw_boxes, projection_split_lines, img_width)
        print(f"[é¢˜ç›®åˆ†å‰²å™¨] âœ“ æŠ•å½±è¾…åŠ©åˆ†å‰²å: {len(raw_boxes)} ä¸ªåŒºåŸŸ")
    
    # 8. æ™ºèƒ½åˆå¹¶ï¼ˆæ›´ä¿å®ˆï¼Œé¿å…è¿‡åº¦åˆå¹¶ï¼‰
    if len(raw_boxes) > 0:
        merged_boxes = merge_overlapping_boxes(raw_boxes, img_height, merge_threshold=0.5)  # æé«˜åˆå¹¶é˜ˆå€¼
        print(f"[é¢˜ç›®åˆ†å‰²å™¨] âœ“ åˆå¹¶åå‰©ä½™ {len(merged_boxes)} ä¸ªé¢˜ç›®åŒºåŸŸ")
    else:
        merged_boxes = []
    
    # 9. ã€V24.1+æ–°å¢ã€‘å…¨è¦†ç›–æ£€æŸ¥ - ç¡®ä¿ä¸é—æ¼ä»»ä½•ä¿¡æ¯
    if len(merged_boxes) > 0:
        final_boxes = ensure_full_coverage(binary, merged_boxes, img_width, img_height)
        print(f"[é¢˜ç›®åˆ†å‰²å™¨] âœ“ å…¨è¦†ç›–æ£€æŸ¥å®Œæˆï¼Œæœ€ç»ˆ: {len(final_boxes)} ä¸ªé¢˜ç›®åŒºåŸŸ")
    else:
        final_boxes = merged_boxes
    
    # 10. ä»ä¸Šåˆ°ä¸‹æ’åº
    final_boxes.sort(key=lambda box: box[1])
    
    print(f"\n{'='*70}")
    print(f"[é¢˜ç›®åˆ†å‰²å™¨] âœ… æœ€ç»ˆæ£€æµ‹åˆ° {len(final_boxes)} ä¸ªé¢˜ç›®åŒºåŸŸ")
    print(f"{'='*70}\n")
    
    return final_boxes


def find_split_lines_by_projection(binary: np.ndarray, img_height: int, min_gap: int = 20) -> List[int]:
    """
    ã€V24.1æ–°å¢ã€‘ä½¿ç”¨æ°´å¹³æŠ•å½±æ³•æ‰¾åˆ°é¢˜ç›®ä¹‹é—´çš„åˆ†å‰²çº¿
    
    åŸç†ï¼šé¢˜ç›®ä¹‹é—´é€šå¸¸æœ‰ç©ºç™½è¡Œï¼Œè¿™äº›è¡Œçš„åƒç´ æŠ•å½±å€¼ä¼šå¾ˆä½
    
    å‚æ•°:
        binary: äºŒå€¼åŒ–å›¾åƒ
        img_height: å›¾ç‰‡é«˜åº¦
        min_gap: æœ€å°ç©ºç™½è¡Œé«˜åº¦ï¼ˆåƒç´ ï¼‰
    
    è¿”å›:
        åˆ†å‰²çº¿çš„yåæ ‡åˆ—è¡¨
    """
    # è®¡ç®—æ¯ä¸€è¡Œçš„æ°´å¹³æŠ•å½±ï¼ˆç™½è‰²åƒç´ æ•°é‡ï¼‰
    h_projection = np.sum(binary == 255, axis=1)
    
    # æ‰¾åˆ°æŠ•å½±å€¼å¾ˆä½çš„è¡Œï¼ˆç©ºç™½åŒºåŸŸï¼‰
    threshold = np.max(h_projection) * 0.1  # ä½äºæœ€å¤§å€¼10%è§†ä¸ºç©ºç™½
    is_blank = h_projection < threshold
    
    # æ‰¾åˆ°è¿ç»­çš„ç©ºç™½åŒºåŸŸ
    split_lines = []
    in_gap = False
    gap_start = 0
    
    for i, blank in enumerate(is_blank):
        if blank and not in_gap:
            gap_start = i
            in_gap = True
        elif not blank and in_gap:
            gap_height = i - gap_start
            if gap_height >= min_gap:
                # é€‰æ‹©ç©ºç™½åŒºåŸŸçš„ä¸­é—´ä½œä¸ºåˆ†å‰²çº¿
                split_line = (gap_start + i) // 2
                split_lines.append(split_line)
            in_gap = False
    
    return split_lines


def split_boxes_by_projection(boxes: List[Tuple[int, int, int, int]], 
                               split_lines: List[int], 
                               img_width: int) -> List[Tuple[int, int, int, int]]:
    """
    ã€V24.1æ–°å¢ã€‘ä½¿ç”¨æŠ•å½±åˆ†å‰²çº¿å°†å¤§æ¡†åˆ†å‰²æˆå°æ¡†
    
    å‚æ•°:
        boxes: åŸå§‹è¾¹ç•Œæ¡†åˆ—è¡¨
        split_lines: åˆ†å‰²çº¿yåæ ‡åˆ—è¡¨
        img_width: å›¾ç‰‡å®½åº¦
    
    è¿”å›:
        åˆ†å‰²åçš„è¾¹ç•Œæ¡†åˆ—è¡¨
    """
    new_boxes = []
    
    for x, y, w, h in boxes:
        box_bottom = y + h
        
        # æ‰¾åˆ°ç©¿è¿‡æ­¤æ¡†çš„åˆ†å‰²çº¿
        internal_splits = [line for line in split_lines if y < line < box_bottom]
        
        if not internal_splits:
            # æ²¡æœ‰åˆ†å‰²çº¿ç©¿è¿‡ï¼Œä¿ç•™åŸæ¡†
            new_boxes.append((x, y, w, h))
        else:
            # æœ‰åˆ†å‰²çº¿ï¼Œè¿›è¡Œåˆ†å‰²
            internal_splits = [y] + sorted(internal_splits) + [box_bottom]
            
            for i in range(len(internal_splits) - 1):
                sub_y = internal_splits[i]
                sub_h = internal_splits[i + 1] - sub_y
                
                # è¿‡æ»¤æ‰å¤ªå°çš„å­æ¡†
                if sub_h > 30:  # è‡³å°‘30åƒç´ é«˜
                    new_boxes.append((x, sub_y, w, sub_h))
    
    return new_boxes


def ensure_full_coverage(binary: np.ndarray, 
                         boxes: List[Tuple[int, int, int, int]], 
                         img_width: int, 
                         img_height: int,
                         min_uncovered_area: int = 500) -> List[Tuple[int, int, int, int]]:
    """
    ã€V24.1+æ–°å¢ã€‘ç¡®ä¿æ‰€æœ‰æœ‰æ„ä¹‰çš„åŒºåŸŸéƒ½è¢«è‡³å°‘ä¸€ä¸ªæ¡†è¦†ç›–
    
    ç­–ç•¥ï¼š
    1. åˆ›å»ºä¸€ä¸ªè¦†ç›–æ©ç ï¼Œæ ‡è®°å·²è¢«è¦†ç›–çš„åŒºåŸŸ
    2. æ£€æµ‹æœªè¢«è¦†ç›–çš„æ–‡å­—åŒºåŸŸ
    3. ä¸ºè¿™äº›åŒºåŸŸåˆ›å»ºè¡¥å……æ¡†
    4. å…è®¸æ¡†ä¹‹é—´æœ‰é€‚å½“é‡å ï¼ˆ10-20%ï¼‰
    
    å‚æ•°:
        binary: äºŒå€¼åŒ–å›¾åƒ
        boxes: ç°æœ‰çš„è¾¹ç•Œæ¡†åˆ—è¡¨
        img_width: å›¾ç‰‡å®½åº¦
        img_height: å›¾ç‰‡é«˜åº¦
        min_uncovered_area: æœ€å°æœªè¦†ç›–åŒºåŸŸé¢ç§¯ï¼ˆåƒç´ ï¼‰ï¼Œå°äºæ­¤å€¼å¿½ç•¥
    
    è¿”å›:
        åŒ…å«è¡¥å……æ¡†çš„å®Œæ•´è¾¹ç•Œæ¡†åˆ—è¡¨
    """
    print(f"\n[å…¨è¦†ç›–æ£€æŸ¥] ğŸ” å¼€å§‹æ£€æŸ¥è¦†ç›–å®Œæ•´æ€§...")
    
    # 1. åˆ›å»ºè¦†ç›–æ©ç ï¼ˆæ‰€æœ‰åƒç´ åˆå§‹ä¸ºæœªè¦†ç›–ï¼‰
    coverage_mask = np.zeros((img_height, img_width), dtype=np.uint8)
    
    # 2. æ ‡è®°å·²è¢«è¦†ç›–çš„åŒºåŸŸï¼ˆç»™äºˆä¸€å®šçš„æ‰©å±•paddingï¼‰
    padding = 15  # è¦†ç›–æ£€æµ‹æ—¶çš„padding
    for x, y, w, h in boxes:
        x1 = max(0, x - padding)
        y1 = max(0, y - padding)
        x2 = min(img_width, x + w + padding)
        y2 = min(img_height, y + h + padding)
        coverage_mask[y1:y2, x1:x2] = 255
    
    # 3. æ‰¾åˆ°æœªè¢«è¦†ç›–çš„æ–‡å­—åŒºåŸŸï¼ˆåœ¨äºŒå€¼å›¾ä¸­æœ‰å†…å®¹ï¼Œä½†åœ¨è¦†ç›–æ©ç ä¸­æœªè¦†ç›–ï¼‰
    uncovered = cv2.bitwise_and(binary, cv2.bitwise_not(coverage_mask))
    
    # 4. æ£€æµ‹æœªè¦†ç›–åŒºåŸŸçš„è½®å»“
    uncovered_contours, _ = cv2.findContours(uncovered, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    # 5. ä¸ºæœªè¦†ç›–åŒºåŸŸåˆ›å»ºè¡¥å……æ¡†
    supplementary_boxes = []
    for contour in uncovered_contours:
        x, y, w, h = cv2.boundingRect(contour)
        area = w * h
        
        # åªå¤„ç†è¶³å¤Ÿå¤§çš„æœªè¦†ç›–åŒºåŸŸ
        if area >= min_uncovered_area:
            # åˆ›å»ºè¡¥å……æ¡†ï¼Œå¸¦æœ‰è¾ƒå¤§çš„paddingç¡®ä¿è¦†ç›–
            supplement_padding = 30
            supp_x = max(0, x - supplement_padding)
            supp_y = max(0, y - supplement_padding)
            supp_w = min(img_width - supp_x, w + 2 * supplement_padding)
            supp_h = min(img_height - supp_y, h + 2 * supplement_padding)
            
            supplementary_boxes.append((supp_x, supp_y, supp_w, supp_h))
            print(f"[å…¨è¦†ç›–æ£€æŸ¥] â†’ å‘ç°æœªè¦†ç›–åŒºåŸŸ ({x},{y},{w}x{h})ï¼Œåˆ›å»ºè¡¥å……æ¡†")
    
    # 6. åˆå¹¶åŸå§‹æ¡†å’Œè¡¥å……æ¡†
    all_boxes = boxes + supplementary_boxes
    
    if supplementary_boxes:
        print(f"[å…¨è¦†ç›–æ£€æŸ¥] âœ“ åˆ›å»ºäº† {len(supplementary_boxes)} ä¸ªè¡¥å……æ¡†")
    else:
        print(f"[å…¨è¦†ç›–æ£€æŸ¥] âœ“ æ— éœ€è¡¥å……ï¼Œæ‰€æœ‰åŒºåŸŸå·²è¦†ç›–")
    
    # 7. è®¡ç®—è¦†ç›–ç‡ç»Ÿè®¡
    total_text_pixels = np.sum(binary == 255)
    final_coverage_mask = np.zeros((img_height, img_width), dtype=np.uint8)
    for x, y, w, h in all_boxes:
        final_coverage_mask[y:min(img_height, y+h), x:min(img_width, x+w)] = 255
    
    covered_text_pixels = np.sum(cv2.bitwise_and(binary, final_coverage_mask) == 255)
    coverage_rate = (covered_text_pixels / total_text_pixels * 100) if total_text_pixels > 0 else 100
    
    print(f"[å…¨è¦†ç›–æ£€æŸ¥] ğŸ“Š è¦†ç›–ç‡: {coverage_rate:.1f}% ({covered_text_pixels}/{total_text_pixels} åƒç´ )")
    
    return all_boxes


def merge_overlapping_boxes(boxes: List[Tuple[int, int, int, int]], img_height: int, merge_threshold: float = 0.3) -> List[Tuple[int, int, int, int]]:
    """
    åˆå¹¶é‡å æˆ–å‚ç›´è·ç¦»è¿‡è¿‘çš„è¾¹ç•Œæ¡†ã€‚
    
    ã€V24.1ä¼˜åŒ–ã€‘æ›´ä¿å®ˆçš„åˆå¹¶ç­–ç•¥ï¼Œé¿å…è¿‡åº¦åˆå¹¶ç´§å¯†é¢˜ç›®
    
    ç­–ç•¥ï¼š
    - å¦‚æœä¸¤ä¸ªæ¡†çš„å‚ç›´é‡å è¶…è¿‡merge_thresholdï¼ˆé»˜è®¤30%ï¼‰ï¼Œåˆå¹¶
    - å¦‚æœä¸¤ä¸ªæ¡†çš„å‚ç›´é—´è·å°äºå›¾ç‰‡é«˜åº¦çš„2%ï¼ˆä»3%é™ä½ï¼‰ï¼Œåˆå¹¶
    """
    if len(boxes) <= 1:
        return boxes
    
    # æŒ‰yåæ ‡æ’åº
    sorted_boxes = sorted(boxes, key=lambda b: b[1])
    merged = [sorted_boxes[0]]
    
    for current in sorted_boxes[1:]:
        last_merged = merged[-1]
        
        # è®¡ç®—å‚ç›´é‡å å’Œé—´è·
        last_bottom = last_merged[1] + last_merged[3]
        current_top = current[1]
        current_bottom = current[1] + current[3]
        
        # è®¡ç®—é‡å é«˜åº¦
        overlap = max(0, min(last_bottom, current_bottom) - max(last_merged[1], current_top))
        
        # è®¡ç®—é—´è·
        gap = current_top - last_bottom
        
        # åˆ¤æ–­æ˜¯å¦éœ€è¦åˆå¹¶
        should_merge = False
        
        # æ¡ä»¶1: æœ‰æ˜¾è‘—é‡å ï¼ˆè¶…è¿‡è¾ƒå°æ¡†é«˜åº¦çš„merge_thresholdï¼‰
        if overlap > min(last_merged[3], current[3]) * merge_threshold:
            should_merge = True
        
        # æ¡ä»¶2: é—´è·å¾ˆå°ï¼ˆå°äºå›¾ç‰‡é«˜åº¦çš„2%ï¼‰- ä»3%é™ä½åˆ°2%ï¼Œæ›´ä¿å®ˆ
        if gap >= 0 and gap < img_height * 0.02:
            should_merge = True
        
        if should_merge:
            # åˆå¹¶ä¸¤ä¸ªæ¡†ï¼šå–æœ€å°çš„xå’Œyï¼Œæœ€å¤§çš„å³ä¸‹è§’
            new_x = min(last_merged[0], current[0])
            new_y = min(last_merged[1], current[1])
            new_right = max(last_merged[0] + last_merged[2], current[0] + current[2])
            new_bottom = max(last_merged[1] + last_merged[3], current[1] + current[3])
            
            merged[-1] = (new_x, new_y, new_right - new_x, new_bottom - new_y)
            print(f"[é¢˜ç›®åˆ†å‰²å™¨] â†’ åˆå¹¶äº†ä¸¤ä¸ªæ¥è¿‘çš„åŒºåŸŸï¼ˆgap={gap}pxï¼‰")
        else:
            merged.append(current)
    
    return merged


def visualize_detected_boxes(image: Image.Image, 
                            boxes: List[Tuple[int, int, int, int]], 
                            output_path: str = "debug_boxes.png",
                            show_overlap: bool = True):
    """
    ã€V24.1å¢å¼ºã€‘è°ƒè¯•ç”¨ï¼šåœ¨å›¾ç‰‡ä¸Šç»˜åˆ¶æ£€æµ‹åˆ°çš„è¾¹ç•Œæ¡†å¹¶ä¿å­˜
    
    å‚æ•°:
        image: åŸå§‹å›¾ç‰‡
        boxes: æ£€æµ‹åˆ°çš„è¾¹ç•Œæ¡†åˆ—è¡¨
        output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        show_overlap: æ˜¯å¦ç”¨ä¸åŒé¢œè‰²æ ‡è¯†é‡å åŒºåŸŸ
    """
    cv_image = pil_to_cv2(image)
    img_height, img_width = cv_image.shape[:2]
    
    # å¦‚æœè¦æ˜¾ç¤ºé‡å ï¼Œå…ˆåˆ›å»ºè¦†ç›–æ©ç 
    if show_overlap:
        overlap_mask = np.zeros((img_height, img_width), dtype=np.uint8)
        for x, y, w, h in boxes:
            overlap_mask[y:y+h, x:x+w] += 1
        
        # ç”¨åŠé€æ˜é¢œè‰²æ˜¾ç¤ºé‡å åŒºåŸŸ
        overlay = cv_image.copy()
        # é‡å 2æ¬¡åŠä»¥ä¸Šçš„åŒºåŸŸç”¨é»„è‰²æ ‡è¯†
        overlap_2x = (overlap_mask >= 2)
        overlay[overlap_2x] = [0, 255, 255]  # é»„è‰²
        
        # æ··åˆ
        cv_image = cv2.addWeighted(cv_image, 0.7, overlay, 0.3, 0)
    
    # ç»˜åˆ¶æ‰€æœ‰è¾¹ç•Œæ¡†
    for i, (x, y, w, h) in enumerate(boxes):
        # ç»˜åˆ¶çŸ©å½¢ï¼ˆç»¿è‰²è¾¹æ¡†ï¼‰
        cv2.rectangle(cv_image, (x, y), (x + w, y + h), (0, 255, 0), 3)
        
        # ç»˜åˆ¶é¢˜å·ï¼ˆçº¢è‰²æ–‡å­—ï¼Œç™½è‰²èƒŒæ™¯ï¼‰
        label = f"Q{i+1}"
        font_scale = 1.0
        thickness = 2
        (text_width, text_height), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, font_scale, thickness)
        
        # ç»˜åˆ¶ç™½è‰²èƒŒæ™¯
        cv2.rectangle(cv_image, (x + 5, y + 5), (x + text_width + 15, y + text_height + 15), (255, 255, 255), -1)
        # ç»˜åˆ¶æ–‡å­—
        cv2.putText(cv_image, label, (x + 10, y + text_height + 10), 
                   cv2.FONT_HERSHEY_SIMPLEX, font_scale, (0, 0, 255), thickness)
    
    # æ·»åŠ å›¾ä¾‹
    legend_y = 30
    cv2.putText(cv_image, f"Total: {len(boxes)} boxes", (10, legend_y), 
               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
    if show_overlap:
        cv2.putText(cv_image, "Yellow = Overlap", (10, legend_y + 30), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)
    
    # ä¿å­˜
    cv2.imwrite(output_path, cv_image)
    print(f"[é¢˜ç›®åˆ†å‰²å™¨] ğŸ“¸ è°ƒè¯•å›¾ç‰‡å·²ä¿å­˜åˆ°: {output_path}")
    
    # ç»Ÿè®¡é‡å ä¿¡æ¯
    if show_overlap:
        overlap_pixels = np.sum(overlap_mask >= 2)
        total_covered = np.sum(overlap_mask >= 1)
        overlap_rate = (overlap_pixels / total_covered * 100) if total_covered > 0 else 0
        print(f"[é¢˜ç›®åˆ†å‰²å™¨] ğŸ“Š é‡å ç‡: {overlap_rate:.1f}%")

