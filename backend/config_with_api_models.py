"""
==============================================================================
æ²æ¢§AIè§£é¢˜ç³»ç»Ÿ - å¤§æ¨¡å‹é…ç½®ä¸­å¿ƒï¼ˆAPIç‰ˆæœ¬ï¼‰
==============================================================================
åŠŸèƒ½ï¼š
- æ”¯æŒé€šè¿‡APIè°ƒç”¨å¼€æºæ¨¡å‹
- æ— éœ€æœ¬åœ°GPUéƒ¨ç½²
- å¤šç§APIæœåŠ¡å•†å¯é€‰
==============================================================================
"""

import os
from typing import Dict, Any, Literal
from dotenv import load_dotenv

load_dotenv()

# ==============================================================================
# æ ¸å¿ƒé…ç½®ï¼šä¿®æ”¹æ­¤å˜é‡ä»¥åˆ‡æ¢å…¨å±€ä½¿ç”¨çš„æ¨¡å‹
# ==============================================================================

# å½“å‰æ¿€æ´»çš„æ¨¡å‹
ACTIVE_MODEL_KEY = "qwen-vl-max"  # é»˜è®¤ä½¿ç”¨é—­æºåŸºå‡†æ¨¡å‹

# å¯é€‰æ¨¡å‹ï¼ˆé€šè¿‡APIè°ƒç”¨ï¼Œæ— éœ€æœ¬åœ°éƒ¨ç½²ï¼‰:
# ACTIVE_MODEL_KEY = "qwen-vl-plus"              # é˜¿é‡Œäº‘å¼€æºç‰ˆAPI
# ACTIVE_MODEL_KEY = "qwen2-vl-72b"              # é˜¿é‡Œäº‘72Bç‰ˆæœ¬
# ACTIVE_MODEL_KEY = "qwen-vl-7b-siliconflow"    # SiliconFlowæä¾›
# ACTIVE_MODEL_KEY = "qwen-vl-72b-together"      # Together AIæä¾›

# ==============================================================================
# æ¨¡å‹é…ç½®å­—å…¸
# ==============================================================================

MODEL_CONFIGS: Dict[str, Dict[str, Any]] = {
    # ----------------------------------------------------------------------
    # é˜¿é‡Œäº‘DashScope APIï¼ˆé—­æºå’Œå¼€æºéƒ½æ”¯æŒï¼‰
    # ----------------------------------------------------------------------
    "qwen-vl-max": {
        "type": "dashscope_api",
        "model_name": "qwen-vl-max",
        "api_key_env": "DASHSCOPE_API_KEY",
        "description": "é€šä¹‰åƒé—®VL Max - é—­æºæ——èˆ°ç‰ˆ",
        "capabilities": ["multimodal", "streaming", "high_accuracy"],
        "cost_tier": "high",
        "max_tokens": 8192,
        "temperature": 0.7,
        "provider": "é˜¿é‡Œäº‘DashScope",
    },
    
    "qwen-vl-plus": {
        "type": "dashscope_api",
        "model_name": "qwen-vl-plus",
        "api_key_env": "DASHSCOPE_API_KEY",
        "description": "é€šä¹‰åƒé—®VL Plus - æ€§ä»·æ¯”å¼€æºç‰ˆï¼ˆAPIï¼‰",
        "capabilities": ["multimodal", "streaming", "cost_effective"],
        "cost_tier": "medium",
        "max_tokens": 8192,
        "temperature": 0.7,
        "provider": "é˜¿é‡Œäº‘DashScope",
        "pricing": "çº¦0.002å…ƒ/åƒtokensï¼ˆæ¯”Maxä¾¿å®œ70%ï¼‰",
    },
    
    "qwen2-vl-72b": {
        "type": "dashscope_api",
        "model_name": "qwen2-vl-72b-instruct",
        "api_key_env": "DASHSCOPE_API_KEY",
        "description": "Qwen2-VL 72B Instruct - é«˜æ€§èƒ½å¼€æºï¼ˆAPIï¼‰",
        "capabilities": ["multimodal", "streaming", "high_performance"],
        "cost_tier": "medium",
        "max_tokens": 8192,
        "temperature": 0.7,
        "provider": "é˜¿é‡Œäº‘DashScope",
        "pricing": "çº¦0.004å…ƒ/åƒtokens",
    },
    
    # ----------------------------------------------------------------------
    # SiliconFlow APIï¼ˆè¶…ä¾¿å®œï¼Œæ¨èï¼‰
    # ----------------------------------------------------------------------
    "qwen-vl-7b-siliconflow": {
        "type": "openai_compatible",
        "model_name": "Qwen/Qwen2-VL-7B-Instruct",
        "api_base": "https://api.siliconflow.cn/v1",
        "api_key": os.getenv("SILICONFLOW_API_KEY", ""),
        "description": "Qwen2-VL 7B - SiliconFlowè¶…ä½ä»·API",
        "capabilities": ["multimodal", "streaming", "ultra_low_cost"],
        "cost_tier": "very_low",
        "max_tokens": 8192,
        "temperature": 0.7,
        "provider": "SiliconFlow",
        "pricing": "çº¦0.0007å…ƒ/åƒtokensï¼ˆè¶…ä¾¿å®œï¼ï¼‰",
        "signup_url": "https://cloud.siliconflow.cn/",
    },
    
    "qwen-vl-72b-siliconflow": {
        "type": "openai_compatible",
        "model_name": "Qwen/Qwen2-VL-72B-Instruct",
        "api_base": "https://api.siliconflow.cn/v1",
        "api_key": os.getenv("SILICONFLOW_API_KEY", ""),
        "description": "Qwen2-VL 72B - SiliconFlowä½ä»·API",
        "capabilities": ["multimodal", "streaming", "low_cost"],
        "cost_tier": "low",
        "max_tokens": 8192,
        "temperature": 0.7,
        "provider": "SiliconFlow",
        "pricing": "çº¦0.0035å…ƒ/åƒtokens",
    },
    
    # ----------------------------------------------------------------------
    # Together AIï¼ˆå›½é™…åŒ–ï¼Œç¨³å®šï¼‰
    # ----------------------------------------------------------------------
    "qwen-vl-72b-together": {
        "type": "openai_compatible",
        "model_name": "Qwen/Qwen2-VL-72B-Instruct",
        "api_base": "https://api.together.xyz/v1",
        "api_key": os.getenv("TOGETHER_API_KEY", ""),
        "description": "Qwen2-VL 72B - Together AIå›½é™…æœåŠ¡",
        "capabilities": ["multimodal", "streaming", "international"],
        "cost_tier": "medium",
        "max_tokens": 8192,
        "temperature": 0.7,
        "provider": "Together AI",
        "pricing": "$0.001/åƒtokens",
        "signup_url": "https://www.together.ai/",
    },
    
    # ----------------------------------------------------------------------
    # DeepInfraï¼ˆå¤‡é€‰æ–¹æ¡ˆï¼‰
    # ----------------------------------------------------------------------
    "qwen-vl-7b-deepinfra": {
        "type": "openai_compatible",
        "model_name": "Qwen/Qwen2-VL-7B-Instruct",
        "api_base": "https://api.deepinfra.com/v1/openai",
        "api_key": os.getenv("DEEPINFRA_API_KEY", ""),
        "description": "Qwen2-VL 7B - DeepInfraç¨³å®šæœåŠ¡",
        "capabilities": ["multimodal", "streaming", "stable"],
        "cost_tier": "low",
        "max_tokens": 8192,
        "temperature": 0.7,
        "provider": "DeepInfra",
        "pricing": "$0.0006/åƒtokens",
        "signup_url": "https://deepinfra.com/",
    },
    
    # ----------------------------------------------------------------------
    # æœ¬åœ°/è¿œç¨‹vLLMéƒ¨ç½²ï¼ˆå¯é€‰ï¼‰
    # ----------------------------------------------------------------------
    "qwen3-vl-32b-local": {
        "type": "openai_compatible",
        "model_name": "Qwen/Qwen3-VL-32B-Instruct",
        "api_base": os.getenv("LOCAL_MODEL_API_BASE", "http://localhost:8001/v1"),
        "api_key": "EMPTY",
        "description": "Qwen3-VL 32B - æœ¬åœ°/è¿œç¨‹vLLMéƒ¨ç½²",
        "capabilities": ["multimodal", "streaming", "self_hosted"],
        "cost_tier": "zero",  # è‡ªå·±éƒ¨ç½²ï¼Œåªæœ‰ç¡¬ä»¶æˆæœ¬
        "max_tokens": 8192,
        "temperature": 0.7,
        "provider": "è‡ªéƒ¨ç½²vLLM",
        "note": "éœ€è¦GPUæœåŠ¡å™¨ï¼Œé€‚åˆå¤§è§„æ¨¡ä½¿ç”¨",
    },
}

# ==============================================================================
# é…ç½®è·å–å‡½æ•°
# ==============================================================================

def get_active_model_config() -> Dict[str, Any]:
    """è·å–å½“å‰æ¿€æ´»çš„æ¨¡å‹é…ç½®"""
    if ACTIVE_MODEL_KEY not in MODEL_CONFIGS:
        raise ValueError(
            f"æœªçŸ¥çš„æ¨¡å‹KEY: {ACTIVE_MODEL_KEY}. "
            f"å¯ç”¨çš„æ¨¡å‹: {list(MODEL_CONFIGS.keys())}"
        )
    
    config = MODEL_CONFIGS[ACTIVE_MODEL_KEY].copy()
    
    # å¦‚æœæ˜¯Dashscope APIï¼ŒåŠ è½½API Key
    if config["type"] == "dashscope_api":
        api_key = os.getenv(config["api_key_env"])
        if not api_key:
            raise ValueError(f"ç¯å¢ƒå˜é‡ {config['api_key_env']} æœªè®¾ç½®ï¼")
        config["api_key"] = api_key
    
    # å¦‚æœæ˜¯OpenAIå…¼å®¹APIï¼ŒéªŒè¯api_key
    elif config["type"] == "openai_compatible":
        if not config.get("api_key"):
            print(f"âš ï¸  è­¦å‘Š: {ACTIVE_MODEL_KEY} çš„APIå¯†é’¥æœªè®¾ç½®")
    
    return config


def get_model_info() -> str:
    """è·å–å½“å‰æ¨¡å‹çš„å‹å¥½æè¿°ä¿¡æ¯"""
    config = get_active_model_config()
    
    info = [
        f"[å½“å‰æ¨¡å‹] {ACTIVE_MODEL_KEY}",
        f"  æè¿°: {config['description']}",
        f"  æä¾›å•†: {config.get('provider', 'æœªçŸ¥')}",
        f"  ç±»å‹: {config['type']}",
        f"  æˆæœ¬ç­‰çº§: {config['cost_tier']}",
    ]
    
    if 'pricing' in config:
        info.append(f"  ä»·æ ¼: {config['pricing']}")
    
    if 'signup_url' in config:
        info.append(f"  æ³¨å†Œåœ°å€: {config['signup_url']}")
    
    info.append(f"  èƒ½åŠ›: {', '.join(config['capabilities'])}")
    
    return "\n".join(info)


def list_api_models_by_provider():
    """æŒ‰æœåŠ¡å•†åˆ—å‡ºæ‰€æœ‰APIæ¨¡å‹"""
    print("=" * 70)
    print("å¯ç”¨çš„APIæ¨¡å‹ï¼ˆæŒ‰æœåŠ¡å•†åˆ†ç±»ï¼‰")
    print("=" * 70 + "\n")
    
    providers = {}
    for key, config in MODEL_CONFIGS.items():
        provider = config.get('provider', 'æœªçŸ¥')
        if provider not in providers:
            providers[provider] = []
        providers[provider].append((key, config))
    
    for provider, models in providers.items():
        print(f"ğŸ¢ {provider}")
        print("-" * 70)
        for key, config in models:
            is_active = "âœ“ [å½“å‰]" if key == ACTIVE_MODEL_KEY else "  "
            pricing = config.get('pricing', 'ä»·æ ¼æœªçŸ¥')
            print(f"{is_active} {key}")
            print(f"    {config['description']}")
            print(f"    ä»·æ ¼: {pricing}")
            if 'signup_url' in config:
                print(f"    æ³¨å†Œ: {config['signup_url']}")
            print()
        print()


def recommend_model_by_scenario():
    """æ ¹æ®ä½¿ç”¨åœºæ™¯æ¨èæ¨¡å‹"""
    print("=" * 70)
    print("ä½¿ç”¨åœºæ™¯æ¨è")
    print("=" * 70 + "\n")
    
    recommendations = {
        "ğŸ’° æè‡´æˆæœ¬ä¼˜åŒ–": "qwen-vl-7b-siliconflowï¼ˆ0.0007å…ƒ/åƒtokensï¼‰",
        "âš–ï¸  æ€§ä»·æ¯”å¹³è¡¡": "qwen-vl-plusï¼ˆé˜¿é‡Œäº‘ï¼Œç¨³å®šå¯é ï¼‰",
        "ğŸš€ é«˜æ€§èƒ½éœ€æ±‚": "qwen2-vl-72bï¼ˆ72Bå‚æ•°ï¼Œæ¨ç†èƒ½åŠ›å¼ºï¼‰",
        "ğŸŒ å›½é™…åŒ–éƒ¨ç½²": "qwen-vl-72b-togetherï¼ˆTogether AIï¼‰",
        "ğŸ”’ æ•°æ®å®‰å…¨/å¤§è§„æ¨¡": "qwen3-vl-32b-localï¼ˆè‡ªéƒ¨ç½²ï¼‰",
        "ğŸ§ª å¼€å‘æµ‹è¯•": "qwen-vl-7b-siliconflowï¼ˆä¾¿å®œå¿«é€Ÿï¼‰",
    }
    
    for scenario, model in recommendations.items():
        print(f"{scenario}")
        print(f"  æ¨è: {model}\n")


# ==============================================================================
# çŸ¥è¯†ç‚¹æå–æ¨¡å‹é…ç½®ï¼ˆä¿æŒä¸å˜ï¼‰
# ==============================================================================

KNOWLEDGE_EXTRACTION_MODEL = "qwen-turbo"

KNOWLEDGE_EXTRACTION_CONFIGS = {
    "qwen-turbo": {
        "type": "dashscope_api",
        "model_name": "qwen-turbo",
        "api_key_env": "DASHSCOPE_API_KEY",
    },
}

def get_knowledge_extraction_config() -> Dict[str, Any]:
    """è·å–çŸ¥è¯†ç‚¹æå–æ¨¡å‹é…ç½®"""
    config = KNOWLEDGE_EXTRACTION_CONFIGS[KNOWLEDGE_EXTRACTION_MODEL].copy()
    if config["type"] == "dashscope_api":
        api_key = os.getenv(config["api_key_env"])
        if not api_key:
            raise ValueError(f"ç¯å¢ƒå˜é‡ {config['api_key_env']} æœªè®¾ç½®ï¼")
        config["api_key"] = api_key
    return config


# ==============================================================================
# è¿è¡Œæ—¶æµ‹è¯•
# ==============================================================================

if __name__ == "__main__":
    print("\n" + "=" * 70)
    print("æ²æ¢§AIè§£é¢˜ç³»ç»Ÿ - æ¨¡å‹é…ç½®æµ‹è¯•ï¼ˆAPIç‰ˆæœ¬ï¼‰")
    print("=" * 70 + "\n")
    
    # æ˜¾ç¤ºæ‰€æœ‰APIæ¨¡å‹
    list_api_models_by_provider()
    
    # æ˜¾ç¤ºä½¿ç”¨åœºæ™¯æ¨è
    recommend_model_by_scenario()
    
    # æ˜¾ç¤ºå½“å‰æ¿€æ´»çš„æ¨¡å‹
    print("=" * 70)
    print(get_model_info())
    print("=" * 70)
    
    # æµ‹è¯•é…ç½®è·å–
    try:
        config = get_active_model_config()
        print("\nâœ… é…ç½®åŠ è½½æˆåŠŸï¼")
        print(f"   æ¨¡å‹åç§°: {config['model_name']}")
        print(f"   APIç±»å‹: {config['type']}")
        if config['type'] == 'openai_compatible':
            print(f"   APIåœ°å€: {config['api_base']}")
    except Exception as e:
        print(f"\nâŒ é…ç½®åŠ è½½å¤±è´¥: {e}")

