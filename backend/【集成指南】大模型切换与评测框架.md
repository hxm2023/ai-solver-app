# å¤§æ¨¡å‹åˆ‡æ¢ä¸è¯„æµ‹æ¡†æ¶ - é›†æˆæŒ‡å—

## ğŸ“‹ æ¦‚è¿°

æœ¬æ–‡æ¡£è¯´æ˜å¦‚ä½•å°†æ–°å¼€å‘çš„**å¤§æ¨¡å‹åˆ‡æ¢æœºåˆ¶**å’Œ**è¯„æµ‹æ¡†æ¶**é›†æˆåˆ°ç°æœ‰çš„`main_db.py`ä¸­ã€‚

## ğŸ¯ ä¸‰å¤§æ ¸å¿ƒæ¨¡å—

### 1. config.py - æ¨¡å‹é…ç½®ä¸­å¿ƒ
- ç»Ÿä¸€ç®¡ç†æ‰€æœ‰æ¨¡å‹é…ç½®
- ä¸€é”®åˆ‡æ¢æ¨¡å‹ï¼ˆä¿®æ”¹`ACTIVE_MODEL_KEY`ï¼‰

### 2. model_adapter.py - æ¨¡å‹é€‚é…å™¨
- ç»Ÿä¸€ä¸åŒæ¨¡å‹çš„è°ƒç”¨æ¥å£
- æ”¯æŒDashscopeå’ŒOpenAIå…¼å®¹API

### 3. evaluation_suite.py - è¯„æµ‹æ¡†æ¶
- è‡ªåŠ¨è®°å½•è¯„æµ‹æ•°æ®
- å¤šç»´åº¦è¯„åˆ†ç³»ç»Ÿ
- ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š

---

## ğŸ”§ é›†æˆæ­¥éª¤

### æ­¥éª¤1ï¼šä¿®æ”¹ main_db.py çš„å¯¼å…¥éƒ¨åˆ†

åœ¨`main_db.py`é¡¶éƒ¨æ·»åŠ æ–°æ¨¡å—çš„å¯¼å…¥ï¼š

```python
# ã€æ–°å¢ã€‘å¤§æ¨¡å‹é€‚é…å™¨
from model_adapter import (
    MultiModalModelAdapter,
    TextModelAdapter,
    get_multimodal_adapter,
    get_text_adapter
)

# ã€æ–°å¢ã€‘è¯„æµ‹æ¡†æ¶
from evaluation_suite import (
    create_evaluation_record,
    EvaluationLogger,
    quick_evaluate_and_log
)

# ã€æ–°å¢ã€‘é…ç½®
import config
```

### æ­¥éª¤2ï¼šæ›¿æ¢AIè°ƒç”¨é€»è¾‘

#### åŸä»£ç ï¼ˆå¤§çº¦åœ¨ç¬¬1630-1700è¡Œï¼‰

```python
# åŸæ¥çš„ä»£ç ï¼ˆä»…ç¤ºä¾‹ï¼‰
response = dashscope.MultiModalConversation.call(
    model='qwen-vl-max',
    messages=messages,
    stream=True
)
```

#### ä¿®æ”¹ä¸ºï¼ˆä½¿ç”¨é€‚é…å™¨ï¼‰

```python
# ã€ä¿®æ”¹ã€‘ä½¿ç”¨ç»Ÿä¸€é€‚é…å™¨
adapter = get_multimodal_adapter()  # è‡ªåŠ¨ä½¿ç”¨config.pyä¸­é…ç½®çš„æ¨¡å‹

# æ„å»ºæ¶ˆæ¯
messages = [
    {
        "role": "user",
        "content": [
            {"image": f"data:image/jpeg;base64,{current_image}"},
            {"text": prompt}
        ]
    }
]

# æ·»åŠ å†å²æ¶ˆæ¯
if session_id and session_id in chat_sessions:
    messages = chat_sessions[session_id]["messages"] + messages

# è°ƒç”¨æ¨¡å‹
full_response = ""
start_time = time.time()

for chunk in adapter.call(messages, stream=True):
    if chunk["finish_reason"] == "error":
        # å¤„ç†é”™è¯¯
        error_msg = chunk.get("error", "æœªçŸ¥é”™è¯¯")
        print(f"âŒ AIè°ƒç”¨å¤±è´¥: {error_msg}")
        break
    
    content = chunk["content"]
    full_response += content
    
    # æµå¼è¿”å›ç»™å‰ç«¯ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰
    yield f"data: {json.dumps({'content': content})}\n\n"

response_time = time.time() - start_time
```

### æ­¥éª¤3ï¼šé›†æˆè¯„æµ‹è®°å½•

åœ¨AIå“åº”å®Œæˆåï¼Œæ·»åŠ è¯„æµ‹è®°å½•ï¼š

```python
# ã€æ–°å¢ã€‘åœ¨AIå“åº”å®Œæˆåè®°å½•è¯„æµ‹æ•°æ®
if request.mode == 'review':  # æ‰¹æ”¹æ¨¡å¼
    task_type = 'review'
elif 'ç”Ÿæˆé¢˜ç›®' in request.prompt or 'å‡ºé¢˜' in request.prompt:  # ç”Ÿé¢˜æ¨¡å¼
    task_type = 'generate'
else:  # è§£é¢˜æ¨¡å¼
    task_type = 'solve'

# è®°å½•è¯„æµ‹ï¼ˆå¼‚æ­¥æ‰§è¡Œï¼Œä¸é˜»å¡ä¸»æµç¨‹ï¼‰
try:
    quick_evaluate_and_log(
        model_name=config.ACTIVE_MODEL_KEY,
        task_type=task_type,
        input_prompt=request.prompt,
        raw_output=full_response,
        input_image_path=None,  # å¯é€‰ï¼šä¿å­˜å›¾ç‰‡è·¯å¾„
        response_time=response_time,
        token_count=len(full_response),  # ç®€åŒ–è®¡ç®—
        notes=""  # å¯ç”±æµ‹è¯•äººå‘˜åç»­æ·»åŠ 
    )
    print(f"âœ… [è¯„æµ‹] å·²è®°å½• {config.ACTIVE_MODEL_KEY} çš„ {task_type} ä»»åŠ¡")
except Exception as eval_error:
    print(f"âš ï¸  [è¯„æµ‹] è®°å½•å¤±è´¥: {eval_error}")
```

### æ­¥éª¤4ï¼šä¿®æ”¹çŸ¥è¯†ç‚¹æå–

```python
# åŸä»£ç 
extract_response = dashscope.Generation.call(
    model='qwen-turbo',
    prompt=extract_prompt
)

# ã€ä¿®æ”¹ä¸ºã€‘
text_adapter = get_text_adapter()
knowledge_text = text_adapter.call(extract_prompt)

if knowledge_text:
    knowledge_points = [kp.strip() for kp in knowledge_text.split('ï¼Œ')]
    print(f"[çŸ¥è¯†ç‚¹æå–] æˆåŠŸ: {knowledge_points}")
```

---

## ğŸ“ å®Œæ•´ç¤ºä¾‹ï¼šä¿®æ”¹ /api/db/chat è·¯ç”±

ä»¥ä¸‹æ˜¯ä¸€ä¸ªå®Œæ•´çš„ä¿®æ”¹ç¤ºä¾‹ï¼š

```python
@app.post("/api/db/chat")
async def db_chat(request: ChatRequest, user: dict = Depends(get_current_user)):
    """
    AIå¯¹è¯æ¥å£ï¼ˆæ”¯æŒå¤šæ¨¡å‹åˆ‡æ¢å’Œè¯„æµ‹ï¼‰
    
    V25.2 å¢å¼ºï¼š
    - æ”¯æŒå¤šæ¨¡å‹åˆ‡æ¢
    - è‡ªåŠ¨è¯„æµ‹è®°å½•
    """
    import time
    import config
    from model_adapter import get_multimodal_adapter, get_text_adapter
    from evaluation_suite import quick_evaluate_and_log
    
    user_id = user["user_id"]
    mode = request.mode
    prompt = request.prompt
    session_id = request.session_id
    
    # æ‰“å°å½“å‰ä½¿ç”¨çš„æ¨¡å‹
    print(f"\n{'='*60}")
    print(f"[AIå¯¹è¯] ç”¨æˆ·: {user_id}")
    print(f"[AIå¯¹è¯] æ¨¡å¼: {mode}")
    print(f"[AIå¯¹è¯] å½“å‰æ¨¡å‹: {config.ACTIVE_MODEL_KEY}")
    print(f"{'='*60}\n")
    
    # å¤„ç†å›¾ç‰‡
    current_image = None
    if request.image_base64:
        current_image = request.image_base64
    elif session_id and session_id in chat_sessions:
        current_image = chat_sessions[session_id].get("image_base64")
    
    # æ„å»ºæ¶ˆæ¯
    messages = []
    
    # æ·»åŠ ç³»ç»Ÿæç¤ºï¼ˆå¯é€‰ï¼‰
    if mode == 'solve':
        system_msg = "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„æ•°å­¦è€å¸ˆï¼Œæ“…é•¿è§£ç­”å„ç§æ•°å­¦é—®é¢˜ã€‚"
    elif mode == 'review':
        system_msg = "ä½ æ˜¯ä¸€ä½ç»éªŒä¸°å¯Œçš„è€å¸ˆï¼Œæ“…é•¿æ‰¹æ”¹ä½œä¸šå¹¶æŒ‡å‡ºé”™è¯¯ã€‚"
    else:
        system_msg = "ä½ æ˜¯ä¸€ä½AIåŠ©æ‰‹ã€‚"
    
    messages.append({
        "role": "system",
        "content": system_msg
    })
    
    # æ·»åŠ å†å²æ¶ˆæ¯
    if session_id and session_id in chat_sessions:
        messages.extend(chat_sessions[session_id]["messages"])
    
    # æ·»åŠ å½“å‰ç”¨æˆ·æ¶ˆæ¯
    user_message = {
        "role": "user",
        "content": []
    }
    
    if current_image:
        user_message["content"].append({
            "image": f"data:image/jpeg;base64,{current_image}"
        })
    
    user_message["content"].append({"text": prompt})
    messages.append(user_message)
    
    # ä½¿ç”¨é€‚é…å™¨è°ƒç”¨AI
    adapter = get_multimodal_adapter()
    
    full_response = ""
    start_time = time.time()
    has_error = False
    
    async def generate():
        nonlocal full_response, has_error
        
        yield f"data: {json.dumps({'type': 'start'})}\n\n"
        
        try:
            for chunk in adapter.call(messages, stream=True):
                if chunk["finish_reason"] == "error":
                    error_msg = chunk.get("error", "æœªçŸ¥é”™è¯¯")
                    yield f"data: {json.dumps({'type': 'error', 'content': error_msg})}\n\n"
                    has_error = True
                    break
                
                content = chunk["content"]
                full_response += content
                
                yield f"data: {json.dumps({'type': 'content', 'content': content})}\n\n"
            
            yield f"data: {json.dumps({'type': 'done'})}\n\n"
        
        except Exception as e:
            error_msg = f"AIè°ƒç”¨å¼‚å¸¸: {str(e)}"
            print(f"âŒ {error_msg}")
            yield f"data: {json.dumps({'type': 'error', 'content': error_msg})}\n\n"
            has_error = True
    
    # è¿”å›æµå¼å“åº”
    response = StreamingResponse(generate(), media_type="text/event-stream")
    
    # ã€æ–°å¢ã€‘åœ¨åå°è®°å½•è¯„æµ‹æ•°æ®
    response_time = time.time() - start_time
    
    # åˆ¤æ–­ä»»åŠ¡ç±»å‹
    if mode == 'review':
        task_type = 'review'
    elif 'ç”Ÿæˆ' in prompt or 'å‡ºé¢˜' in prompt:
        task_type = 'generate'
    else:
        task_type = 'solve'
    
    # å¼‚æ­¥è®°å½•è¯„æµ‹
    if not has_error:
        try:
            quick_evaluate_and_log(
                model_name=config.ACTIVE_MODEL_KEY,
                task_type=task_type,
                input_prompt=prompt,
                raw_output=full_response,
                response_time=response_time,
                token_count=len(full_response)
            )
        except Exception as eval_error:
            print(f"âš ï¸  è¯„æµ‹è®°å½•å¤±è´¥: {eval_error}")
    
    # ä¿å­˜ä¼šè¯
    if session_id:
        if session_id not in chat_sessions:
            chat_sessions[session_id] = {
                "user_id": user_id,
                "messages": [],
                "image_base64": current_image,
                "created_at": datetime.now().isoformat()
            }
        
        # æ·»åŠ åˆ°å†å²
        chat_sessions[session_id]["messages"].append(user_message)
        chat_sessions[session_id]["messages"].append({
            "role": "assistant",
            "content": full_response
        })
    
    # ã€ä¿ç•™ã€‘é”™é¢˜è‡ªåŠ¨ä¿å­˜é€»è¾‘
    if mode == 'review' and not has_error:
        is_mistake = any(keyword in full_response for keyword in [
            'é”™è¯¯', 'ä¸æ­£ç¡®', 'ä¸å¯¹', 'æœ‰è¯¯', 'ç­”æ¡ˆé”™äº†', 
            'åšé”™äº†', 'æœ‰é—®é¢˜', 'é”™äº†'
        ])
        
        if is_mistake and current_image:
            # ... ä¿ç•™åŸæœ‰çš„é”™é¢˜ä¿å­˜é€»è¾‘ ...
            print(f"âœ… æ£€æµ‹åˆ°é”™è¯¯ï¼Œæ­£åœ¨ä¿å­˜åˆ°é”™é¢˜æœ¬...")
    
    return response
```

---

## ğŸ¨ æ¨¡å‹åˆ‡æ¢æ¼”ç¤º

### åˆ‡æ¢åˆ°32B-Instructæ¨¡å‹

1. ç¼–è¾‘ `backend/config.py`ï¼š
```python
# ACTIVE_MODEL_KEY = "qwen-vl-max"  # æ³¨é‡Šæ‰åŸæ¥çš„
ACTIVE_MODEL_KEY = "qwen3-vl-32b-instruct"  # å¯ç”¨æ–°æ¨¡å‹
```

2. é‡å¯åç«¯æœåŠ¡
3. ç³»ç»Ÿè‡ªåŠ¨ä½¿ç”¨æ–°æ¨¡å‹

### éªŒè¯å½“å‰æ¨¡å‹

```python
# åœ¨Pythonç»ˆç«¯ä¸­è¿è¡Œ
import config
print(config.get_model_info())
```

è¾“å‡ºï¼š
```
[å½“å‰æ¨¡å‹] qwen3-vl-32b-instruct
  æè¿°: Qwen3-VL 32B Instructç‰ˆ - ç›´æ¥æŒ‡ä»¤æ‰§è¡Œ
  ç±»å‹: local_oss_api
  æˆæœ¬ç­‰çº§: low
  èƒ½åŠ›: multimodal, streaming, fast_response
```

---

## ğŸ“Š è¯„æµ‹æµç¨‹

### è‡ªåŠ¨è¯„æµ‹

æ¯æ¬¡AIè°ƒç”¨éƒ½ä¼šè‡ªåŠ¨è®°å½•åˆ°`evaluation_data/evaluation_results.csv`

### äººå·¥è¯„åˆ†

1. æ‰“å¼€CSVæ–‡ä»¶
2. æ‰¾åˆ°éœ€è¦è¯„åˆ†çš„è®°å½•
3. å¡«å†™å„é¡¹è¯„åˆ†ï¼ˆ1-5åˆ†ï¼‰
4. åœ¨`notes`åˆ—æ·»åŠ è§‚å¯Ÿåˆ°çš„é—®é¢˜

ç¤ºä¾‹CSVå†…å®¹ï¼š
```csv
record_id,model_name,task_type,instruction_following_score,notes
qwen-vl-max_solve_20251030_001,qwen-vl-max,solve,4.5,"OCRè¯†åˆ«å‡†ç¡®ï¼Œä½†å…¬å¼æ¸²æŸ“æœ‰å°é—®é¢˜"
qwen3-vl-32b-instruct_solve_20251030_002,qwen3-vl-32b-instruct,solve,5.0,"å®Œç¾æ‰§è¡ŒæŒ‡ä»¤ï¼Œæ ¼å¼è§„èŒƒ"
```

### ç”ŸæˆæŠ¥å‘Š

```bash
cd backend
python evaluation_suite.py
```

æˆ–åœ¨ä»£ç ä¸­ï¼š
```python
from evaluation_suite import EvaluationLogger, ReportGenerator

logger = EvaluationLogger()
generator = ReportGenerator(logger)
report = generator.generate_report()

print("æŠ¥å‘Šå·²ç”Ÿæˆï¼")
```

æŠ¥å‘Šä¿å­˜åœ¨ï¼š`evaluation_reports/evaluation_report_{timestamp}.md`

---

## âš™ï¸ æœ¬åœ°æ¨¡å‹éƒ¨ç½²é…ç½®

### ä½¿ç”¨vLLMéƒ¨ç½²å¼€æºæ¨¡å‹

#### 1. å®‰è£…vLLM
```bash
pip install vllm
```

#### 2. å¯åŠ¨æ¨ç†æœåŠ¡ï¼ˆ32Bæ¨¡å‹ï¼‰
```bash
python -m vllm.entrypoints.openai.api_server \
    --model Qwen/Qwen3-VL-32B-Instruct \
    --host 0.0.0.0 \
    --port 8001 \
    --gpu-memory-utilization 0.9
```

#### 3. å¯åŠ¨æ¨ç†æœåŠ¡ï¼ˆ235Bæ¨¡å‹ï¼‰
```bash
python -m vllm.entrypoints.openai.api_server \
    --model Qwen/Qwen3-VL-235B-A22B-Instruct \
    --host 0.0.0.0 \
    --port 8002 \
    --tensor-parallel-size 4  # å¤šGPUå¹¶è¡Œ
```

#### 4. éªŒè¯æœåŠ¡
```bash
curl http://localhost:8001/v1/models
```

#### 5. æ›´æ–°config.pyä¸­çš„APIåœ°å€
```python
# ç¡®ä¿ç¯å¢ƒå˜é‡è®¾ç½®æ­£ç¡®
LOCAL_MODEL_API_BASE=http://localhost:8001/v1
```

---

## ğŸ§ª æµ‹è¯•æ¸…å•

### åŠŸèƒ½æµ‹è¯•

- [ ] æ¨¡å‹åˆ‡æ¢ï¼šä¿®æ”¹`ACTIVE_MODEL_KEY`åé‡å¯ï¼ŒéªŒè¯æ—¥å¿—æ˜¾ç¤ºæ­£ç¡®æ¨¡å‹
- [ ] APIè°ƒç”¨ï¼šä¸Šä¼ å›¾ç‰‡ï¼Œå‘é€è§£é¢˜è¯·æ±‚ï¼ŒéªŒè¯å“åº”æ­£å¸¸
- [ ] æµå¼å“åº”ï¼šéªŒè¯ç­”æ¡ˆé€å­—æ˜¾ç¤º
- [ ] é”™é¢˜ä¿å­˜ï¼šæ‰¹æ”¹æ¨¡å¼ä¸‹æ£€æµ‹åˆ°é”™è¯¯ï¼ŒéªŒè¯è‡ªåŠ¨ä¿å­˜
- [ ] è¯„æµ‹è®°å½•ï¼šæ£€æŸ¥`evaluation_data/evaluation_results.csv`æ˜¯å¦ç”Ÿæˆ
- [ ] æŠ¥å‘Šç”Ÿæˆï¼šè¿è¡Œè¯„æµ‹æ¡†æ¶ï¼ŒéªŒè¯MarkdownæŠ¥å‘Šç”Ÿæˆ

### æ€§èƒ½æµ‹è¯•

å¯¹æ¯ä¸ªæ¨¡å‹æµ‹è¯•ï¼š
1. ç›¸åŒè¾“å…¥ä¸‹çš„å“åº”æ—¶é—´
2. è¾“å‡ºè´¨é‡å¯¹æ¯”
3. èµ„æºå ç”¨ï¼ˆGPUå†…å­˜ã€æ¨ç†é€Ÿåº¦ï¼‰

### å¯¹æ¯”æµ‹è¯•

æŒ‰ç…§è¯„æµ‹æ¡†æ¶çš„ç»´åº¦è¿›è¡Œäººå·¥è¯„åˆ†ï¼š
1. æŒ‡ä»¤éµå¾ª
2. æ ¼å¼æ­£ç¡®æ€§
3. OCRå‡†ç¡®ç‡
4. ç­”æ¡ˆæ­£ç¡®æ€§
5. æ¨ç†è´¨é‡

---

## ğŸ“Œ æ³¨æ„äº‹é¡¹

### 1. ç¯å¢ƒå˜é‡

ç¡®ä¿`.env`æ–‡ä»¶åŒ…å«ï¼š
```env
DASHSCOPE_API_KEY=sk-your-key-here
LOCAL_MODEL_API_BASE=http://localhost:8001/v1
```

### 2. ä¾èµ–å®‰è£…

```bash
pip install httpx pandas matplotlib
```

### 3. å…¼å®¹æ€§

- ç°æœ‰APIæ¥å£ä¿æŒä¸å˜
- å‰ç«¯æ— éœ€ä¿®æ”¹
- æ•°æ®åº“ç»“æ„ä¸å˜

### 4. å›æ»šæ–¹æ¡ˆ

å¦‚æœæ–°æ¨¡å‹æœ‰é—®é¢˜ï¼Œç«‹å³åˆ‡æ¢å›åŸæ¨¡å‹ï¼š
```python
ACTIVE_MODEL_KEY = "qwen-vl-max"
```

### 5. æ€§èƒ½ä¼˜åŒ–

- ä½¿ç”¨è¿æ¥æ± å¤ç”¨HTTPè¿æ¥
- æœ¬åœ°æ¨¡å‹å¯å¯ç”¨æ‰¹å¤„ç†
- è€ƒè™‘ä½¿ç”¨å¼‚æ­¥I/O

---

## ğŸ¯ ä¸‹ä¸€æ­¥

1. **å®Œæˆé›†æˆ**ï¼šæŒ‰ç…§æœ¬æŒ‡å—ä¿®æ”¹`main_db.py`
2. **éƒ¨ç½²æœ¬åœ°æ¨¡å‹**ï¼šä½¿ç”¨vLLMæˆ–ç±»ä¼¼å·¥å…·
3. **å¼€å§‹è¯„æµ‹**ï¼šæ”¶é›†è‡³å°‘æ¯ä¸ªæ¨¡å‹10+æ ·æœ¬
4. **äººå·¥è¯„åˆ†**ï¼šå¡«å†™CSVä¸­çš„è¯„åˆ†å­—æ®µ
5. **ç”ŸæˆæŠ¥å‘Š**ï¼šè¿è¡Œè¯„æµ‹æ¡†æ¶
6. **åšå‡ºå†³ç­–**ï¼šæ ¹æ®æŠ¥å‘Šé€‰æ‹©æœ€ä¼˜æ¨¡å‹
7. **ç”Ÿäº§éƒ¨ç½²**ï¼šåˆ‡æ¢åˆ°é€‰å®šçš„æ¨¡å‹

---

## ğŸ’¡ æœ€ä½³å®è·µ

### è¯„æµ‹æ ·æœ¬é€‰æ‹©

- ç®€å•é¢˜ç›®ï¼šåŸºç¡€è¿ç®—ã€æ¦‚å¿µé¢˜
- ä¸­ç­‰é¢˜ç›®ï¼šå¤šæ­¥éª¤æ¨ç†
- å¤æ‚é¢˜ç›®ï¼šç»¼åˆåº”ç”¨ã€è¯æ˜é¢˜
- ç‰¹æ®Šæƒ…å†µï¼šæ‰‹å†™ä½“ã€æ¨¡ç³Šå›¾ç‰‡ã€å¤æ‚å…¬å¼

### è¯„åˆ†æ ‡å‡†

å»ºç«‹ç»Ÿä¸€çš„è¯„åˆ†æ ‡å‡†æ–‡æ¡£ï¼Œç¡®ä¿ä¸åŒæµ‹è¯•äººå‘˜çš„è¯„åˆ†ä¸€è‡´æ€§ã€‚

### æŒç»­ç›‘æ§

ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²åï¼ŒæŒç»­æ”¶é›†ç”¨æˆ·åé¦ˆï¼Œå®šæœŸé‡æ–°è¯„ä¼°ã€‚

---

## ğŸ“š å‚è€ƒèµ„æ–™

- **é…ç½®æ–‡ä»¶**: `backend/config.py`
- **é€‚é…å™¨**: `backend/model_adapter.py`
- **è¯„æµ‹æ¡†æ¶**: `backend/evaluation_suite.py`
- **æŠ€æœ¯æŠ¥å‘Š**: `ã€å·¥ç¨‹æ–‡æ¡£ã€‘æ²æ¢§AIè§£é¢˜ç³»ç»Ÿå®Œæ•´æŠ€æœ¯æŠ¥å‘ŠV2.md`

---

**é›†æˆæŒ‡å—ç‰ˆæœ¬**: V1.0  
**æœ€åæ›´æ–°**: 2025-10-30  
**ç»´æŠ¤è€…**: æ²æ¢§AIè§£é¢˜ç³»ç»Ÿå¼€å‘å›¢é˜Ÿ

