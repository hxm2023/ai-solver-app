"""
==============================================================================
æ²æ¢§AIè§£é¢˜ç³»ç»Ÿ - å¤§æ¨¡å‹é€‚é…å™¨
==============================================================================
åŠŸèƒ½ï¼š
- ç»Ÿä¸€ä¸åŒæ¨¡å‹çš„è°ƒç”¨æ¥å£
- æ”¯æŒDashscope APIå’ŒOpenAIå…¼å®¹API
- è‡ªåŠ¨å¤„ç†æ ¼å¼è½¬æ¢å’Œæµå¼å“åº”
==============================================================================
"""

import os
import json
import httpx
import dashscope
from typing import List, Dict, Any, Generator, Optional
from config import get_active_model_config, get_knowledge_extraction_config


# ==============================================================================
# æ¶ˆæ¯æ ¼å¼è½¬æ¢
# ==============================================================================

def convert_messages_to_openai_format(messages: List[Dict]) -> List[Dict]:
    """
    å°†Dashscopeæ ¼å¼çš„æ¶ˆæ¯è½¬æ¢ä¸ºOpenAIå…¼å®¹æ ¼å¼
    
    Dashscopeæ ¼å¼:
    {
        "role": "user",
        "content": [
            {"image": "data:image/jpeg;base64,..."},
            {"text": "é—®é¢˜æ–‡æœ¬"}
        ]
    }
    
    OpenAIæ ¼å¼:
    {
        "role": "user",
        "content": [
            {"type": "image_url", "image_url": {"url": "data:image/jpeg;base64,..."}},
            {"type": "text", "text": "é—®é¢˜æ–‡æœ¬"}
        ]
    }
    """
    converted = []
    
    for msg in messages:
        new_msg = {"role": msg["role"]}
        
        # å¦‚æœcontentæ˜¯å­—ç¬¦ä¸²ï¼Œç›´æ¥ä½¿ç”¨
        if isinstance(msg["content"], str):
            new_msg["content"] = msg["content"]
        
        # å¦‚æœcontentæ˜¯åˆ—è¡¨ï¼Œéœ€è¦è½¬æ¢æ ¼å¼
        elif isinstance(msg["content"], list):
            new_content = []
            for item in msg["content"]:
                if "text" in item:
                    new_content.append({
                        "type": "text",
                        "text": item["text"]
                    })
                elif "image" in item:
                    new_content.append({
                        "type": "image_url",
                        "image_url": {
                            "url": item["image"]
                        }
                    })
            new_msg["content"] = new_content
        
        converted.append(new_msg)
    
    return converted


def convert_messages_to_dashscope_format(messages: List[Dict]) -> List[Dict]:
    """
    å°†OpenAIæ ¼å¼è½¬æ¢å›Dashscopeæ ¼å¼ï¼ˆå¦‚æœéœ€è¦ï¼‰
    """
    converted = []
    
    for msg in messages:
        new_msg = {"role": msg["role"]}
        
        if isinstance(msg["content"], str):
            new_msg["content"] = msg["content"]
        elif isinstance(msg["content"], list):
            new_content = []
            for item in msg["content"]:
                if item.get("type") == "text":
                    new_content.append({"text": item["text"]})
                elif item.get("type") == "image_url":
                    new_content.append({"image": item["image_url"]["url"]})
            new_msg["content"] = new_content
        
        converted.append(new_msg)
    
    return converted


# ==============================================================================
# æ ¸å¿ƒé€‚é…å™¨ç±»
# ==============================================================================

class MultiModalModelAdapter:
    """
    å¤šæ¨¡æ€æ¨¡å‹ç»Ÿä¸€é€‚é…å™¨
    
    æ”¯æŒ:
    - Dashscope API (é˜¿é‡Œäº‘é€šä¹‰åƒé—®)
    - OpenAIå…¼å®¹API (æœ¬åœ°éƒ¨ç½²çš„å¼€æºæ¨¡å‹)
    """
    
    def __init__(self, model_config: Optional[Dict[str, Any]] = None):
        """
        åˆå§‹åŒ–é€‚é…å™¨
        
        Args:
            model_config: æ¨¡å‹é…ç½®å­—å…¸ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨get_active_model_config()
        """
        self.config = model_config or get_active_model_config()
        self.model_type = self.config["type"]
        self.model_name = self.config["model_name"]
        
        print(f"âœ… [æ¨¡å‹é€‚é…å™¨] åˆå§‹åŒ–: {self.model_name} (ç±»å‹: {self.model_type})")
    
    def call(
        self,
        messages: List[Dict],
        stream: bool = True,
        temperature: Optional[float] = None,
        max_tokens: Optional[int] = None
    ) -> Generator[Dict, None, None]:
        """
        ç»Ÿä¸€çš„æ¨¡å‹è°ƒç”¨æ¥å£
        
        Args:
            messages: å¯¹è¯æ¶ˆæ¯åˆ—è¡¨
            stream: æ˜¯å¦ä½¿ç”¨æµå¼å“åº”
            temperature: æ¸©åº¦å‚æ•°
            max_tokens: æœ€å¤§ç”Ÿæˆtokenæ•°
        
        Yields:
            Dict: å“åº”chunkï¼Œæ ¼å¼ç»Ÿä¸€ä¸º {"content": str, "finish_reason": str}
        """
        if self.model_type == "dashscope_api":
            yield from self._call_dashscope(messages, stream, temperature, max_tokens)
        
        elif self.model_type in ["local_oss_api", "openai_compatible"]:
            yield from self._call_openai_compatible(messages, stream, temperature, max_tokens)
        
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡å‹ç±»å‹: {self.model_type}")
    
    def _call_dashscope(
        self,
        messages: List[Dict],
        stream: bool,
        temperature: Optional[float],
        max_tokens: Optional[int]
    ) -> Generator[Dict, None, None]:
        """
        è°ƒç”¨Dashscope API
        """
        # è®¾ç½®API Key
        dashscope.api_key = self.config["api_key"]
        
        # æ„å»ºå‚æ•°
        params = {
            "model": self.model_name,
            "messages": messages,
            "stream": stream
        }
        
        if temperature is not None:
            params["temperature"] = temperature
        if max_tokens is not None:
            params["max_length"] = max_tokens
        
        # è°ƒç”¨API
        try:
            response = dashscope.MultiModalConversation.call(**params)
            
            if stream:
                # æµå¼å“åº”
                for chunk in response:
                    if chunk.status_code == 200:
                        content = chunk.output.choices[0].message.content[0]["text"]
                        finish_reason = chunk.output.choices[0].finish_reason
                        
                        yield {
                            "content": content,
                            "finish_reason": finish_reason,
                            "usage": chunk.usage if hasattr(chunk, 'usage') else None
                        }
                    else:
                        error_msg = f"Dashscope APIé”™è¯¯: {chunk.code} - {chunk.message}"
                        print(f"âŒ {error_msg}")
                        yield {
                            "content": "",
                            "finish_reason": "error",
                            "error": error_msg
                        }
                        break
            else:
                # éæµå¼å“åº”
                if response.status_code == 200:
                    content = response.output.choices[0].message.content[0]["text"]
                    yield {
                        "content": content,
                        "finish_reason": "stop",
                        "usage": response.usage
                    }
                else:
                    error_msg = f"Dashscope APIé”™è¯¯: {response.code} - {response.message}"
                    print(f"âŒ {error_msg}")
                    yield {
                        "content": "",
                        "finish_reason": "error",
                        "error": error_msg
                    }
        
        except Exception as e:
            error_msg = f"Dashscopeè°ƒç”¨å¼‚å¸¸: {str(e)}"
            print(f"âŒ {error_msg}")
            yield {
                "content": "",
                "finish_reason": "error",
                "error": error_msg
            }
    
    def _call_openai_compatible(
        self,
        messages: List[Dict],
        stream: bool,
        temperature: Optional[float],
        max_tokens: Optional[int]
    ) -> Generator[Dict, None, None]:
        """
        è°ƒç”¨OpenAIå…¼å®¹APIï¼ˆç”¨äºæœ¬åœ°éƒ¨ç½²çš„å¼€æºæ¨¡å‹ï¼‰
        """
        # è½¬æ¢æ¶ˆæ¯æ ¼å¼
        converted_messages = convert_messages_to_openai_format(messages)
        
        # æ„å»ºè¯·æ±‚å‚æ•°
        api_base = self.config["api_base"]
        api_key = self.config.get("api_key", "EMPTY")
        
        params = {
            "model": self.model_name,
            "messages": converted_messages,
            "stream": stream,
            "temperature": temperature or self.config.get("temperature", 0.7),
            "max_tokens": max_tokens or self.config.get("max_tokens", 8192)
        }
        
        # å¦‚æœæ˜¯thinkingæ¨¡å¼ï¼Œæ·»åŠ ç‰¹æ®Šå‚æ•°
        if self.config.get("thinking_mode"):
            params["extra_body"] = {"enable_thinking": True}
        
        try:
            # ä½¿ç”¨httpxå‘é€è¯·æ±‚
            headers = {
                "Authorization": f"Bearer {api_key}",
                "Content-Type": "application/json"
            }
            
            with httpx.Client(timeout=300.0) as client:
                if stream:
                    # æµå¼è¯·æ±‚
                    with client.stream(
                        "POST",
                        f"{api_base}/chat/completions",
                        json=params,
                        headers=headers
                    ) as response:
                        response.raise_for_status()
                        
                        for line in response.iter_lines():
                            if line.startswith("data: "):
                                data_str = line[6:]  # å»æ‰ "data: " å‰ç¼€
                                
                                if data_str.strip() == "[DONE]":
                                    break
                                
                                try:
                                    data = json.loads(data_str)
                                    delta = data["choices"][0]["delta"]
                                    content = delta.get("content", "")
                                    finish_reason = data["choices"][0].get("finish_reason")
                                    
                                    yield {
                                        "content": content,
                                        "finish_reason": finish_reason,
                                        "usage": data.get("usage")
                                    }
                                except json.JSONDecodeError:
                                    continue
                
                else:
                    # éæµå¼è¯·æ±‚
                    response = client.post(
                        f"{api_base}/chat/completions",
                        json=params,
                        headers=headers
                    )
                    response.raise_for_status()
                    
                    data = response.json()
                    content = data["choices"][0]["message"]["content"]
                    
                    yield {
                        "content": content,
                        "finish_reason": "stop",
                        "usage": data.get("usage")
                    }
        
        except httpx.HTTPStatusError as e:
            error_msg = f"HTTPé”™è¯¯ {e.response.status_code}: {e.response.text}"
            print(f"âŒ [OpenAIå…¼å®¹API] {error_msg}")
            yield {
                "content": "",
                "finish_reason": "error",
                "error": error_msg
            }
        
        except Exception as e:
            error_msg = f"è¯·æ±‚å¼‚å¸¸: {str(e)}"
            print(f"âŒ [OpenAIå…¼å®¹API] {error_msg}")
            yield {
                "content": "",
                "finish_reason": "error",
                "error": error_msg
            }


# ==============================================================================
# æ–‡æœ¬æ¨¡å‹é€‚é…å™¨ï¼ˆç”¨äºçŸ¥è¯†ç‚¹æå–ç­‰ï¼‰
# ==============================================================================

class TextModelAdapter:
    """
    çº¯æ–‡æœ¬æ¨¡å‹é€‚é…å™¨ï¼ˆç”¨äºçŸ¥è¯†ç‚¹æå–ã€ç»­ç­”ç”Ÿæˆç­‰ï¼‰
    """
    
    def __init__(self, model_config: Optional[Dict[str, Any]] = None):
        """åˆå§‹åŒ–æ–‡æœ¬æ¨¡å‹é€‚é…å™¨"""
        self.config = model_config or get_knowledge_extraction_config()
        self.model_type = self.config["type"]
        self.model_name = self.config["model_name"]
        
        if self.model_type == "dashscope_api":
            dashscope.api_key = self.config["api_key"]
    
    def call(self, prompt: str, temperature: float = 0.3) -> str:
        """
        è°ƒç”¨æ–‡æœ¬æ¨¡å‹
        
        Args:
            prompt: è¾“å…¥æç¤º
            temperature: æ¸©åº¦å‚æ•°
        
        Returns:
            str: æ¨¡å‹è¾“å‡ºæ–‡æœ¬
        """
        if self.model_type == "dashscope_api":
            try:
                response = dashscope.Generation.call(
                    model=self.model_name,
                    prompt=prompt,
                    temperature=temperature
                )
                
                if response.status_code == 200:
                    return response.output.text
                else:
                    print(f"âŒ Dashscopeæ–‡æœ¬æ¨¡å‹é”™è¯¯: {response.code} - {response.message}")
                    return ""
            
            except Exception as e:
                print(f"âŒ æ–‡æœ¬æ¨¡å‹è°ƒç”¨å¼‚å¸¸: {e}")
                return ""
        
        else:
            # TODO: æ·»åŠ OpenAIå…¼å®¹APIçš„æ–‡æœ¬æ¨¡å‹è°ƒç”¨
            print(f"âš ï¸  æš‚ä¸æ”¯æŒ {self.model_type} ç±»å‹çš„æ–‡æœ¬æ¨¡å‹")
            return ""


# ==============================================================================
# ä¾¿æ·å‡½æ•°
# ==============================================================================

def get_multimodal_adapter() -> MultiModalModelAdapter:
    """è·å–å¤šæ¨¡æ€æ¨¡å‹é€‚é…å™¨å®ä¾‹ï¼ˆä½¿ç”¨å½“å‰æ¿€æ´»çš„æ¨¡å‹ï¼‰"""
    return MultiModalModelAdapter()


def get_text_adapter() -> TextModelAdapter:
    """è·å–æ–‡æœ¬æ¨¡å‹é€‚é…å™¨å®ä¾‹"""
    return TextModelAdapter()


# ==============================================================================
# æµ‹è¯•ä»£ç 
# ==============================================================================

if __name__ == "__main__":
    print("\n" + "=" * 70)
    print("æ¨¡å‹é€‚é…å™¨æµ‹è¯•")
    print("=" * 70 + "\n")
    
    # æµ‹è¯•å¤šæ¨¡æ€é€‚é…å™¨
    try:
        adapter = get_multimodal_adapter()
        
        # æ„å»ºæµ‹è¯•æ¶ˆæ¯
        test_messages = [
            {
                "role": "user",
                "content": [
                    {"text": "ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±ã€‚"}
                ]
            }
        ]
        
        print("ğŸ“¤ å‘é€æµ‹è¯•æ¶ˆæ¯...")
        print("ğŸ’¬ å›å¤:")
        
        full_response = ""
        for chunk in adapter.call(test_messages, stream=True):
            if chunk["finish_reason"] != "error":
                content = chunk["content"]
                full_response += content
                print(content, end="", flush=True)
            else:
                print(f"\nâŒ é”™è¯¯: {chunk.get('error')}")
                break
        
        print("\n\nâœ… æµ‹è¯•å®Œæˆï¼")
        print(f"ğŸ“Š å®Œæ•´å›å¤é•¿åº¦: {len(full_response)} å­—ç¬¦")
    
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")

