"""
==============================================================================
æ²æ¢§AIè§£é¢˜ç³»ç»Ÿ - 5å¤§æ¨¡å‹APIé…ç½®ä¸­å¿ƒ
==============================================================================
åŠŸèƒ½ï¼šé€šè¿‡ä¿®æ”¹ä¸€è¡Œä»£ç åˆ‡æ¢5ä¸ªå¤§æ¨¡å‹
- qwen-vl-max
- qwen3-vl-32b-thinking  
- qwen3-vl-32b-instruct
- qwen3-vl-235b-a22b-thinking
- qwen3-vl-235b-a22b-instruct
==============================================================================
"""

import os
from typing import Dict, Any
from dotenv import load_dotenv

load_dotenv()

# ==============================================================================
# ğŸ”¥ æ ¸å¿ƒé…ç½®ï¼šåªéœ€ä¿®æ”¹è¿™ä¸€è¡Œä»£ç å³å¯åˆ‡æ¢æ¨¡å‹ï¼
# ==============================================================================

ACTIVE_MODEL_KEY = "qwen-vl-max"  

# åˆ‡æ¢åˆ°å…¶ä»–æ¨¡å‹ï¼Œåªéœ€å–æ¶ˆä¸‹é¢æŸä¸€è¡Œçš„æ³¨é‡Šï¼š
# ACTIVE_MODEL_KEY = "qwen3-vl-32b-thinking"
# ACTIVE_MODEL_KEY = "qwen3-vl-32b-instruct"
# ACTIVE_MODEL_KEY = "qwen3-vl-235b-a22b-thinking"
# ACTIVE_MODEL_KEY = "qwen3-vl-235b-a22b-instruct"

# ==============================================================================
# æ¨¡å‹é…ç½®è¯¦æƒ…
# ==============================================================================

MODEL_CONFIGS: Dict[str, Dict[str, Any]] = {
    
    # ----------------------------------------------------------------------
    # 1. é€šä¹‰åƒé—®VL Maxï¼ˆé—­æºåŸºå‡†æ¨¡å‹ï¼‰
    # ----------------------------------------------------------------------
    "qwen-vl-max": {
        "type": "dashscope_api",
        "model_name": "qwen-vl-max",
        "api_key_env": "DASHSCOPE_API_KEY",
        "description": "é€šä¹‰åƒé—®VL Max - é—­æºæ——èˆ°ç‰ˆ",
        "provider": "é˜¿é‡Œäº‘DashScope",
        "capabilities": ["multimodal", "streaming", "high_accuracy"],
        "cost_tier": "high",
        "pricing": "çº¦0.008å…ƒ/åƒtokens",
        "max_tokens": 8192,
        "temperature": 0.7,
    },
    
    # ----------------------------------------------------------------------
    # 2. Qwen3-VL-32B-Thinkingï¼ˆå¼€æºï¼Œå¸¦æ€è€ƒé“¾ï¼‰
    # ----------------------------------------------------------------------
    "qwen3-vl-32b-thinking": {
        "type": "openai_compatible",  # ä½¿ç”¨OpenAIå…¼å®¹APIæ ¼å¼
        "model_name": "Qwen/Qwen3-VL-32B-Thinking",  # å®é™…æ¨¡å‹åç§°
        "api_base": os.getenv("QWEN3_API_BASE", "https://api.siliconflow.cn/v1"),  # APIæœåŠ¡åœ°å€
        "api_key": os.getenv("QWEN3_API_KEY", ""),  # APIå¯†é’¥
        "description": "Qwen3-VL 32B Thinkingç‰ˆ - å¸¦æ€è€ƒé“¾æ¨ç†",
        "provider": "APIæœåŠ¡å•†ï¼ˆSiliconFlow/Together AI/è‡ªå»ºï¼‰",
        "capabilities": ["multimodal", "streaming", "chain_of_thought"],
        "cost_tier": "medium",
        "pricing": "çº¦0.003å…ƒ/åƒtokensï¼ˆå…·ä½“çœ‹æœåŠ¡å•†ï¼‰",
        "max_tokens": 8192,
        "temperature": 0.7,
        "thinking_mode": True,
    },
    
    # ----------------------------------------------------------------------
    # 3. Qwen3-VL-32B-Instructï¼ˆå¼€æºï¼Œç›´æ¥æŒ‡ä»¤ï¼‰
    # ----------------------------------------------------------------------
    "qwen3-vl-32b-instruct": {
        "type": "openai_compatible",
        "model_name": "Qwen/Qwen3-VL-32B-Instruct",
        "api_base": os.getenv("QWEN3_API_BASE", "https://api.siliconflow.cn/v1"),
        "api_key": os.getenv("QWEN3_API_KEY", ""),
        "description": "Qwen3-VL 32B Instructç‰ˆ - ç›´æ¥æŒ‡ä»¤æ‰§è¡Œ",
        "provider": "APIæœåŠ¡å•†ï¼ˆSiliconFlow/Together AI/è‡ªå»ºï¼‰",
        "capabilities": ["multimodal", "streaming", "fast_response"],
        "cost_tier": "medium",
        "pricing": "çº¦0.003å…ƒ/åƒtokens",
        "max_tokens": 8192,
        "temperature": 0.7,
        "thinking_mode": False,
    },
    
    # ----------------------------------------------------------------------
    # 4. Qwen3-VL-235B-A22B-Thinkingï¼ˆé«˜æ€§èƒ½ï¼Œå¸¦æ€è€ƒé“¾ï¼‰
    # ----------------------------------------------------------------------
    "qwen3-vl-235b-a22b-thinking": {
        "type": "openai_compatible",
        "model_name": "Qwen/Qwen3-VL-235B-A22B-Thinking",
        "api_base": os.getenv("QWEN235_API_BASE", "https://api.together.xyz/v1"),  # å¤§æ¨¡å‹é€šå¸¸ç”¨Together AI
        "api_key": os.getenv("QWEN235_API_KEY", ""),
        "description": "Qwen3-VL 235B-A22B Thinkingç‰ˆ - é¡¶çº§æ€§èƒ½æ¨ç†",
        "provider": "APIæœåŠ¡å•†ï¼ˆTogether AI/è‡ªå»ºGPUé›†ç¾¤ï¼‰",
        "capabilities": ["multimodal", "streaming", "advanced_reasoning", "high_ocr"],
        "cost_tier": "high",
        "pricing": "çº¦0.006å…ƒ/åƒtokens",
        "max_tokens": 8192,
        "temperature": 0.7,
        "thinking_mode": True,
        "ocr_enhanced": True,
    },
    
    # ----------------------------------------------------------------------
    # 5. Qwen3-VL-235B-A22B-Instructï¼ˆé«˜æ€§èƒ½ï¼Œç›´æ¥æŒ‡ä»¤ï¼‰
    # ----------------------------------------------------------------------
    "qwen3-vl-235b-a22b-instruct": {
        "type": "openai_compatible",
        "model_name": "Qwen/Qwen3-VL-235B-A22B-Instruct",
        "api_base": os.getenv("QWEN235_API_BASE", "https://api.together.xyz/v1"),
        "api_key": os.getenv("QWEN235_API_KEY", ""),
        "description": "Qwen3-VL 235B-A22B Instructç‰ˆ - é¡¶çº§æ€§èƒ½ç›´æ¥æ‰§è¡Œ",
        "provider": "APIæœåŠ¡å•†ï¼ˆTogether AI/è‡ªå»ºGPUé›†ç¾¤ï¼‰",
        "capabilities": ["multimodal", "streaming", "advanced_reasoning", "high_ocr"],
        "cost_tier": "high",
        "pricing": "çº¦0.006å…ƒ/åƒtokens",
        "max_tokens": 8192,
        "temperature": 0.7,
        "thinking_mode": False,
        "ocr_enhanced": True,
    },
}

# ==============================================================================
# é…ç½®è·å–å‡½æ•°
# ==============================================================================

def get_active_model_config() -> Dict[str, Any]:
    """è·å–å½“å‰æ¿€æ´»çš„æ¨¡å‹é…ç½®"""
    if ACTIVE_MODEL_KEY not in MODEL_CONFIGS:
        raise ValueError(
            f"æœªçŸ¥çš„æ¨¡å‹KEY: {ACTIVE_MODEL_KEY}. "
            f"å¯ç”¨çš„æ¨¡å‹: {list(MODEL_CONFIGS.keys())}"
        )
    
    config = MODEL_CONFIGS[ACTIVE_MODEL_KEY].copy()
    
    # å¦‚æœæ˜¯Dashscope APIï¼ŒåŠ è½½API Key
    if config["type"] == "dashscope_api":
        api_key = os.getenv(config["api_key_env"])
        if not api_key:
            raise ValueError(f"âŒ ç¯å¢ƒå˜é‡ {config['api_key_env']} æœªè®¾ç½®ï¼è¯·åœ¨.envæ–‡ä»¶ä¸­é…ç½®ã€‚")
        config["api_key"] = api_key
    
    # å¦‚æœæ˜¯OpenAIå…¼å®¹APIï¼ŒéªŒè¯api_key
    elif config["type"] == "openai_compatible":
        if not config.get("api_key"):
            print(f"âš ï¸  è­¦å‘Š: {ACTIVE_MODEL_KEY} çš„APIå¯†é’¥æœªè®¾ç½®ï¼Œè¯·åœ¨.envæ–‡ä»¶ä¸­é…ç½®ç›¸åº”çš„ç¯å¢ƒå˜é‡ã€‚")
    
    return config


def get_model_info() -> str:
    """è·å–å½“å‰æ¨¡å‹çš„è¯¦ç»†ä¿¡æ¯"""
    config = get_active_model_config()
    
    info = [
        "=" * 70,
        f"[å½“å‰æ¿€æ´»æ¨¡å‹] {ACTIVE_MODEL_KEY}",
        "=" * 70,
        f"ğŸ“ æè¿°: {config['description']}",
        f"ğŸ¢ æä¾›å•†: {config.get('provider', 'æœªçŸ¥')}",
        f"ğŸ”§ APIç±»å‹: {config['type']}",
        f"ğŸ’° æˆæœ¬ç­‰çº§: {config['cost_tier']}",
        f"ğŸ’µ ä»·æ ¼: {config.get('pricing', 'ä»·æ ¼æœªçŸ¥')}",
        f"âœ¨ èƒ½åŠ›: {', '.join(config['capabilities'])}",
    ]
    
    if config['type'] == 'openai_compatible':
        info.append(f"ğŸŒ APIåœ°å€: {config['api_base']}")
    
    info.append("=" * 70)
    
    return "\n".join(info)


def list_all_models():
    """åˆ—å‡ºæ‰€æœ‰å¯ç”¨æ¨¡å‹"""
    print("\n" + "=" * 70)
    print("å¯ç”¨çš„5å¤§æ¨¡å‹åˆ—è¡¨")
    print("=" * 70 + "\n")
    
    for i, (key, config) in enumerate(MODEL_CONFIGS.items(), 1):
        is_active = "âœ… [å½“å‰ä½¿ç”¨]" if key == ACTIVE_MODEL_KEY else "  "
        print(f"{i}. {is_active} {key}")
        print(f"   {config['description']}")
        print(f"   æä¾›å•†: {config.get('provider', 'æœªçŸ¥')} | ä»·æ ¼: {config.get('pricing', 'æœªçŸ¥')}")
        print()


def validate_api_keys():
    """éªŒè¯æ‰€æœ‰æ¨¡å‹çš„APIå¯†é’¥æ˜¯å¦é…ç½®"""
    print("\n" + "=" * 70)
    print("APIå¯†é’¥é…ç½®æ£€æŸ¥")
    print("=" * 70 + "\n")
    
    for key, config in MODEL_CONFIGS.items():
        if config["type"] == "dashscope_api":
            api_key = os.getenv(config["api_key_env"])
            status = "âœ… å·²é…ç½®" if api_key else "âŒ æœªé…ç½®"
            print(f"{key}: {status} ({config['api_key_env']})")
        
        elif config["type"] == "openai_compatible":
            api_key = config.get("api_key")
            status = "âœ… å·²é…ç½®" if api_key else "âŒ æœªé…ç½®"
            
            # ä»api_baseæ¨æ–­ç¯å¢ƒå˜é‡å
            if "siliconflow" in config["api_base"]:
                env_var = "QWEN3_API_KEY (æˆ– SILICONFLOW_API_KEY)"
            elif "together" in config["api_base"]:
                env_var = "QWEN235_API_KEY (æˆ– TOGETHER_API_KEY)"
            else:
                env_var = "è‡ªå®šä¹‰APIå¯†é’¥"
            
            print(f"{key}: {status} ({env_var})")
    
    print()


# ==============================================================================
# çŸ¥è¯†ç‚¹æå–æ¨¡å‹é…ç½®
# ==============================================================================

KNOWLEDGE_EXTRACTION_MODEL = "qwen-turbo"

KNOWLEDGE_EXTRACTION_CONFIGS = {
    "qwen-turbo": {
        "type": "dashscope_api",
        "model_name": "qwen-turbo",
        "api_key_env": "DASHSCOPE_API_KEY",
    },
}

def get_knowledge_extraction_config() -> Dict[str, Any]:
    """è·å–çŸ¥è¯†ç‚¹æå–æ¨¡å‹é…ç½®"""
    config = KNOWLEDGE_EXTRACTION_CONFIGS[KNOWLEDGE_EXTRACTION_MODEL].copy()
    if config["type"] == "dashscope_api":
        api_key = os.getenv(config["api_key_env"])
        if not api_key:
            raise ValueError(f"ç¯å¢ƒå˜é‡ {config['api_key_env']} æœªè®¾ç½®ï¼")
        config["api_key"] = api_key
    return config


# ==============================================================================
# æµ‹è¯•ä»£ç 
# ==============================================================================

if __name__ == "__main__":
    print("\n" + "=" * 70)
    print("æ²æ¢§AIè§£é¢˜ç³»ç»Ÿ - 5å¤§æ¨¡å‹é…ç½®æµ‹è¯•")
    print("=" * 70)
    
    # æ˜¾ç¤ºæ‰€æœ‰æ¨¡å‹
    list_all_models()
    
    # æ˜¾ç¤ºå½“å‰æ¿€æ´»çš„æ¨¡å‹
    print(get_model_info())
    
    # éªŒè¯APIå¯†é’¥
    validate_api_keys()
    
    # æµ‹è¯•é…ç½®è·å–
    print("=" * 70)
    print("é…ç½®åŠ è½½æµ‹è¯•")
    print("=" * 70 + "\n")
    
    try:
        config = get_active_model_config()
        print(f"âœ… é…ç½®åŠ è½½æˆåŠŸï¼")
        print(f"   æ¨¡å‹åç§°: {config['model_name']}")
        print(f"   APIç±»å‹: {config['type']}")
        if config['type'] == 'openai_compatible':
            print(f"   APIåœ°å€: {config['api_base']}")
    except Exception as e:
        print(f"âŒ é…ç½®åŠ è½½å¤±è´¥: {e}")
    
    print("\n" + "=" * 70)
    print("ğŸ’¡ æç¤º: ä¿®æ”¹ ACTIVE_MODEL_KEY å˜é‡å³å¯åˆ‡æ¢æ¨¡å‹")
    print("=" * 70 + "\n")

