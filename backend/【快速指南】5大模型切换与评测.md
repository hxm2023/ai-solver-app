# 🚀 沐梧AI解题系统 - 5大模型切换与评测完整指南

## 📋 目录
1. [快速切换模型](#1-快速切换模型)
2. [API密钥配置](#2-api密钥配置)
3. [测试模型连接](#3-测试模型连接)
4. [运行评测](#4-运行评测)
5. [生成对比报告](#5-生成对比报告)
6. [API服务商推荐](#6-api服务商推荐)

---

## 1. 快速切换模型

### 🎯 一行代码切换法

打开 `backend/config_api_models.py`，找到第 **23** 行：

```python
ACTIVE_MODEL_KEY = "qwen-vl-max"  
```

修改为以下任意一个即可切换：

```python
# 切换到 Qwen3-VL-32B-Thinking
ACTIVE_MODEL_KEY = "qwen3-vl-32b-thinking"

# 切换到 Qwen3-VL-32B-Instruct
ACTIVE_MODEL_KEY = "qwen3-vl-32b-instruct"

# 切换到 Qwen3-VL-235B-A22B-Thinking
ACTIVE_MODEL_KEY = "qwen3-vl-235b-a22b-thinking"

# 切换到 Qwen3-VL-235B-A22B-Instruct
ACTIVE_MODEL_KEY = "qwen3-vl-235b-a22b-instruct"
```

### ✅ 让配置生效

**方式一：替换现有config.py（推荐）**
```bash
cd backend
# 备份原配置
copy config.py config_backup.py
# 使用新配置
copy config_api_models.py config.py
```

**方式二：在main_db.py中修改导入**
```python
# 将 import config 改为
import config_api_models as config
```

---

## 2. API密钥配置

### 📝 编辑 `.env` 文件

在 `backend/.env` 文件中添加以下配置：

```bash
# 1. 阿里云DashScope（qwen-vl-max必需）
DASHSCOPE_API_KEY=sk-your-dashscope-api-key-here

# 2. Qwen3-32B系列API密钥（选择以下任一服务商）

# 方案A：使用SiliconFlow（推荐，便宜稳定）
QWEN3_API_BASE=https://api.siliconflow.cn/v1
QWEN3_API_KEY=sk-your-siliconflow-api-key

# 方案B：使用Together AI
# QWEN3_API_BASE=https://api.together.xyz/v1
# QWEN3_API_KEY=your-together-ai-key

# 方案C：自建vLLM服务器
# QWEN3_API_BASE=http://your-server-ip:8001/v1
# QWEN3_API_KEY=EMPTY

# 3. Qwen3-235B系列API密钥（大模型，推荐Together AI）

# 方案A：使用Together AI（推荐）
QWEN235_API_BASE=https://api.together.xyz/v1
QWEN235_API_KEY=your-together-ai-key

# 方案B：自建GPU集群
# QWEN235_API_BASE=http://your-gpu-cluster:8002/v1
# QWEN235_API_KEY=EMPTY
```

### 🔑 获取API密钥

#### SiliconFlow（推荐用于32B模型）
1. 访问：https://cloud.siliconflow.cn/
2. 注册并登录
3. 进入"API密钥"页面创建新密钥
4. 价格：约 ¥0.003/千tokens（非常便宜）

#### Together AI（推荐用于235B大模型）
1. 访问：https://www.together.ai/
2. 注册并登录
3. 进入"API Keys"创建新密钥
4. 价格：约 $0.006/千tokens

#### 阿里云DashScope（qwen-vl-max）
1. 访问：https://dashscope.console.aliyun.com/
2. 开通服务并创建API Key
3. 价格：约 ¥0.008/千tokens

---

## 3. 测试模型连接

### 🧪 方法一：使用配置测试脚本

```bash
cd backend
python config_api_models.py
```

预期输出：
```
==================================================================
可用的5大模型列表
==================================================================

1. ✅ [当前使用] qwen-vl-max
   通义千问VL Max - 闭源旗舰版
   提供商: 阿里云DashScope | 价格: 约0.008元/千tokens

2.   qwen3-vl-32b-thinking
   Qwen3-VL 32B Thinking版 - 带思考链推理
   提供商: API服务商（SiliconFlow/Together AI/自建） | 价格: 约0.003元/千tokens

...

==================================================================
API密钥配置检查
==================================================================

qwen-vl-max: ✅ 已配置 (DASHSCOPE_API_KEY)
qwen3-vl-32b-thinking: ✅ 已配置 (QWEN3_API_KEY)
...
```

### 🧪 方法二：使用快速测试脚本

```bash
cd backend
python run_evaluation_test.py
```

这会实际调用一次API，测试连接是否正常。

---

## 4. 运行评测

### 📊 自动评测（推荐）

评测框架已集成到 `main_db.py` 中，**每次AI交互都会自动记录评测数据**。

**启动系统进行评测：**

```bash
# 1. 启动后端
cd backend
python main_db.py

# 2. 启动前端
cd frontend/vite-project
npm run dev

# 3. 在浏览器中进行测试
# 访问 http://localhost:5173
# 登录后进行解题、批改作业、生成试卷等操作
```

**评测数据自动保存位置：**
```
backend/evaluation_data/evaluation_results.csv
```

### 🔄 完整5模型对比评测流程

为了获得完整的对比报告，您需要依次测试每个模型：

**第1步：测试 qwen-vl-max**
```python
# 编辑 backend/config_api_models.py
ACTIVE_MODEL_KEY = "qwen-vl-max"
```
```bash
# 重启后端
cd backend
python main_db.py
```
在前端进行10-20次测试（解题、批改、生成试卷）

**第2步：测试 qwen3-vl-32b-thinking**
```python
ACTIVE_MODEL_KEY = "qwen3-vl-32b-thinking"
```
重启后端，再进行10-20次测试

**第3步至第5步：依次测试其他3个模型**

按照相同流程测试：
- `qwen3-vl-32b-instruct`
- `qwen3-vl-235b-a22b-thinking`
- `qwen3-vl-235b-a22b-instruct`

---

## 5. 生成对比报告

### 📈 生成Markdown评测报告

完成所有模型测试后，运行报告生成脚本：

```bash
cd backend
python -c "from evaluation_suite import EvaluationLogger, ReportGenerator; logger = EvaluationLogger(); report = ReportGenerator(logger); report.generate_report()"
```

**报告保存位置：**
```
backend/evaluation_reports/evaluation_report_YYYYMMDD_HHMMSS.md
```

### 📊 报告内容包括：

1. **执行摘要**：综合对比结论
2. **综合评分对比表**：5个模型的全维度对比
3. **任务专项分析**：
   - 解题任务（OCR准确率、正确性、推理质量）
   - 批改任务（错误检测、解释清晰度、知识点准确性）
   - 生成任务（相关性、创意性、答案完整性）
4. **定性问题日志**：典型失败案例分类
5. **最终推荐**：基于性能和成本的建议

### 📝 查看报告

```bash
# 使用Markdown查看器
# 或直接用VS Code打开
code backend/evaluation_reports/evaluation_report_*.md
```

---

## 6. API服务商推荐

### 🏆 推荐配置方案

#### 方案A：极致性价比（推荐初期测试）
```bash
# qwen-vl-max: 阿里云DashScope（基准对比）
# qwen3-32b系列: SiliconFlow（便宜）
# qwen3-235b系列: Together AI（稳定）

总成本：约 ¥0.004/千tokens（平均）
```

#### 方案B：高性能稳定
```bash
# qwen-vl-max: 阿里云DashScope
# 所有开源模型: Together AI

总成本：约 ¥0.006/千tokens
优势：服务稳定，国际化
```

#### 方案C：完全自主（大规模使用）
```bash
# qwen-vl-max: 阿里云DashScope（仅用于对比）
# 所有开源模型: 自建vLLM集群

成本：仅GPU硬件成本
优势：数据隐私、无限调用
```

---

## 🎯 快速上手检查清单

- [ ] 1. 复制 `config_api_models.py` 为 `config.py`
- [ ] 2. 在 `.env` 中配置 `DASHSCOPE_API_KEY`
- [ ] 3. 在 `.env` 中配置 `QWEN3_API_KEY`（选择服务商）
- [ ] 4. 在 `.env` 中配置 `QWEN235_API_KEY`（选择服务商）
- [ ] 5. 运行 `python config_api_models.py` 测试配置
- [ ] 6. 启动系统，进行第一个模型的测试
- [ ] 7. 切换模型（修改 `ACTIVE_MODEL_KEY`），重复测试
- [ ] 8. 完成所有模型测试后，生成对比报告
- [ ] 9. 查看 `evaluation_reports` 文件夹中的报告

---

## ❓ 常见问题

### Q1: 开源模型的API在哪里找？
**A**: 
- Qwen3-VL-32B系列：推荐 SiliconFlow (https://cloud.siliconflow.cn)
- Qwen3-VL-235B系列：推荐 Together AI (https://www.together.ai)
- 也可以自己用vLLM部署后暴露OpenAI兼容API

### Q2: 为什么我的开源模型返回错误？
**A**: 检查以下几点：
1. API密钥是否正确配置
2. API地址是否正确（有些需要 `/v1` 后缀）
3. 模型名称是否准确（如 `Qwen/Qwen3-VL-32B-Instruct`）
4. 服务商是否支持该模型的多模态能力

### Q3: 评测数据在哪里？
**A**: 
- 原始数据：`backend/evaluation_data/evaluation_results.csv`
- 报告：`backend/evaluation_reports/evaluation_report_*.md`

### Q4: 如何手动添加评测记录？
**A**: 直接编辑 `evaluation_results.csv`，或在代码中调用：
```python
from evaluation_suite import quick_evaluate_and_log
quick_evaluate_and_log(
    model_name="qwen3-vl-32b-thinking",
    task_type="solve",
    input_prompt="解这道题...",
    raw_output="AI的回答...",
    response_time=2.5,
    token_count=1024,
    notes="测试备注"
)
```

---

## 📞 技术支持

如有问题，请检查：
1. `backend/【集成指南】大模型切换与评测框架.md`
2. `backend/【完成】大模型替换与评测框架开发报告.md`
3. `【交付】大模型替换与评测框架 - 完整交付清单.md`

---

**祝您测试顺利！🎉**

