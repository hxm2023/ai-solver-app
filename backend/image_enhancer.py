# ==============================================================================
# image_enhancer.py - ä¸“ä¸šçº§å›¾åƒå¢å¼ºæ¨¡å—
# åŠŸèƒ½ï¼šå¯¹ä¸Šä¼ çš„å›¾ç‰‡è¿›è¡Œæ™ºèƒ½ç”»è´¨ä¼˜åŒ–ï¼Œæå‡OCRè¯†åˆ«å‡†ç¡®ç‡
# æŠ€æœ¯ï¼šåé”åŒ–æ©æ¨¡ (Unsharp Masking) + CLAHEå¯¹æ¯”åº¦å¢å¼º
# ç‰ˆæœ¬ï¼šV1.0
# ==============================================================================

import cv2
import numpy as np
from PIL import Image
from typing import Optional


def pil_to_cv2(pil_img: Image.Image) -> np.ndarray:
    """
    å°†Pillow Imageå¯¹è±¡è½¬æ¢ä¸ºOpenCVçš„numpy ndarrayæ ¼å¼ï¼ˆBGRè‰²å½©ç©ºé—´ï¼‰
    
    Args:
        pil_img: PIL.Imageå¯¹è±¡
        
    Returns:
        cv_img: OpenCVæ ¼å¼çš„numpyæ•°ç»„ï¼ˆBGRè‰²å½©ç©ºé—´ï¼‰
    """
    # ç¡®ä¿å›¾åƒæ˜¯RGBæ¨¡å¼
    if pil_img.mode != 'RGB':
        pil_img = pil_img.convert('RGB')
    
    # PILä½¿ç”¨RGBï¼ŒOpenCVä½¿ç”¨BGRï¼Œéœ€è¦è½¬æ¢
    # å…ˆè½¬ä¸ºnumpyæ•°ç»„ï¼ˆRGBï¼‰
    img_array = np.array(pil_img)
    
    # RGB â†’ BGRï¼ˆOpenCVæ ¼å¼ï¼‰
    cv_img = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)
    
    return cv_img


def cv2_to_pil(cv_img: np.ndarray) -> Image.Image:
    """
    å°†OpenCVçš„numpyæ•°ç»„è½¬æ¢å›Pillow Imageå¯¹è±¡
    
    Args:
        cv_img: OpenCVæ ¼å¼çš„numpyæ•°ç»„ï¼ˆBGRè‰²å½©ç©ºé—´ï¼‰
        
    Returns:
        pil_img: PIL.Imageå¯¹è±¡
    """
    # BGR â†’ RGB
    rgb_img = cv2.cvtColor(cv_img, cv2.COLOR_BGR2RGB)
    
    # numpyæ•°ç»„ â†’ PIL Image
    pil_img = Image.fromarray(rgb_img)
    
    return pil_img


def sharpen_image(cv_img: np.ndarray, kernel_size: int = 5, sigma: float = 1.0, 
                  amount: float = 1.5, threshold: int = 0) -> np.ndarray:
    """
    ä½¿ç”¨åé”åŒ–æ©æ¨¡ï¼ˆUnsharp Maskingï¼‰ç®—æ³•å¯¹å›¾åƒè¿›è¡Œé”åŒ–å¤„ç†
    
    åŸç†ï¼š
    1. å¯¹åŸå›¾è¿›è¡Œé«˜æ–¯æ¨¡ç³Šå¾—åˆ°æ¨¡ç³Šç‰ˆæœ¬
    2. åŸå›¾å‡å»æ¨¡ç³Šç‰ˆæœ¬å¾—åˆ°é«˜é¢‘ç»†èŠ‚ï¼ˆè¾¹ç¼˜ï¼‰
    3. å°†é«˜é¢‘ç»†èŠ‚æŒ‰æ¯”ä¾‹å åŠ å›åŸå›¾ï¼Œå¢å¼ºè¾¹ç¼˜
    
    Args:
        cv_img: è¾“å…¥å›¾åƒï¼ˆBGRæ ¼å¼ï¼‰
        kernel_size: é«˜æ–¯æ¨¡ç³Šæ ¸å¤§å°ï¼ˆå¥‡æ•°ï¼‰ï¼Œè¶Šå¤§æ¨¡ç³Šè¶Šå¼º
        sigma: é«˜æ–¯æ ¸æ ‡å‡†å·®ï¼Œæ§åˆ¶æ¨¡ç³Šç¨‹åº¦
        amount: é”åŒ–å¼ºåº¦ï¼Œ1.0-2.0ä¸ºä½³ï¼Œè¶Šå¤§è¶Šé”
        threshold: é˜ˆå€¼ï¼Œåªé”åŒ–å·®å¼‚è¶…è¿‡æ­¤å€¼çš„åƒç´ ï¼ˆé™å™ªç”¨ï¼‰
        
    Returns:
        sharpened: é”åŒ–åçš„å›¾åƒ
    """
    print(f"[å›¾åƒå¢å¼º] æ­£åœ¨è¿›è¡Œé”åŒ–å¤„ç†... (kernel_size={kernel_size}, amount={amount})")
    
    # æ­¥éª¤1ï¼šåˆ›å»ºæ¨¡ç³Šç‰ˆæœ¬
    blurred = cv2.GaussianBlur(cv_img, (kernel_size, kernel_size), sigma)
    
    # æ­¥éª¤2ï¼šè®¡ç®—é«˜é¢‘ç»†èŠ‚ï¼ˆåŸå›¾ - æ¨¡ç³Šå›¾ï¼‰
    # ä½¿ç”¨floatç±»å‹é¿å…æº¢å‡º
    high_freq = cv_img.astype(np.float32) - blurred.astype(np.float32)
    
    # æ­¥éª¤3ï¼šå°†é«˜é¢‘ç»†èŠ‚æŒ‰æ¯”ä¾‹å åŠ å›åŸå›¾
    # sharpened = original + amount * high_freq
    sharpened = cv_img.astype(np.float32) + amount * high_freq
    
    # æ­¥éª¤4ï¼šåº”ç”¨é˜ˆå€¼ï¼ˆå¯é€‰ï¼Œç”¨äºé™å™ªï¼‰
    if threshold > 0:
        # åªä¿ç•™å·®å¼‚è¶…è¿‡é˜ˆå€¼çš„å¢å¼º
        mask = np.abs(high_freq) > threshold
        sharpened = np.where(mask, sharpened, cv_img.astype(np.float32))
    
    # æ­¥éª¤5ï¼šè£å‰ªåˆ°æœ‰æ•ˆèŒƒå›´[0, 255]å¹¶è½¬æ¢å›uint8
    sharpened = np.clip(sharpened, 0, 255).astype(np.uint8)
    
    print("[å›¾åƒå¢å¼º] âœ“ é”åŒ–å¤„ç†å®Œæˆ")
    return sharpened


def enhance_contrast_clahe(cv_img: np.ndarray, clip_limit: float = 2.0, 
                           tile_grid_size: tuple = (8, 8)) -> np.ndarray:
    """
    ä½¿ç”¨CLAHEï¼ˆå¯¹æ¯”åº¦å—é™è‡ªé€‚åº”ç›´æ–¹å›¾å‡è¡¡åŒ–ï¼‰å¢å¼ºå›¾åƒå¯¹æ¯”åº¦
    
    åŸç†ï¼š
    CLAHEæ˜¯ä¼ ç»Ÿç›´æ–¹å›¾å‡è¡¡åŒ–çš„æ”¹è¿›ç‰ˆæœ¬ï¼Œå®ƒå°†å›¾åƒåˆ†æˆå°å—ï¼ˆtilesï¼‰ï¼Œ
    åœ¨æ¯ä¸ªå°å—å†…ç‹¬ç«‹è¿›è¡Œå¯¹æ¯”åº¦å¢å¼ºï¼Œå¹¶ä½¿ç”¨åŒçº¿æ€§æ’å€¼å¹³æ»‘è¾¹ç•Œã€‚
    å¯¹æ¯”åº¦é™åˆ¶ï¼ˆclip_limitï¼‰é˜²æ­¢è¿‡åº¦å¢å¼ºå¯¼è‡´å™ªå£°æ”¾å¤§ã€‚
    
    ä¸ºä»€ä¹ˆç”¨LABè‰²å½©ç©ºé—´ï¼Ÿ
    - Lé€šé“ï¼šäº®åº¦ä¿¡æ¯ï¼Œç‹¬ç«‹äºé¢œè‰²
    - A/Bé€šé“ï¼šè‰²å½©ä¿¡æ¯
    - åªå¯¹Lé€šé“å¢å¼ºï¼Œä¿æŒè‰²å½©ä¸å¤±çœŸ
    
    Args:
        cv_img: è¾“å…¥å›¾åƒï¼ˆBGRæ ¼å¼ï¼‰
        clip_limit: å¯¹æ¯”åº¦é™åˆ¶å› å­ï¼Œ1.0-4.0ä¸ºä½³ï¼Œè¶Šå¤§å¯¹æ¯”åº¦è¶Šå¼º
        tile_grid_size: åˆ†å—å¤§å°ï¼Œå¦‚(8,8)è¡¨ç¤ºå°†å›¾åƒåˆ†æˆ8x8ä¸ªå°å—
        
    Returns:
        enhanced: å¯¹æ¯”åº¦å¢å¼ºåçš„å›¾åƒï¼ˆBGRæ ¼å¼ï¼‰
    """
    print(f"[å›¾åƒå¢å¼º] æ­£åœ¨è¿›è¡ŒCLAHEå¯¹æ¯”åº¦å¢å¼º... (clip_limit={clip_limit}, tile_grid={tile_grid_size})")
    
    # æ­¥éª¤1ï¼šBGR â†’ LABè‰²å½©ç©ºé—´
    # LABç©ºé—´ä¸­Lé€šé“è¡¨ç¤ºäº®åº¦ï¼Œä¸è‰²å½©ä¿¡æ¯è§£è€¦
    lab = cv2.cvtColor(cv_img, cv2.COLOR_BGR2LAB)
    
    # æ­¥éª¤2ï¼šåˆ†ç¦»LABä¸‰ä¸ªé€šé“
    l_channel, a_channel, b_channel = cv2.split(lab)
    
    # æ­¥éª¤3ï¼šåˆ›å»ºCLAHEå¯¹è±¡
    clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=tile_grid_size)
    
    # æ­¥éª¤4ï¼šåªå¯¹Lï¼ˆäº®åº¦ï¼‰é€šé“åº”ç”¨CLAHE
    l_channel_clahe = clahe.apply(l_channel)
    
    # æ­¥éª¤5ï¼šåˆå¹¶å¢å¼ºåçš„Lé€šé“ä¸åŸå§‹çš„Aã€Bé€šé“
    lab_enhanced = cv2.merge([l_channel_clahe, a_channel, b_channel])
    
    # æ­¥éª¤6ï¼šLAB â†’ BGRï¼Œè½¬æ¢å›åŸå§‹è‰²å½©ç©ºé—´
    enhanced = cv2.cvtColor(lab_enhanced, cv2.COLOR_LAB2BGR)
    
    print("[å›¾åƒå¢å¼º] âœ“ CLAHEå¯¹æ¯”åº¦å¢å¼ºå®Œæˆ")
    return enhanced


def advanced_image_processing_pipeline(pil_img: Image.Image, 
                                      sharpen_amount: float = 1.5,
                                      clahe_clip_limit: float = 2.0) -> Image.Image:
    """
    é«˜çº§å›¾åƒå¤„ç†æµæ°´çº¿ï¼ˆæ€»å…¥å£å‡½æ•°ï¼‰
    
    å¤„ç†æµç¨‹ï¼š
    1. Pillow Image â†’ OpenCV numpyæ•°ç»„
    2. åé”åŒ–æ©æ¨¡é”åŒ–ï¼ˆå¢å¼ºè¾¹ç¼˜å’Œæ–‡å­—æ¸…æ™°åº¦ï¼‰
    3. CLAHEå¯¹æ¯”åº¦å¢å¼ºï¼ˆæ”¹å–„å…‰ç…§ä¸å‡å’Œå¯¹æ¯”åº¦ä¸è¶³ï¼‰
    4. OpenCV numpyæ•°ç»„ â†’ Pillow Image
    
    Args:
        pil_img: è¾“å…¥çš„Pillow Imageå¯¹è±¡
        sharpen_amount: é”åŒ–å¼ºåº¦ï¼ˆ1.0-2.0ï¼‰ï¼Œé»˜è®¤1.5
        clahe_clip_limit: CLAHEå¯¹æ¯”åº¦é™åˆ¶ï¼ˆ1.0-4.0ï¼‰ï¼Œé»˜è®¤2.0
        
    Returns:
        enhanced_pil_img: å¢å¼ºåçš„Pillow Imageå¯¹è±¡
    """
    print("\n" + "="*70)
    print("ã€å›¾åƒå¢å¼ºæµæ°´çº¿ã€‘å¼€å§‹å¤„ç†")
    print("="*70)
    
    try:
        # æ­¥éª¤1ï¼šæ ¼å¼è½¬æ¢ PIL â†’ OpenCV
        print("[å›¾åƒå¢å¼º] æ­¥éª¤1: è½¬æ¢å›¾åƒæ ¼å¼ (PIL â†’ OpenCV)")
        cv_img = pil_to_cv2(pil_img)
        print(f"[å›¾åƒå¢å¼º] âœ“ å›¾åƒå°ºå¯¸: {cv_img.shape[1]}x{cv_img.shape[0]}, è‰²å½©é€šé“: {cv_img.shape[2]}")
        
        # æ­¥éª¤2ï¼šé”åŒ–å¤„ç†
        print("[å›¾åƒå¢å¼º] æ­¥éª¤2: åº”ç”¨åé”åŒ–æ©æ¨¡")
        sharpened_img = sharpen_image(cv_img, amount=sharpen_amount)
        
        # æ­¥éª¤3ï¼šå¯¹æ¯”åº¦å¢å¼º
        print("[å›¾åƒå¢å¼º] æ­¥éª¤3: åº”ç”¨CLAHEå¯¹æ¯”åº¦å¢å¼º")
        enhanced_img = enhance_contrast_clahe(sharpened_img, clip_limit=clahe_clip_limit)
        
        # æ­¥éª¤4ï¼šæ ¼å¼è½¬æ¢ OpenCV â†’ PIL
        print("[å›¾åƒå¢å¼º] æ­¥éª¤4: è½¬æ¢å›¾åƒæ ¼å¼ (OpenCV â†’ PIL)")
        enhanced_pil_img = cv2_to_pil(enhanced_img)
        
        print("="*70)
        print("ã€å›¾åƒå¢å¼ºæµæ°´çº¿ã€‘âœ… å¤„ç†å®Œæˆï¼")
        print("="*70 + "\n")
        
        return enhanced_pil_img
        
    except Exception as e:
        print(f"!!! [å›¾åƒå¢å¼º] å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        print(f"!!! [å›¾åƒå¢å¼º] è¿”å›åŸå§‹å›¾åƒä½œä¸ºé™çº§æ–¹æ¡ˆ")
        print("="*70 + "\n")
        return pil_img


# ==============================================================================
# å¯é€‰ï¼šç‹¬ç«‹æµ‹è¯•å‡½æ•°ï¼ˆå¼€å‘è°ƒè¯•ç”¨ï¼‰
# ==============================================================================
def test_enhancer(image_path: str, output_path: str = "enhanced_output.png"):
    """
    ç‹¬ç«‹æµ‹è¯•å‡½æ•°ï¼Œç”¨äºå¼€å‘æ—¶éªŒè¯å›¾åƒå¢å¼ºæ•ˆæœ
    
    ä½¿ç”¨æ–¹æ³•ï¼š
    python image_enhancer.py
    
    Args:
        image_path: è¾“å…¥å›¾åƒè·¯å¾„
        output_path: è¾“å‡ºå›¾åƒè·¯å¾„
    """
    print(f"ğŸ” æµ‹è¯•æ¨¡å¼ï¼šè¯»å–å›¾åƒ {image_path}")
    
    # è¯»å–å›¾åƒ
    pil_img = Image.open(image_path)
    print(f"åŸå§‹å›¾åƒå°ºå¯¸: {pil_img.size}, æ¨¡å¼: {pil_img.mode}")
    
    # åº”ç”¨å¢å¼ºæµæ°´çº¿
    enhanced_img = advanced_image_processing_pipeline(pil_img)
    
    # ä¿å­˜ç»“æœ
    enhanced_img.save(output_path)
    print(f"âœ… å¢å¼ºåçš„å›¾åƒå·²ä¿å­˜åˆ°: {output_path}")
    
    # æ˜¾ç¤ºå¯¹æ¯”ï¼ˆå¯é€‰ï¼Œéœ€è¦matplotlibï¼‰
    try:
        import matplotlib.pyplot as plt
        
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))
        ax1.imshow(pil_img)
        ax1.set_title("åŸå§‹å›¾åƒ")
        ax1.axis('off')
        
        ax2.imshow(enhanced_img)
        ax2.set_title("å¢å¼ºåå›¾åƒ")
        ax2.axis('off')
        
        plt.tight_layout()
        plt.savefig("comparison.png")
        print("âœ… å¯¹æ¯”å›¾å·²ä¿å­˜åˆ°: comparison.png")
        
    except ImportError:
        print("â„¹ï¸ æœªå®‰è£…matplotlibï¼Œè·³è¿‡å¯¹æ¯”å›¾ç”Ÿæˆ")


if __name__ == "__main__":
    # å¦‚æœç›´æ¥è¿è¡Œæ­¤æ–‡ä»¶ï¼Œæ‰§è¡Œæµ‹è¯•
    import sys
    
    if len(sys.argv) > 1:
        test_image_path = sys.argv[1]
        output_path = sys.argv[2] if len(sys.argv) > 2 else "enhanced_output.png"
        test_enhancer(test_image_path, output_path)
    else:
        print("ğŸ“– ä½¿ç”¨æ–¹æ³•:")
        print("  python image_enhancer.py <è¾“å…¥å›¾åƒè·¯å¾„> [è¾“å‡ºå›¾åƒè·¯å¾„]")
        print("\nç¤ºä¾‹:")
        print("  python image_enhancer.py test_image.png enhanced_test.png")

